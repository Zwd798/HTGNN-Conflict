{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data.utils import load_graphs\n",
    "\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import model.model\n",
    "importlib.reload(model.model)\n",
    "from model.model import HTGNN, LinkPredictor\n",
    "\n",
    "from utils.pytorchtools import EarlyStopping\n",
    "from utils.utils import compute_metric, compute_loss\n",
    "\n",
    "import utils\n",
    "import utils.data\n",
    "importlib.reload(utils)\n",
    "importlib.reload(utils.data)\n",
    "from utils.data import load_MAG_data,load_MAG_data_acled,load_MAG_data_acled_time_split, generate_APA_acled, construct_htg_label_mag_acled, load_MAG_data_acled_general\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dgl.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def evaluate(model, val_feats, val_labels):\n",
    "    device = torch.device('cuda:0')\n",
    "    val_mae_list, val_rmse_list = [], []\n",
    "    auc_list, ap_list, acc_list, f1_list = [], [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (G_feat, (pos_label, neg_label)) in zip(val_feats, val_labels):\n",
    "            # pdb.set_trace()\n",
    "            G_feat = G_feat.to(device)\n",
    "            pos_label = pos_label.to(device)\n",
    "            neg_label = neg_label.to(device)\n",
    "\n",
    "            # h = model[0](G_feat, 'author')\n",
    "            h = model[0](G_feat, 'actor')\n",
    "            pos_score = model[1](pos_label, h)\n",
    "            neg_score = model[1](neg_label, h)\n",
    "            # print('score')\n",
    "            # print(neg_score)\n",
    "            loss = compute_loss(pos_score, neg_score, device)\n",
    "            auc, ap, acc, f1 = compute_metric(pos_score, neg_score)\n",
    "            auc_list.append(auc)\n",
    "            ap_list.append(ap)\n",
    "            acc_list.append(acc)\n",
    "            f1_list.append(f1)\n",
    "    \n",
    "    return auc, ap, statistics.mean(auc_list), statistics.mean(ap_list), statistics.mean(acc_list), statistics.mean(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Graph(num_nodes={'author': 17764, 'field_of_study': 14635, 'institution': 2276, 'paper': 27112},\n",
       "       num_edges={('author', 'affiliated_with', 'institution'): 40307, ('author', 'writes', 'paper'): 101109, ('paper', 'cites', 'paper'): 19926, ('paper', 'has_topic', 'field_of_study'): 285074},\n",
       "       metagraph=[('author', 'institution', 'affiliated_with'), ('author', 'paper', 'writes'), ('paper', 'paper', 'cites'), ('paper', 'field_of_study', 'has_topic')]),\n",
       " Graph(num_nodes={'author': 17764, 'field_of_study': 15186, 'institution': 2276, 'paper': 28584},\n",
       "       num_edges={('author', 'affiliated_with', 'institution'): 40307, ('author', 'writes', 'paper'): 130156, ('paper', 'cites', 'paper'): 21276, ('paper', 'has_topic', 'field_of_study'): 299817},\n",
       "       metagraph=[('author', 'institution', 'affiliated_with'), ('author', 'paper', 'writes'), ('paper', 'paper', 'cites'), ('paper', 'field_of_study', 'has_topic')]),\n",
       " Graph(num_nodes={'author': 17764, 'field_of_study': 15709, 'institution': 2276, 'paper': 30490},\n",
       "       num_edges={('author', 'affiliated_with', 'institution'): 40307, ('author', 'writes', 'paper'): 200760, ('paper', 'cites', 'paper'): 24575, ('paper', 'has_topic', 'field_of_study'): 318040},\n",
       "       metagraph=[('author', 'institution', 'affiliated_with'), ('author', 'paper', 'writes'), ('paper', 'paper', 'cites'), ('paper', 'field_of_study', 'has_topic')]),\n",
       " Graph(num_nodes={'author': 17764, 'field_of_study': 15953, 'institution': 2276, 'paper': 31499},\n",
       "       num_edges={('author', 'affiliated_with', 'institution'): 40307, ('author', 'writes', 'paper'): 172354, ('paper', 'cites', 'paper'): 27417, ('paper', 'has_topic', 'field_of_study'): 328176},\n",
       "       metagraph=[('author', 'institution', 'affiliated_with'), ('author', 'paper', 'writes'), ('paper', 'paper', 'cites'), ('paper', 'field_of_study', 'has_topic')]),\n",
       " Graph(num_nodes={'author': 17764, 'field_of_study': 15936, 'institution': 2276, 'paper': 30767},\n",
       "       num_edges={('author', 'affiliated_with', 'institution'): 40307, ('author', 'writes', 'paper'): 214951, ('paper', 'cites', 'paper'): 25780, ('paper', 'has_topic', 'field_of_study'): 320562},\n",
       "       metagraph=[('author', 'institution', 'affiliated_with'), ('author', 'paper', 'writes'), ('paper', 'paper', 'cites'), ('paper', 'field_of_study', 'has_topic')]),\n",
       " Graph(num_nodes={'author': 17764, 'field_of_study': 15736, 'institution': 2276, 'paper': 30266},\n",
       "       num_edges={('author', 'affiliated_with', 'institution'): 40307, ('author', 'writes', 'paper'): 244222, ('paper', 'cites', 'paper'): 24416, ('paper', 'has_topic', 'field_of_study'): 314497},\n",
       "       metagraph=[('author', 'institution', 'affiliated_with'), ('author', 'paper', 'writes'), ('paper', 'paper', 'cites'), ('paper', 'field_of_study', 'has_topic')]),\n",
       " Graph(num_nodes={'author': 17764, 'field_of_study': 15719, 'institution': 2276, 'paper': 30053},\n",
       "       num_edges={('author', 'affiliated_with', 'institution'): 40307, ('author', 'writes', 'paper'): 256070, ('paper', 'cites', 'paper'): 25054, ('paper', 'has_topic', 'field_of_study'): 310210},\n",
       "       metagraph=[('author', 'institution', 'affiliated_with'), ('author', 'paper', 'writes'), ('paper', 'paper', 'cites'), ('paper', 'field_of_study', 'has_topic')]),\n",
       " Graph(num_nodes={'author': 17764, 'field_of_study': 15311, 'institution': 2276, 'paper': 27703},\n",
       "       num_edges={('author', 'affiliated_with', 'institution'): 40307, ('author', 'writes', 'paper'): 235822, ('paper', 'cites', 'paper'): 22423, ('paper', 'has_topic', 'field_of_study'): 281615},\n",
       "       metagraph=[('author', 'institution', 'affiliated_with'), ('author', 'paper', 'writes'), ('paper', 'paper', 'cites'), ('paper', 'field_of_study', 'has_topic')]),\n",
       " Graph(num_nodes={'author': 17764, 'field_of_study': 14353, 'institution': 2276, 'paper': 26588},\n",
       "       num_edges={('author', 'affiliated_with', 'institution'): 40307, ('author', 'writes', 'paper'): 315154, ('paper', 'cites', 'paper'): 23017, ('paper', 'has_topic', 'field_of_study'): 258168},\n",
       "       metagraph=[('author', 'institution', 'affiliated_with'), ('author', 'paper', 'writes'), ('paper', 'paper', 'cites'), ('paper', 'field_of_study', 'has_topic')]),\n",
       " Graph(num_nodes={'author': 17764, 'field_of_study': 11933, 'institution': 2276, 'paper': 18977},\n",
       "       num_edges={('author', 'affiliated_with', 'institution'): 40307, ('author', 'writes', 'paper'): 191079, ('paper', 'cites', 'paper'): 16627, ('paper', 'has_topic', 'field_of_study'): 177605},\n",
       "       metagraph=[('author', 'institution', 'affiliated_with'), ('author', 'paper', 'writes'), ('paper', 'paper', 'cites'), ('paper', 'field_of_study', 'has_topic')])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glist, label_dict = load_graphs('data/ogbn_graphs.bin')\n",
    "glist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 420, ('actor', 'involved_with', 'actor'): 460},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 493, ('actor', 'involved_with', 'actor'): 514},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 559, ('actor', 'involved_with', 'actor'): 594},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 538, ('actor', 'involved_with', 'actor'): 562},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 502, ('actor', 'involved_with', 'actor'): 544},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 528, ('actor', 'involved_with', 'actor'): 582},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 481, ('actor', 'involved_with', 'actor'): 506},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 457, ('actor', 'involved_with', 'actor'): 516},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 506, ('actor', 'involved_with', 'actor'): 584},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 526, ('actor', 'involved_with', 'actor'): 591},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 558, ('actor', 'involved_with', 'actor'): 664},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 629, ('actor', 'involved_with', 'actor'): 745},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 614, ('actor', 'involved_with', 'actor'): 740},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 1173, ('actor', 'involved_with', 'actor'): 1425},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 1420, ('actor', 'involved_with', 'actor'): 1701},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 1633, ('actor', 'involved_with', 'actor'): 1856},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 1950, ('actor', 'involved_with', 'actor'): 2272},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 2078, ('actor', 'involved_with', 'actor'): 2479},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 2196, ('actor', 'involved_with', 'actor'): 2671},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 3009, ('actor', 'involved_with', 'actor'): 3657},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 3669, ('actor', 'involved_with', 'actor'): 4646},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 5477, ('actor', 'involved_with', 'actor'): 7431},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 5830, ('actor', 'involved_with', 'actor'): 7894},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 5849, ('actor', 'involved_with', 'actor'): 8453},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 6330, ('actor', 'involved_with', 'actor'): 8878},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 7244, ('actor', 'involved_with', 'actor'): 9931},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 7335, ('actor', 'involved_with', 'actor'): 9816},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 6320, ('actor', 'involved_with', 'actor'): 8364},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glist, label_dict = load_graphs('graph_data_acled.bin')\n",
    "glist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,  ..., 18619, 18620, 18621])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glist[0].ndata['_ID']['actor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mp2vec\n",
      "generating train, val, test sets \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "        num_edges={('action', 'involved_in_r_t0', 'actor'): 420, ('action', 'involved_in_r_t1', 'actor'): 493, ('actor', 'involved_in_t0', 'action'): 420, ('actor', 'involved_in_t1', 'action'): 493, ('actor', 'involved_with_r_t0', 'actor'): 460, ('actor', 'involved_with_r_t1', 'actor'): 514, ('actor', 'involved_with_t0', 'actor'): 460, ('actor', 'involved_with_t1', 'actor'): 514},\n",
       "        metagraph=[('action', 'actor', 'involved_in_r_t0'), ('action', 'actor', 'involved_in_r_t1'), ('actor', 'action', 'involved_in_t0'), ('actor', 'action', 'involved_in_t1'), ('actor', 'actor', 'involved_with_r_t0'), ('actor', 'actor', 'involved_with_r_t1'), ('actor', 'actor', 'involved_with_t0'), ('actor', 'actor', 'involved_with_t1')])],\n",
       " [(Graph(num_nodes=18622, num_edges=208,\n",
       "         ndata_schemes={}\n",
       "         edata_schemes={}),\n",
       "   Graph(num_nodes=18622, num_edges=208,\n",
       "         ndata_schemes={}\n",
       "         edata_schemes={}))],\n",
       " [Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "        num_edges={('action', 'involved_in_r_t0', 'actor'): 493, ('action', 'involved_in_r_t1', 'actor'): 559, ('actor', 'involved_in_t0', 'action'): 493, ('actor', 'involved_in_t1', 'action'): 559, ('actor', 'involved_with_r_t0', 'actor'): 514, ('actor', 'involved_with_r_t1', 'actor'): 594, ('actor', 'involved_with_t0', 'actor'): 514, ('actor', 'involved_with_t1', 'actor'): 594},\n",
       "        metagraph=[('action', 'actor', 'involved_in_r_t0'), ('action', 'actor', 'involved_in_r_t1'), ('actor', 'action', 'involved_in_t0'), ('actor', 'action', 'involved_in_t1'), ('actor', 'actor', 'involved_with_r_t0'), ('actor', 'actor', 'involved_with_r_t1'), ('actor', 'actor', 'involved_with_t0'), ('actor', 'actor', 'involved_with_t1')])],\n",
       " [(Graph(num_nodes=18622, num_edges=137,\n",
       "         ndata_schemes={}\n",
       "         edata_schemes={}),\n",
       "   Graph(num_nodes=18622, num_edges=137,\n",
       "         ndata_schemes={}\n",
       "         edata_schemes={}))],\n",
       " [Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "        num_edges={('action', 'involved_in_r_t0', 'actor'): 559, ('action', 'involved_in_r_t1', 'actor'): 538, ('actor', 'involved_in_t0', 'action'): 559, ('actor', 'involved_in_t1', 'action'): 538, ('actor', 'involved_with_r_t0', 'actor'): 594, ('actor', 'involved_with_r_t1', 'actor'): 562, ('actor', 'involved_with_t0', 'actor'): 594, ('actor', 'involved_with_t1', 'actor'): 562},\n",
       "        metagraph=[('action', 'actor', 'involved_in_r_t0'), ('action', 'actor', 'involved_in_r_t1'), ('actor', 'action', 'involved_in_t0'), ('actor', 'action', 'involved_in_t1'), ('actor', 'actor', 'involved_with_r_t0'), ('actor', 'actor', 'involved_with_r_t1'), ('actor', 'actor', 'involved_with_t0'), ('actor', 'actor', 'involved_with_t1')])],\n",
       " [(Graph(num_nodes=18622, num_edges=140,\n",
       "         ndata_schemes={}\n",
       "         edata_schemes={}),\n",
       "   Graph(num_nodes=18622, num_edges=140,\n",
       "         ndata_schemes={}\n",
       "         edata_schemes={}))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glist, label_dict = load_graphs('graph_data_acled.bin')\n",
    "# glist, label_dict = load_graphs('data/ogbn_graphs.bin')\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "time_window = 2\n",
    "\n",
    "load_MAG_data_acled(glist[:5], time_window, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,  ..., 18619, 18620, 18621])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glist[0].ndata['_ID']['actor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17764"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glist[0].in_edges(glist[0].nodes('paper'), etype='writes')[0])\n",
    "unique_elements, counts = torch.unique(glist[0].in_edges(glist[0].nodes('paper'), etype='writes')[0], return_counts=True)\n",
    "len(unique_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,  ..., 17761, 17762, 17763])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 28,  4,  ...,  1, 15,  5])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_list = torch.arange(17764)\n",
    "appearances = [1 if element in unique_elements else 0 for element in num_list]\n",
    "# all_at_most_once = all(count <= 1 for count in appearances.values())\n",
    "# all_at_most_once\n",
    "all(appearances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 7559,   456, 15077, 15482, 12199, 10728, 15151, 11295,  1760, 13737,\n",
       "         12193,  3594]),\n",
       " tensor([ 2,  5,  6,  6,  7,  9, 10, 12, 18, 20, 21, 24]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glist[0].in_edges(glist[0].nodes('action'), etype='involved_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,  ..., 17761, 17762, 17763])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glist[0].ndata['_ID']['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glist[0].ndata['_ID']['paper']\n",
    "unique_elements, counts = torch.unique(glist[0].ndata['_ID']['paper'], return_counts=True)\n",
    "has_repeats = (counts > 1).any()\n",
    "has_repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,  ..., 18619, 18620, 18621])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glist[0].ndata['_ID']['actor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glist[0].ndata['_ID']['action']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glist[0].edata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mp2vec\n",
      "a_17764\n",
      "a_17765\n",
      "a_17766\n",
      "a_17767\n",
      "a_17768\n",
      "a_17769\n",
      "a_17770\n",
      "a_17771\n",
      "a_17772\n",
      "a_17773\n",
      "a_17774\n",
      "a_17775\n",
      "a_17776\n",
      "a_17777\n",
      "a_17778\n",
      "a_17779\n",
      "a_17780\n",
      "a_17781\n",
      "a_17782\n",
      "a_17783\n",
      "a_17784\n",
      "a_17785\n",
      "a_17786\n",
      "a_17787\n",
      "a_17788\n",
      "a_17789\n",
      "a_17790\n",
      "a_17791\n",
      "a_17792\n",
      "a_17793\n",
      "a_17794\n",
      "a_17795\n",
      "a_17796\n",
      "a_17797\n",
      "a_17798\n",
      "a_17799\n",
      "a_17800\n",
      "a_17801\n",
      "a_17802\n",
      "a_17803\n",
      "a_17804\n",
      "a_17805\n",
      "a_17806\n",
      "a_17807\n",
      "a_17808\n",
      "a_17809\n",
      "a_17810\n",
      "a_17811\n",
      "a_17812\n",
      "a_17813\n",
      "a_17814\n",
      "a_17815\n",
      "a_17816\n",
      "a_17817\n",
      "a_17818\n",
      "a_17819\n",
      "a_17820\n",
      "a_17821\n",
      "a_17822\n",
      "a_17823\n",
      "a_17824\n",
      "a_17825\n",
      "a_17826\n",
      "a_17827\n",
      "a_17828\n",
      "a_17829\n",
      "a_17830\n",
      "a_17831\n",
      "a_17832\n",
      "a_17833\n",
      "a_17834\n",
      "a_17835\n",
      "a_17836\n",
      "a_17837\n",
      "a_17838\n",
      "a_17839\n",
      "a_17840\n",
      "a_17841\n",
      "a_17842\n",
      "a_17843\n",
      "a_17844\n",
      "a_17845\n",
      "a_17846\n",
      "a_17847\n",
      "a_17848\n",
      "a_17849\n",
      "a_17850\n",
      "a_17851\n",
      "a_17852\n",
      "a_17853\n",
      "a_17854\n",
      "a_17855\n",
      "a_17856\n",
      "a_17857\n",
      "a_17858\n",
      "a_17859\n",
      "a_17860\n",
      "a_17861\n",
      "a_17862\n",
      "a_17863\n",
      "a_17864\n",
      "a_17865\n",
      "a_17866\n",
      "a_17867\n",
      "a_17868\n",
      "a_17869\n",
      "a_17870\n",
      "a_17871\n",
      "a_17872\n",
      "a_17873\n",
      "a_17874\n",
      "a_17875\n",
      "a_17876\n",
      "a_17877\n",
      "a_17878\n",
      "a_17879\n",
      "a_17880\n",
      "a_17881\n",
      "a_17882\n",
      "a_17883\n",
      "a_17884\n",
      "a_17885\n",
      "a_17886\n",
      "a_17887\n",
      "a_17888\n",
      "a_17889\n",
      "a_17890\n",
      "a_17891\n",
      "a_17892\n",
      "a_17893\n",
      "a_17894\n",
      "a_17895\n",
      "a_17896\n",
      "a_17897\n",
      "a_17898\n",
      "a_17899\n",
      "a_17900\n",
      "a_17901\n",
      "a_17902\n",
      "a_17903\n",
      "a_17904\n",
      "a_17905\n",
      "a_17906\n",
      "a_17907\n",
      "a_17908\n",
      "a_17909\n",
      "a_17910\n",
      "a_17911\n",
      "a_17912\n",
      "a_17913\n",
      "a_17914\n",
      "a_17915\n",
      "a_17916\n",
      "a_17917\n",
      "a_17918\n",
      "a_17919\n",
      "a_17920\n",
      "a_17921\n",
      "a_17922\n",
      "a_17923\n",
      "a_17924\n",
      "a_17925\n",
      "a_17926\n",
      "a_17927\n",
      "a_17928\n",
      "a_17929\n",
      "a_17930\n",
      "a_17931\n",
      "a_17932\n",
      "a_17933\n",
      "a_17934\n",
      "a_17935\n",
      "a_17936\n",
      "a_17937\n",
      "a_17938\n",
      "a_17939\n",
      "a_17940\n",
      "a_17941\n",
      "a_17942\n",
      "a_17943\n",
      "a_17944\n",
      "a_17945\n",
      "a_17946\n",
      "a_17947\n",
      "a_17948\n",
      "a_17949\n",
      "a_17950\n",
      "a_17951\n",
      "a_17952\n",
      "a_17953\n",
      "a_17954\n",
      "a_17955\n",
      "a_17956\n",
      "a_17957\n",
      "a_17958\n",
      "a_17959\n",
      "a_17960\n",
      "a_17961\n",
      "a_17962\n",
      "a_17963\n",
      "a_17964\n",
      "a_17965\n",
      "a_17966\n",
      "a_17967\n",
      "a_17968\n",
      "a_17969\n",
      "a_17970\n",
      "a_17971\n",
      "a_17972\n",
      "a_17973\n",
      "a_17974\n",
      "a_17975\n",
      "a_17976\n",
      "a_17977\n",
      "a_17978\n",
      "a_17979\n",
      "a_17980\n",
      "a_17981\n",
      "a_17982\n",
      "a_17983\n",
      "a_17984\n",
      "a_17985\n",
      "a_17986\n",
      "a_17987\n",
      "a_17988\n",
      "a_17989\n",
      "a_17990\n",
      "a_17991\n",
      "a_17992\n",
      "a_17993\n",
      "a_17994\n",
      "a_17995\n",
      "a_17996\n",
      "a_17997\n",
      "a_17998\n",
      "a_17999\n",
      "a_18000\n",
      "a_18001\n",
      "a_18002\n",
      "a_18003\n",
      "a_18004\n",
      "a_18005\n",
      "a_18006\n",
      "a_18007\n",
      "a_18008\n",
      "a_18009\n",
      "a_18010\n",
      "a_18011\n",
      "a_18012\n",
      "a_18013\n",
      "a_18014\n",
      "a_18015\n",
      "a_18016\n",
      "a_18017\n",
      "a_18018\n",
      "a_18019\n",
      "a_18020\n",
      "a_18021\n",
      "a_18022\n",
      "a_18023\n",
      "a_18024\n",
      "a_18025\n",
      "a_18026\n",
      "a_18027\n",
      "a_18028\n",
      "a_18029\n",
      "a_18030\n",
      "a_18031\n",
      "a_18032\n",
      "a_18033\n",
      "a_18034\n",
      "a_18035\n",
      "a_18036\n",
      "a_18037\n",
      "a_18038\n",
      "a_18039\n",
      "a_18040\n",
      "a_18041\n",
      "a_18042\n",
      "a_18043\n",
      "a_18044\n",
      "a_18045\n",
      "a_18046\n",
      "a_18047\n",
      "a_18048\n",
      "a_18049\n",
      "a_18050\n",
      "a_18051\n",
      "a_18052\n",
      "a_18053\n",
      "a_18054\n",
      "a_18055\n",
      "a_18056\n",
      "a_18057\n",
      "a_18058\n",
      "a_18059\n",
      "a_18060\n",
      "a_18061\n",
      "a_18062\n",
      "a_18063\n",
      "a_18064\n",
      "a_18065\n",
      "a_18066\n",
      "a_18067\n",
      "a_18068\n",
      "a_18069\n",
      "a_18070\n",
      "a_18071\n",
      "a_18072\n",
      "a_18073\n",
      "a_18074\n",
      "a_18075\n",
      "a_18076\n",
      "a_18077\n",
      "a_18078\n",
      "a_18079\n",
      "a_18080\n",
      "a_18081\n",
      "a_18082\n",
      "a_18083\n",
      "a_18084\n",
      "a_18085\n",
      "a_18086\n",
      "a_18087\n",
      "a_18088\n",
      "a_18089\n",
      "a_18090\n",
      "a_18091\n",
      "a_18092\n",
      "a_18093\n",
      "a_18094\n",
      "a_18095\n",
      "a_18096\n",
      "a_18097\n",
      "a_18098\n",
      "a_18099\n",
      "a_18100\n",
      "a_18101\n",
      "a_18102\n",
      "a_18103\n",
      "a_18104\n",
      "a_18105\n",
      "a_18106\n",
      "a_18107\n",
      "a_18108\n",
      "a_18109\n",
      "a_18110\n",
      "a_18111\n",
      "a_18112\n",
      "a_18113\n",
      "a_18114\n",
      "a_18115\n",
      "a_18116\n",
      "a_18117\n",
      "a_18118\n",
      "a_18119\n",
      "a_18120\n",
      "a_18121\n",
      "a_18122\n",
      "a_18123\n",
      "a_18124\n",
      "a_18125\n",
      "a_18126\n",
      "a_18127\n",
      "a_18128\n",
      "a_18129\n",
      "a_18130\n",
      "a_18131\n",
      "a_18132\n",
      "a_18133\n",
      "a_18134\n",
      "a_18135\n",
      "a_18136\n",
      "a_18137\n",
      "a_18138\n",
      "a_18139\n",
      "a_18140\n",
      "a_18141\n",
      "a_18142\n",
      "a_18143\n",
      "a_18144\n",
      "a_18145\n",
      "a_18146\n",
      "a_18147\n",
      "a_18148\n",
      "a_18149\n",
      "a_18150\n",
      "a_18151\n",
      "a_18152\n",
      "a_18153\n",
      "a_18154\n",
      "a_18155\n",
      "a_18156\n",
      "a_18157\n",
      "a_18158\n",
      "a_18159\n",
      "a_18160\n",
      "a_18161\n",
      "a_18162\n",
      "a_18163\n",
      "a_18164\n",
      "a_18165\n",
      "a_18166\n",
      "a_18167\n",
      "a_18168\n",
      "a_18169\n",
      "a_18170\n",
      "a_18171\n",
      "a_18172\n",
      "a_18173\n",
      "a_18174\n",
      "a_18175\n",
      "a_18176\n",
      "a_18177\n",
      "a_18178\n",
      "a_18179\n",
      "a_18180\n",
      "a_18181\n",
      "a_18182\n",
      "a_18183\n",
      "a_18184\n",
      "a_18185\n",
      "a_18186\n",
      "a_18187\n",
      "a_18188\n",
      "a_18189\n",
      "a_18190\n",
      "a_18191\n",
      "a_18192\n",
      "a_18193\n",
      "a_18194\n",
      "a_18195\n",
      "a_18196\n",
      "a_18197\n",
      "a_18198\n",
      "a_18199\n",
      "a_18200\n",
      "a_18201\n",
      "a_18202\n",
      "a_18203\n",
      "a_18204\n",
      "a_18205\n",
      "a_18206\n",
      "a_18207\n",
      "a_18208\n",
      "a_18209\n",
      "a_18210\n",
      "a_18211\n",
      "a_18212\n",
      "a_18213\n",
      "a_18214\n",
      "a_18215\n",
      "a_18216\n",
      "a_18217\n",
      "a_18218\n",
      "a_18219\n",
      "a_18220\n",
      "a_18221\n",
      "a_18222\n",
      "a_18223\n",
      "a_18224\n",
      "a_18225\n",
      "a_18226\n",
      "a_18227\n",
      "a_18228\n",
      "a_18229\n",
      "a_18230\n",
      "a_18231\n",
      "a_18232\n",
      "a_18233\n",
      "a_18234\n",
      "a_18235\n",
      "a_18236\n",
      "a_18237\n",
      "a_18238\n",
      "a_18239\n",
      "a_18240\n",
      "a_18241\n",
      "a_18242\n",
      "a_18243\n",
      "a_18244\n",
      "a_18245\n",
      "a_18246\n",
      "a_18247\n",
      "a_18248\n",
      "a_18249\n",
      "a_18250\n",
      "a_18251\n",
      "a_18252\n",
      "a_18253\n",
      "a_18254\n",
      "a_18255\n",
      "a_18256\n",
      "a_18257\n",
      "a_18258\n",
      "a_18259\n",
      "a_18260\n",
      "a_18261\n",
      "a_18262\n",
      "a_18263\n",
      "a_18264\n",
      "a_18265\n",
      "a_18266\n",
      "a_18267\n",
      "a_18268\n",
      "a_18269\n",
      "a_18270\n",
      "a_18271\n",
      "a_18272\n",
      "a_18273\n",
      "a_18274\n",
      "a_18275\n",
      "a_18276\n",
      "a_18277\n",
      "a_18278\n",
      "a_18279\n",
      "a_18280\n",
      "a_18281\n",
      "a_18282\n",
      "a_18283\n",
      "a_18284\n",
      "a_18285\n",
      "a_18286\n",
      "a_18287\n",
      "a_18288\n",
      "a_18289\n",
      "a_18290\n",
      "a_18291\n",
      "a_18292\n",
      "a_18293\n",
      "a_18294\n",
      "a_18295\n",
      "a_18296\n",
      "a_18297\n",
      "a_18298\n",
      "a_18299\n",
      "a_18300\n",
      "a_18301\n",
      "a_18302\n",
      "a_18303\n",
      "a_18304\n",
      "a_18305\n",
      "a_18306\n",
      "a_18307\n",
      "a_18308\n",
      "a_18309\n",
      "a_18310\n",
      "a_18311\n",
      "a_18312\n",
      "a_18313\n",
      "a_18314\n",
      "a_18315\n",
      "a_18316\n",
      "a_18317\n",
      "a_18318\n",
      "a_18319\n",
      "a_18320\n",
      "a_18321\n",
      "a_18322\n",
      "a_18323\n",
      "a_18324\n",
      "a_18325\n",
      "a_18326\n",
      "a_18327\n",
      "a_18328\n",
      "a_18329\n",
      "a_18330\n",
      "a_18331\n",
      "a_18332\n",
      "a_18333\n",
      "a_18334\n",
      "a_18335\n",
      "a_18336\n",
      "a_18337\n",
      "a_18338\n",
      "a_18339\n",
      "a_18340\n",
      "a_18341\n",
      "a_18342\n",
      "a_18343\n",
      "a_18344\n",
      "a_18345\n",
      "a_18346\n",
      "a_18347\n",
      "a_18348\n",
      "a_18349\n",
      "a_18350\n",
      "a_18351\n",
      "a_18352\n",
      "a_18353\n",
      "a_18354\n",
      "a_18355\n",
      "a_18356\n",
      "a_18357\n",
      "a_18358\n",
      "a_18359\n",
      "a_18360\n",
      "a_18361\n",
      "a_18362\n",
      "a_18363\n",
      "a_18364\n",
      "a_18365\n",
      "a_18366\n",
      "a_18367\n",
      "a_18368\n",
      "a_18369\n",
      "a_18370\n",
      "a_18371\n",
      "a_18372\n",
      "a_18373\n",
      "a_18374\n",
      "a_18375\n",
      "a_18376\n",
      "a_18377\n",
      "a_18378\n",
      "a_18379\n",
      "a_18380\n",
      "a_18381\n",
      "a_18382\n",
      "a_18383\n",
      "a_18384\n",
      "a_18385\n",
      "a_18386\n",
      "a_18387\n",
      "a_18388\n",
      "a_18389\n",
      "a_18390\n",
      "a_18391\n",
      "a_18392\n",
      "a_18393\n",
      "a_18394\n",
      "a_18395\n",
      "a_18396\n",
      "a_18397\n",
      "a_18398\n",
      "a_18399\n",
      "a_18400\n",
      "a_18401\n",
      "a_18402\n",
      "a_18403\n",
      "a_18404\n",
      "a_18405\n",
      "a_18406\n",
      "a_18407\n",
      "a_18408\n",
      "a_18409\n",
      "a_18410\n",
      "a_18411\n",
      "a_18412\n",
      "a_18413\n",
      "a_18414\n",
      "a_18415\n",
      "a_18416\n",
      "a_18417\n",
      "a_18418\n",
      "a_18419\n",
      "a_18420\n",
      "a_18421\n",
      "a_18422\n",
      "a_18423\n",
      "a_18424\n",
      "a_18425\n",
      "a_18426\n",
      "a_18427\n",
      "a_18428\n",
      "a_18429\n",
      "a_18430\n",
      "a_18431\n",
      "a_18432\n",
      "a_18433\n",
      "a_18434\n",
      "a_18435\n",
      "a_18436\n",
      "a_18437\n",
      "a_18438\n",
      "a_18439\n",
      "a_18440\n",
      "a_18441\n",
      "a_18442\n",
      "a_18443\n",
      "a_18444\n",
      "a_18445\n",
      "a_18446\n",
      "a_18447\n",
      "a_18448\n",
      "a_18449\n",
      "a_18450\n",
      "a_18451\n",
      "a_18452\n",
      "a_18453\n",
      "a_18454\n",
      "a_18455\n",
      "a_18456\n",
      "a_18457\n",
      "a_18458\n",
      "a_18459\n",
      "a_18460\n",
      "a_18461\n",
      "a_18462\n",
      "a_18463\n",
      "a_18464\n",
      "a_18465\n",
      "a_18466\n",
      "a_18467\n",
      "a_18468\n",
      "a_18469\n",
      "a_18470\n",
      "a_18471\n",
      "a_18472\n",
      "a_18473\n",
      "a_18474\n",
      "a_18475\n",
      "a_18476\n",
      "a_18477\n",
      "a_18478\n",
      "a_18479\n",
      "a_18480\n",
      "a_18481\n",
      "a_18482\n",
      "a_18483\n",
      "a_18484\n",
      "a_18485\n",
      "a_18486\n",
      "a_18487\n",
      "a_18488\n",
      "a_18489\n",
      "a_18490\n",
      "a_18491\n",
      "a_18492\n",
      "a_18493\n",
      "a_18494\n",
      "a_18495\n",
      "a_18496\n",
      "a_18497\n",
      "a_18498\n",
      "a_18499\n",
      "a_18500\n",
      "a_18501\n",
      "a_18502\n",
      "a_18503\n",
      "a_18504\n",
      "a_18505\n",
      "a_18506\n",
      "a_18507\n",
      "a_18508\n",
      "a_18509\n",
      "a_18510\n",
      "a_18511\n",
      "a_18512\n",
      "a_18513\n",
      "a_18514\n",
      "a_18515\n",
      "a_18516\n",
      "a_18517\n",
      "a_18518\n",
      "a_18519\n",
      "a_18520\n",
      "a_18521\n",
      "a_18522\n",
      "a_18523\n",
      "a_18524\n",
      "a_18525\n",
      "a_18526\n",
      "a_18527\n",
      "a_18528\n",
      "a_18529\n",
      "a_18530\n",
      "a_18531\n",
      "a_18532\n",
      "a_18533\n",
      "a_18534\n",
      "a_18535\n",
      "a_18536\n",
      "a_18537\n",
      "a_18538\n",
      "a_18539\n",
      "a_18540\n",
      "a_18541\n",
      "a_18542\n",
      "a_18543\n",
      "a_18544\n",
      "a_18545\n",
      "a_18546\n",
      "a_18547\n",
      "a_18548\n",
      "a_18549\n",
      "a_18550\n",
      "a_18551\n",
      "a_18552\n",
      "a_18553\n",
      "a_18554\n",
      "a_18555\n",
      "a_18556\n",
      "a_18557\n",
      "a_18558\n",
      "a_18559\n",
      "a_18560\n",
      "a_18561\n",
      "a_18562\n",
      "a_18563\n",
      "a_18564\n",
      "a_18565\n",
      "a_18566\n",
      "a_18567\n",
      "a_18568\n",
      "a_18569\n",
      "a_18570\n",
      "a_18571\n",
      "a_18572\n",
      "a_18573\n",
      "a_18574\n",
      "a_18575\n",
      "a_18576\n",
      "a_18577\n",
      "a_18578\n",
      "a_18579\n",
      "a_18580\n",
      "a_18581\n",
      "a_18582\n",
      "a_18583\n",
      "a_18584\n",
      "a_18585\n",
      "a_18586\n",
      "a_18587\n",
      "a_18588\n",
      "a_18589\n",
      "a_18590\n",
      "a_18591\n",
      "a_18592\n",
      "a_18593\n",
      "a_18594\n",
      "a_18595\n",
      "a_18596\n",
      "a_18597\n",
      "a_18598\n",
      "a_18599\n",
      "a_18600\n",
      "a_18601\n",
      "a_18602\n",
      "a_18603\n",
      "a_18604\n",
      "a_18605\n",
      "a_18606\n",
      "a_18607\n",
      "a_18608\n",
      "a_18609\n",
      "a_18610\n",
      "a_18611\n",
      "a_18612\n",
      "a_18613\n",
      "a_18614\n",
      "a_18615\n",
      "a_18616\n",
      "a_18617\n",
      "a_18618\n",
      "a_18619\n",
      "a_18620\n",
      "a_17764\n",
      "a_17765\n",
      "a_17766\n",
      "a_17767\n",
      "a_17768\n",
      "a_17769\n",
      "a_17770\n",
      "a_17771\n",
      "a_17772\n",
      "a_17773\n",
      "a_17774\n",
      "a_17775\n",
      "a_17776\n",
      "a_17777\n",
      "a_17778\n",
      "a_17779\n",
      "a_17780\n",
      "a_17781\n",
      "a_17782\n",
      "a_17783\n",
      "a_17784\n",
      "a_17785\n",
      "a_17786\n",
      "a_17787\n",
      "a_17788\n",
      "a_17789\n",
      "a_17790\n",
      "a_17791\n",
      "a_17792\n",
      "a_17793\n",
      "a_17794\n",
      "a_17795\n",
      "a_17796\n",
      "a_17797\n",
      "a_17798\n",
      "a_17799\n",
      "a_17800\n",
      "a_17801\n",
      "a_17802\n",
      "a_17803\n",
      "a_17804\n",
      "a_17805\n",
      "a_17806\n",
      "a_17807\n",
      "a_17808\n",
      "a_17809\n",
      "a_17810\n",
      "a_17811\n",
      "a_17812\n",
      "a_17813\n",
      "a_17814\n",
      "a_17815\n",
      "a_17816\n",
      "a_17817\n",
      "a_17818\n",
      "a_17819\n",
      "a_17820\n",
      "a_17821\n",
      "a_17822\n",
      "a_17823\n",
      "a_17824\n",
      "a_17825\n",
      "a_17826\n",
      "a_17827\n",
      "a_17828\n",
      "a_17829\n",
      "a_17830\n",
      "a_17831\n",
      "a_17832\n",
      "a_17833\n",
      "a_17834\n",
      "a_17835\n",
      "a_17836\n",
      "a_17837\n",
      "a_17838\n",
      "a_17839\n",
      "a_17840\n",
      "a_17841\n",
      "a_17842\n",
      "a_17843\n",
      "a_17844\n",
      "a_17845\n",
      "a_17846\n",
      "a_17847\n",
      "a_17848\n",
      "a_17849\n",
      "a_17850\n",
      "a_17851\n",
      "a_17852\n",
      "a_17853\n",
      "a_17854\n",
      "a_17855\n",
      "a_17856\n",
      "a_17857\n",
      "a_17858\n",
      "a_17859\n",
      "a_17860\n",
      "a_17861\n",
      "a_17862\n",
      "a_17863\n",
      "a_17864\n",
      "a_17865\n",
      "a_17866\n",
      "a_17867\n",
      "a_17868\n",
      "a_17869\n",
      "a_17870\n",
      "a_17871\n",
      "a_17872\n",
      "a_17873\n",
      "a_17874\n",
      "a_17875\n",
      "a_17876\n",
      "a_17877\n",
      "a_17878\n",
      "a_17879\n",
      "a_17880\n",
      "a_17881\n",
      "a_17882\n",
      "a_17883\n",
      "a_17884\n",
      "a_17885\n",
      "a_17886\n",
      "a_17887\n",
      "a_17888\n",
      "a_17889\n",
      "a_17890\n",
      "a_17891\n",
      "a_17892\n",
      "a_17893\n",
      "a_17894\n",
      "a_17895\n",
      "a_17896\n",
      "a_17897\n",
      "a_17898\n",
      "a_17899\n",
      "a_17900\n",
      "a_17901\n",
      "a_17902\n",
      "a_17903\n",
      "a_17904\n",
      "a_17905\n",
      "a_17906\n",
      "a_17907\n",
      "a_17908\n",
      "a_17909\n",
      "a_17910\n",
      "a_17911\n",
      "a_17912\n",
      "a_17913\n",
      "a_17914\n",
      "a_17915\n",
      "a_17916\n",
      "a_17917\n",
      "a_17918\n",
      "a_17919\n",
      "a_17920\n",
      "a_17921\n",
      "a_17922\n",
      "a_17923\n",
      "a_17924\n",
      "a_17925\n",
      "a_17926\n",
      "a_17927\n",
      "a_17928\n",
      "a_17929\n",
      "a_17930\n",
      "a_17931\n",
      "a_17932\n",
      "a_17933\n",
      "a_17934\n",
      "a_17935\n",
      "a_17936\n",
      "a_17937\n",
      "a_17938\n",
      "a_17939\n",
      "a_17940\n",
      "a_17941\n",
      "a_17942\n",
      "a_17943\n",
      "a_17944\n",
      "a_17945\n",
      "a_17946\n",
      "a_17947\n",
      "a_17948\n",
      "a_17949\n",
      "a_17950\n",
      "a_17951\n",
      "a_17952\n",
      "a_17953\n",
      "a_17954\n",
      "a_17955\n",
      "a_17956\n",
      "a_17957\n",
      "a_17958\n",
      "a_17959\n",
      "a_17960\n",
      "a_17961\n",
      "a_17962\n",
      "a_17963\n",
      "a_17964\n",
      "a_17965\n",
      "a_17966\n",
      "a_17967\n",
      "a_17968\n",
      "a_17969\n",
      "a_17970\n",
      "a_17971\n",
      "a_17972\n",
      "a_17973\n",
      "a_17974\n",
      "a_17975\n",
      "a_17976\n",
      "a_17977\n",
      "a_17978\n",
      "a_17979\n",
      "a_17980\n",
      "a_17981\n",
      "a_17982\n",
      "a_17983\n",
      "a_17984\n",
      "a_17985\n",
      "a_17986\n",
      "a_17987\n",
      "a_17988\n",
      "a_17989\n",
      "a_17990\n",
      "a_17991\n",
      "a_17992\n",
      "a_17993\n",
      "a_17994\n",
      "a_17995\n",
      "a_17996\n",
      "a_17997\n",
      "a_17998\n",
      "a_17999\n",
      "a_18000\n",
      "a_18001\n",
      "a_18002\n",
      "a_18003\n",
      "a_18004\n",
      "a_18005\n",
      "a_18006\n",
      "a_18007\n",
      "a_18008\n",
      "a_18009\n",
      "a_18010\n",
      "a_18011\n",
      "a_18012\n",
      "a_18013\n",
      "a_18014\n",
      "a_18015\n",
      "a_18016\n",
      "a_18017\n",
      "a_18018\n",
      "a_18019\n",
      "a_18020\n",
      "a_18021\n",
      "a_18022\n",
      "a_18023\n",
      "a_18024\n",
      "a_18025\n",
      "a_18026\n",
      "a_18027\n",
      "a_18028\n",
      "a_18029\n",
      "a_18030\n",
      "a_18031\n",
      "a_18032\n",
      "a_18033\n",
      "a_18034\n",
      "a_18035\n",
      "a_18036\n",
      "a_18037\n",
      "a_18038\n",
      "a_18039\n",
      "a_18040\n",
      "a_18041\n",
      "a_18042\n",
      "a_18043\n",
      "a_18044\n",
      "a_18045\n",
      "a_18046\n",
      "a_18047\n",
      "a_18048\n",
      "a_18049\n",
      "a_18050\n",
      "a_18051\n",
      "a_18052\n",
      "a_18053\n",
      "a_18054\n",
      "a_18055\n",
      "a_18056\n",
      "a_18057\n",
      "a_18058\n",
      "a_18059\n",
      "a_18060\n",
      "a_18061\n",
      "a_18062\n",
      "a_18063\n",
      "a_18064\n",
      "a_18065\n",
      "a_18066\n",
      "a_18067\n",
      "a_18068\n",
      "a_18069\n",
      "a_18070\n",
      "a_18071\n",
      "a_18072\n",
      "a_18073\n",
      "a_18074\n",
      "a_18075\n",
      "a_18076\n",
      "a_18077\n",
      "a_18078\n",
      "a_18079\n",
      "a_18080\n",
      "a_18081\n",
      "a_18082\n",
      "a_18083\n",
      "a_18084\n",
      "a_18085\n",
      "a_18086\n",
      "a_18087\n",
      "a_18088\n",
      "a_18089\n",
      "a_18090\n",
      "a_18091\n",
      "a_18092\n",
      "a_18093\n",
      "a_18094\n",
      "a_18095\n",
      "a_18096\n",
      "a_18097\n",
      "a_18098\n",
      "a_18099\n",
      "a_18100\n",
      "a_18101\n",
      "a_18102\n",
      "a_18103\n",
      "a_18104\n",
      "a_18105\n",
      "a_18106\n",
      "a_18107\n",
      "a_18108\n",
      "a_18109\n",
      "a_18110\n",
      "a_18111\n",
      "a_18112\n",
      "a_18113\n",
      "a_18114\n",
      "a_18115\n",
      "a_18116\n",
      "a_18117\n",
      "a_18118\n",
      "a_18119\n",
      "a_18120\n",
      "a_18121\n",
      "a_18122\n",
      "a_18123\n",
      "a_18124\n",
      "a_18125\n",
      "a_18126\n",
      "a_18127\n",
      "a_18128\n",
      "a_18129\n",
      "a_18130\n",
      "a_18131\n",
      "a_18132\n",
      "a_18133\n",
      "a_18134\n",
      "a_18135\n",
      "a_18136\n",
      "a_18137\n",
      "a_18138\n",
      "a_18139\n",
      "a_18140\n",
      "a_18141\n",
      "a_18142\n",
      "a_18143\n",
      "a_18144\n",
      "a_18145\n",
      "a_18146\n",
      "a_18147\n",
      "a_18148\n",
      "a_18149\n",
      "a_18150\n",
      "a_18151\n",
      "a_18152\n",
      "a_18153\n",
      "a_18154\n",
      "a_18155\n",
      "a_18156\n",
      "a_18157\n",
      "a_18158\n",
      "a_18159\n",
      "a_18160\n",
      "a_18161\n",
      "a_18162\n",
      "a_18163\n",
      "a_18164\n",
      "a_18165\n",
      "a_18166\n",
      "a_18167\n",
      "a_18168\n",
      "a_18169\n",
      "a_18170\n",
      "a_18171\n",
      "a_18172\n",
      "a_18173\n",
      "a_18174\n",
      "a_18175\n",
      "a_18176\n",
      "a_18177\n",
      "a_18178\n",
      "a_18179\n",
      "a_18180\n",
      "a_18181\n",
      "a_18182\n",
      "a_18183\n",
      "a_18184\n",
      "a_18185\n",
      "a_18186\n",
      "a_18187\n",
      "a_18188\n",
      "a_18189\n",
      "a_18190\n",
      "a_18191\n",
      "a_18192\n",
      "a_18193\n",
      "a_18194\n",
      "a_18195\n",
      "a_18196\n",
      "a_18197\n",
      "a_18198\n",
      "a_18199\n",
      "a_18200\n",
      "a_18201\n",
      "a_18202\n",
      "a_18203\n",
      "a_18204\n",
      "a_18205\n",
      "a_18206\n",
      "a_18207\n",
      "a_18208\n",
      "a_18209\n",
      "a_18210\n",
      "a_18211\n",
      "a_18212\n",
      "a_18213\n",
      "a_18214\n",
      "a_18215\n",
      "a_18216\n",
      "a_18217\n",
      "a_18218\n",
      "a_18219\n",
      "a_18220\n",
      "a_18221\n",
      "a_18222\n",
      "a_18223\n",
      "a_18224\n",
      "a_18225\n",
      "a_18226\n",
      "a_18227\n",
      "a_18228\n",
      "a_18229\n",
      "a_18230\n",
      "a_18231\n",
      "a_18232\n",
      "a_18233\n",
      "a_18234\n",
      "a_18235\n",
      "a_18236\n",
      "a_18237\n",
      "a_18238\n",
      "a_18239\n",
      "a_18240\n",
      "a_18241\n",
      "a_18242\n",
      "a_18243\n",
      "a_18244\n",
      "a_18245\n",
      "a_18246\n",
      "a_18247\n",
      "a_18248\n",
      "a_18249\n",
      "a_18250\n",
      "a_18251\n",
      "a_18252\n",
      "a_18253\n",
      "a_18254\n",
      "a_18255\n",
      "a_18256\n",
      "a_18257\n",
      "a_18258\n",
      "a_18259\n",
      "a_18260\n",
      "a_18261\n",
      "a_18262\n",
      "a_18263\n",
      "a_18264\n",
      "a_18265\n",
      "a_18266\n",
      "a_18267\n",
      "a_18268\n",
      "a_18269\n",
      "a_18270\n",
      "a_18271\n",
      "a_18272\n",
      "a_18273\n",
      "a_18274\n",
      "a_18275\n",
      "a_18276\n",
      "a_18277\n",
      "a_18278\n",
      "a_18279\n",
      "a_18280\n",
      "a_18281\n",
      "a_18282\n",
      "a_18283\n",
      "a_18284\n",
      "a_18285\n",
      "a_18286\n",
      "a_18287\n",
      "a_18288\n",
      "a_18289\n",
      "a_18290\n",
      "a_18291\n",
      "a_18292\n",
      "a_18293\n",
      "a_18294\n",
      "a_18295\n",
      "a_18296\n",
      "a_18297\n",
      "a_18298\n",
      "a_18299\n",
      "a_18300\n",
      "a_18301\n",
      "a_18302\n",
      "a_18303\n",
      "a_18304\n",
      "a_18305\n",
      "a_18306\n",
      "a_18307\n",
      "a_18308\n",
      "a_18309\n",
      "a_18310\n",
      "a_18311\n",
      "a_18312\n",
      "a_18313\n",
      "a_18314\n",
      "a_18315\n",
      "a_18316\n",
      "a_18317\n",
      "a_18318\n",
      "a_18319\n",
      "a_18320\n",
      "a_18321\n",
      "a_18322\n",
      "a_18323\n",
      "a_18324\n",
      "a_18325\n",
      "a_18326\n",
      "a_18327\n",
      "a_18328\n",
      "a_18329\n",
      "a_18330\n",
      "a_18331\n",
      "a_18332\n",
      "a_18333\n",
      "a_18334\n",
      "a_18335\n",
      "a_18336\n",
      "a_18337\n",
      "a_18338\n",
      "a_18339\n",
      "a_18340\n",
      "a_18341\n",
      "a_18342\n",
      "a_18343\n",
      "a_18344\n",
      "a_18345\n",
      "a_18346\n",
      "a_18347\n",
      "a_18348\n",
      "a_18349\n",
      "a_18350\n",
      "a_18351\n",
      "a_18352\n",
      "a_18353\n",
      "a_18354\n",
      "a_18355\n",
      "a_18356\n",
      "a_18357\n",
      "a_18358\n",
      "a_18359\n",
      "a_18360\n",
      "a_18361\n",
      "a_18362\n",
      "a_18363\n",
      "a_18364\n",
      "a_18365\n",
      "a_18366\n",
      "a_18367\n",
      "a_18368\n",
      "a_18369\n",
      "a_18370\n",
      "a_18371\n",
      "a_18372\n",
      "a_18373\n",
      "a_18374\n",
      "a_18375\n",
      "a_18376\n",
      "a_18377\n",
      "a_18378\n",
      "a_18379\n",
      "a_18380\n",
      "a_18381\n",
      "a_18382\n",
      "a_18383\n",
      "a_18384\n",
      "a_18385\n",
      "a_18386\n",
      "a_18387\n",
      "a_18388\n",
      "a_18389\n",
      "a_18390\n",
      "a_18391\n",
      "a_18392\n",
      "a_18393\n",
      "a_18394\n",
      "a_18395\n",
      "a_18396\n",
      "a_18397\n",
      "a_18398\n",
      "a_18399\n",
      "a_18400\n",
      "a_18401\n",
      "a_18402\n",
      "a_18403\n",
      "a_18404\n",
      "a_18405\n",
      "a_18406\n",
      "a_18407\n",
      "a_18408\n",
      "a_18409\n",
      "a_18410\n",
      "a_18411\n",
      "a_18412\n",
      "a_18413\n",
      "a_18414\n",
      "a_18415\n",
      "a_18416\n",
      "a_18417\n",
      "a_18418\n",
      "a_18419\n",
      "a_18420\n",
      "a_18421\n",
      "a_18422\n",
      "a_18423\n",
      "a_18424\n",
      "a_18425\n",
      "a_18426\n",
      "a_18427\n",
      "a_18428\n",
      "a_18429\n",
      "a_18430\n",
      "a_18431\n",
      "a_18432\n",
      "a_18433\n",
      "a_18434\n",
      "a_18435\n",
      "a_18436\n",
      "a_18437\n",
      "a_18438\n",
      "a_18439\n",
      "a_18440\n",
      "a_18441\n",
      "a_18442\n",
      "a_18443\n",
      "a_18444\n",
      "a_18445\n",
      "a_18446\n",
      "a_18447\n",
      "a_18448\n",
      "a_18449\n",
      "a_18450\n",
      "a_18451\n",
      "a_18452\n",
      "a_18453\n",
      "a_18454\n",
      "a_18455\n",
      "a_18456\n",
      "a_18457\n",
      "a_18458\n",
      "a_18459\n",
      "a_18460\n",
      "a_18461\n",
      "a_18462\n",
      "a_18463\n",
      "a_18464\n",
      "a_18465\n",
      "a_18466\n",
      "a_18467\n",
      "a_18468\n",
      "a_18469\n",
      "a_18470\n",
      "a_18471\n",
      "a_18472\n",
      "a_18473\n",
      "a_18474\n",
      "a_18475\n",
      "a_18476\n",
      "a_18477\n",
      "a_18478\n",
      "a_18479\n",
      "a_18480\n",
      "a_18481\n",
      "a_18482\n",
      "a_18483\n",
      "a_18484\n",
      "a_18485\n",
      "a_18486\n",
      "a_18487\n",
      "a_18488\n",
      "a_18489\n",
      "a_18490\n",
      "a_18491\n",
      "a_18492\n",
      "a_18493\n",
      "a_18494\n",
      "a_18495\n",
      "a_18496\n",
      "a_18497\n",
      "a_18498\n",
      "a_18499\n",
      "a_18500\n",
      "a_18501\n",
      "a_18502\n",
      "a_18503\n",
      "a_18504\n",
      "a_18505\n",
      "a_18506\n",
      "a_18507\n",
      "a_18508\n",
      "a_18509\n",
      "a_18510\n",
      "a_18511\n",
      "a_18512\n",
      "a_18513\n",
      "a_18514\n",
      "a_18515\n",
      "a_18516\n",
      "a_18517\n",
      "a_18518\n",
      "a_18519\n",
      "a_18520\n",
      "a_18521\n",
      "a_18522\n",
      "a_18523\n",
      "a_18524\n",
      "a_18525\n",
      "a_18526\n",
      "a_18527\n",
      "a_18528\n",
      "a_18529\n",
      "a_18530\n",
      "a_18531\n",
      "a_18532\n",
      "a_18533\n",
      "a_18534\n",
      "a_18535\n",
      "a_18536\n",
      "a_18537\n",
      "a_18538\n",
      "a_18539\n",
      "a_18540\n",
      "a_18541\n",
      "a_18542\n",
      "a_18543\n",
      "a_18544\n",
      "a_18545\n",
      "a_18546\n",
      "a_18547\n",
      "a_18548\n",
      "a_18549\n",
      "a_18550\n",
      "a_18551\n",
      "a_18552\n",
      "a_18553\n",
      "a_18554\n",
      "a_18555\n",
      "a_18556\n",
      "a_18557\n",
      "a_18558\n",
      "a_18559\n",
      "a_18560\n",
      "a_18561\n",
      "a_18562\n",
      "a_18563\n",
      "a_18564\n",
      "a_18565\n",
      "a_18566\n",
      "a_18567\n",
      "a_18568\n",
      "a_18569\n",
      "a_18570\n",
      "a_18571\n",
      "a_18572\n",
      "a_18573\n",
      "a_18574\n",
      "a_18575\n",
      "a_18576\n",
      "a_18577\n",
      "a_18578\n",
      "a_18579\n",
      "a_18580\n",
      "a_18581\n",
      "a_18582\n",
      "a_18583\n",
      "a_18584\n",
      "a_18585\n",
      "a_18586\n",
      "a_18587\n",
      "a_18588\n",
      "a_18589\n",
      "a_18590\n",
      "a_18591\n",
      "a_18592\n",
      "a_18593\n",
      "a_18594\n",
      "a_18595\n",
      "a_18596\n",
      "a_18597\n",
      "a_18598\n",
      "a_18599\n",
      "a_18600\n",
      "a_18601\n",
      "a_18602\n",
      "a_18603\n",
      "a_18604\n",
      "a_18605\n",
      "a_18606\n",
      "a_18607\n",
      "a_18608\n",
      "a_18609\n",
      "a_18610\n",
      "a_18611\n",
      "a_18612\n",
      "a_18613\n",
      "a_18614\n",
      "a_18615\n",
      "a_18616\n",
      "a_18617\n",
      "a_18618\n",
      "a_18619\n",
      "a_18620\n",
      "a_17764\n",
      "a_17765\n",
      "a_17766\n",
      "a_17767\n",
      "a_17768\n",
      "a_17769\n",
      "a_17770\n",
      "a_17771\n",
      "a_17772\n",
      "a_17773\n",
      "a_17774\n",
      "a_17775\n",
      "a_17776\n",
      "a_17777\n",
      "a_17778\n",
      "a_17779\n",
      "a_17780\n",
      "a_17781\n",
      "a_17782\n",
      "a_17783\n",
      "a_17784\n",
      "a_17785\n",
      "a_17786\n",
      "a_17787\n",
      "a_17788\n",
      "a_17789\n",
      "a_17790\n",
      "a_17791\n",
      "a_17792\n",
      "a_17793\n",
      "a_17794\n",
      "a_17795\n",
      "a_17796\n",
      "a_17797\n",
      "a_17798\n",
      "a_17799\n",
      "a_17800\n",
      "a_17801\n",
      "a_17802\n",
      "a_17803\n",
      "a_17804\n",
      "a_17805\n",
      "a_17806\n",
      "a_17807\n",
      "a_17808\n",
      "a_17809\n",
      "a_17810\n",
      "a_17811\n",
      "a_17812\n",
      "a_17813\n",
      "a_17814\n",
      "a_17815\n",
      "a_17816\n",
      "a_17817\n",
      "a_17818\n",
      "a_17819\n",
      "a_17820\n",
      "a_17821\n",
      "a_17822\n",
      "a_17823\n",
      "a_17824\n",
      "a_17825\n",
      "a_17826\n",
      "a_17827\n",
      "a_17828\n",
      "a_17829\n",
      "a_17830\n",
      "a_17831\n",
      "a_17832\n",
      "a_17833\n",
      "a_17834\n",
      "a_17835\n",
      "a_17836\n",
      "a_17837\n",
      "a_17838\n",
      "a_17839\n",
      "a_17840\n",
      "a_17841\n",
      "a_17842\n",
      "a_17843\n",
      "a_17844\n",
      "a_17845\n",
      "a_17846\n",
      "a_17847\n",
      "a_17848\n",
      "a_17849\n",
      "a_17850\n",
      "a_17851\n",
      "a_17852\n",
      "a_17853\n",
      "a_17854\n",
      "a_17855\n",
      "a_17856\n",
      "a_17857\n",
      "a_17858\n",
      "a_17859\n",
      "a_17860\n",
      "a_17861\n",
      "a_17862\n",
      "a_17863\n",
      "a_17864\n",
      "a_17865\n",
      "a_17866\n",
      "a_17867\n",
      "a_17868\n",
      "a_17869\n",
      "a_17870\n",
      "a_17871\n",
      "a_17872\n",
      "a_17873\n",
      "a_17874\n",
      "a_17875\n",
      "a_17876\n",
      "a_17877\n",
      "a_17878\n",
      "a_17879\n",
      "a_17880\n",
      "a_17881\n",
      "a_17882\n",
      "a_17883\n",
      "a_17884\n",
      "a_17885\n",
      "a_17886\n",
      "a_17887\n",
      "a_17888\n",
      "a_17889\n",
      "a_17890\n",
      "a_17891\n",
      "a_17892\n",
      "a_17893\n",
      "a_17894\n",
      "a_17895\n",
      "a_17896\n",
      "a_17897\n",
      "a_17898\n",
      "a_17899\n",
      "a_17900\n",
      "a_17901\n",
      "a_17902\n",
      "a_17903\n",
      "a_17904\n",
      "a_17905\n",
      "a_17906\n",
      "a_17907\n",
      "a_17908\n",
      "a_17909\n",
      "a_17910\n",
      "a_17911\n",
      "a_17912\n",
      "a_17913\n",
      "a_17914\n",
      "a_17915\n",
      "a_17916\n",
      "a_17917\n",
      "a_17918\n",
      "a_17919\n",
      "a_17920\n",
      "a_17921\n",
      "a_17922\n",
      "a_17923\n",
      "a_17924\n",
      "a_17925\n",
      "a_17926\n",
      "a_17927\n",
      "a_17928\n",
      "a_17929\n",
      "a_17930\n",
      "a_17931\n",
      "a_17932\n",
      "a_17933\n",
      "a_17934\n",
      "a_17935\n",
      "a_17936\n",
      "a_17937\n",
      "a_17938\n",
      "a_17939\n",
      "a_17940\n",
      "a_17941\n",
      "a_17942\n",
      "a_17943\n",
      "a_17944\n",
      "a_17945\n",
      "a_17946\n",
      "a_17947\n",
      "a_17948\n",
      "a_17949\n",
      "a_17950\n",
      "a_17951\n",
      "a_17952\n",
      "a_17953\n",
      "a_17954\n",
      "a_17955\n",
      "a_17956\n",
      "a_17957\n",
      "a_17958\n",
      "a_17959\n",
      "a_17960\n",
      "a_17961\n",
      "a_17962\n",
      "a_17963\n",
      "a_17964\n",
      "a_17965\n",
      "a_17966\n",
      "a_17967\n",
      "a_17968\n",
      "a_17969\n",
      "a_17970\n",
      "a_17971\n",
      "a_17972\n",
      "a_17973\n",
      "a_17974\n",
      "a_17975\n",
      "a_17976\n",
      "a_17977\n",
      "a_17978\n",
      "a_17979\n",
      "a_17980\n",
      "a_17981\n",
      "a_17982\n",
      "a_17983\n",
      "a_17984\n",
      "a_17985\n",
      "a_17986\n",
      "a_17987\n",
      "a_17988\n",
      "a_17989\n",
      "a_17990\n",
      "a_17991\n",
      "a_17992\n",
      "a_17993\n",
      "a_17994\n",
      "a_17995\n",
      "a_17996\n",
      "a_17997\n",
      "a_17998\n",
      "a_17999\n",
      "a_18000\n",
      "a_18001\n",
      "a_18002\n",
      "a_18003\n",
      "a_18004\n",
      "a_18005\n",
      "a_18006\n",
      "a_18007\n",
      "a_18008\n",
      "a_18009\n",
      "a_18010\n",
      "a_18011\n",
      "a_18012\n",
      "a_18013\n",
      "a_18014\n",
      "a_18015\n",
      "a_18016\n",
      "a_18017\n",
      "a_18018\n",
      "a_18019\n",
      "a_18020\n",
      "a_18021\n",
      "a_18022\n",
      "a_18023\n",
      "a_18024\n",
      "a_18025\n",
      "a_18026\n",
      "a_18027\n",
      "a_18028\n",
      "a_18029\n",
      "a_18030\n",
      "a_18031\n",
      "a_18032\n",
      "a_18033\n",
      "a_18034\n",
      "a_18035\n",
      "a_18036\n",
      "a_18037\n",
      "a_18038\n",
      "a_18039\n",
      "a_18040\n",
      "a_18041\n",
      "a_18042\n",
      "a_18043\n",
      "a_18044\n",
      "a_18045\n",
      "a_18046\n",
      "a_18047\n",
      "a_18048\n",
      "a_18049\n",
      "a_18050\n",
      "a_18051\n",
      "a_18052\n",
      "a_18053\n",
      "a_18054\n",
      "a_18055\n",
      "a_18056\n",
      "a_18057\n",
      "a_18058\n",
      "a_18059\n",
      "a_18060\n",
      "a_18061\n",
      "a_18062\n",
      "a_18063\n",
      "a_18064\n",
      "a_18065\n",
      "a_18066\n",
      "a_18067\n",
      "a_18068\n",
      "a_18069\n",
      "a_18070\n",
      "a_18071\n",
      "a_18072\n",
      "a_18073\n",
      "a_18074\n",
      "a_18075\n",
      "a_18076\n",
      "a_18077\n",
      "a_18078\n",
      "a_18079\n",
      "a_18080\n",
      "a_18081\n",
      "a_18082\n",
      "a_18083\n",
      "a_18084\n",
      "a_18085\n",
      "a_18086\n",
      "a_18087\n",
      "a_18088\n",
      "a_18089\n",
      "a_18090\n",
      "a_18091\n",
      "a_18092\n",
      "a_18093\n",
      "a_18094\n",
      "a_18095\n",
      "a_18096\n",
      "a_18097\n",
      "a_18098\n",
      "a_18099\n",
      "a_18100\n",
      "a_18101\n",
      "a_18102\n",
      "a_18103\n",
      "a_18104\n",
      "a_18105\n",
      "a_18106\n",
      "a_18107\n",
      "a_18108\n",
      "a_18109\n",
      "a_18110\n",
      "a_18111\n",
      "a_18112\n",
      "a_18113\n",
      "a_18114\n",
      "a_18115\n",
      "a_18116\n",
      "a_18117\n",
      "a_18118\n",
      "a_18119\n",
      "a_18120\n",
      "a_18121\n",
      "a_18122\n",
      "a_18123\n",
      "a_18124\n",
      "a_18125\n",
      "a_18126\n",
      "a_18127\n",
      "a_18128\n",
      "a_18129\n",
      "a_18130\n",
      "a_18131\n",
      "a_18132\n",
      "a_18133\n",
      "a_18134\n",
      "a_18135\n",
      "a_18136\n",
      "a_18137\n",
      "a_18138\n",
      "a_18139\n",
      "a_18140\n",
      "a_18141\n",
      "a_18142\n",
      "a_18143\n",
      "a_18144\n",
      "a_18145\n",
      "a_18146\n",
      "a_18147\n",
      "a_18148\n",
      "a_18149\n",
      "a_18150\n",
      "a_18151\n",
      "a_18152\n",
      "a_18153\n",
      "a_18154\n",
      "a_18155\n",
      "a_18156\n",
      "a_18157\n",
      "a_18158\n",
      "a_18159\n",
      "a_18160\n",
      "a_18161\n",
      "a_18162\n",
      "a_18163\n",
      "a_18164\n",
      "a_18165\n",
      "a_18166\n",
      "a_18167\n",
      "a_18168\n",
      "a_18169\n",
      "a_18170\n",
      "a_18171\n",
      "a_18172\n",
      "a_18173\n",
      "a_18174\n",
      "a_18175\n",
      "a_18176\n",
      "a_18177\n",
      "a_18178\n",
      "a_18179\n",
      "a_18180\n",
      "a_18181\n",
      "a_18182\n",
      "a_18183\n",
      "a_18184\n",
      "a_18185\n",
      "a_18186\n",
      "a_18187\n",
      "a_18188\n",
      "a_18189\n",
      "a_18190\n",
      "a_18191\n",
      "a_18192\n",
      "a_18193\n",
      "a_18194\n",
      "a_18195\n",
      "a_18196\n",
      "a_18197\n",
      "a_18198\n",
      "a_18199\n",
      "a_18200\n",
      "a_18201\n",
      "a_18202\n",
      "a_18203\n",
      "a_18204\n",
      "a_18205\n",
      "a_18206\n",
      "a_18207\n",
      "a_18208\n",
      "a_18209\n",
      "a_18210\n",
      "a_18211\n",
      "a_18212\n",
      "a_18213\n",
      "a_18214\n",
      "a_18215\n",
      "a_18216\n",
      "a_18217\n",
      "a_18218\n",
      "a_18219\n",
      "a_18220\n",
      "a_18221\n",
      "a_18222\n",
      "a_18223\n",
      "a_18224\n",
      "a_18225\n",
      "a_18226\n",
      "a_18227\n",
      "a_18228\n",
      "a_18229\n",
      "a_18230\n",
      "a_18231\n",
      "a_18232\n",
      "a_18233\n",
      "a_18234\n",
      "a_18235\n",
      "a_18236\n",
      "a_18237\n",
      "a_18238\n",
      "a_18239\n",
      "a_18240\n",
      "a_18241\n",
      "a_18242\n",
      "a_18243\n",
      "a_18244\n",
      "a_18245\n",
      "a_18246\n",
      "a_18247\n",
      "a_18248\n",
      "a_18249\n",
      "a_18250\n",
      "a_18251\n",
      "a_18252\n",
      "a_18253\n",
      "a_18254\n",
      "a_18255\n",
      "a_18256\n",
      "a_18257\n",
      "a_18258\n",
      "a_18259\n",
      "a_18260\n",
      "a_18261\n",
      "a_18262\n",
      "a_18263\n",
      "a_18264\n",
      "a_18265\n",
      "a_18266\n",
      "a_18267\n",
      "a_18268\n",
      "a_18269\n",
      "a_18270\n",
      "a_18271\n",
      "a_18272\n",
      "a_18273\n",
      "a_18274\n",
      "a_18275\n",
      "a_18276\n",
      "a_18277\n",
      "a_18278\n",
      "a_18279\n",
      "a_18280\n",
      "a_18281\n",
      "a_18282\n",
      "a_18283\n",
      "a_18284\n",
      "a_18285\n",
      "a_18286\n",
      "a_18287\n",
      "a_18288\n",
      "a_18289\n",
      "a_18290\n",
      "a_18291\n",
      "a_18292\n",
      "a_18293\n",
      "a_18294\n",
      "a_18295\n",
      "a_18296\n",
      "a_18297\n",
      "a_18298\n",
      "a_18299\n",
      "a_18300\n",
      "a_18301\n",
      "a_18302\n",
      "a_18303\n",
      "a_18304\n",
      "a_18305\n",
      "a_18306\n",
      "a_18307\n",
      "a_18308\n",
      "a_18309\n",
      "a_18310\n",
      "a_18311\n",
      "a_18312\n",
      "a_18313\n",
      "a_18314\n",
      "a_18315\n",
      "a_18316\n",
      "a_18317\n",
      "a_18318\n",
      "a_18319\n",
      "a_18320\n",
      "a_18321\n",
      "a_18322\n",
      "a_18323\n",
      "a_18324\n",
      "a_18325\n",
      "a_18326\n",
      "a_18327\n",
      "a_18328\n",
      "a_18329\n",
      "a_18330\n",
      "a_18331\n",
      "a_18332\n",
      "a_18333\n",
      "a_18334\n",
      "a_18335\n",
      "a_18336\n",
      "a_18337\n",
      "a_18338\n",
      "a_18339\n",
      "a_18340\n",
      "a_18341\n",
      "a_18342\n",
      "a_18343\n",
      "a_18344\n",
      "a_18345\n",
      "a_18346\n",
      "a_18347\n",
      "a_18348\n",
      "a_18349\n",
      "a_18350\n",
      "a_18351\n",
      "a_18352\n",
      "a_18353\n",
      "a_18354\n",
      "a_18355\n",
      "a_18356\n",
      "a_18357\n",
      "a_18358\n",
      "a_18359\n",
      "a_18360\n",
      "a_18361\n",
      "a_18362\n",
      "a_18363\n",
      "a_18364\n",
      "a_18365\n",
      "a_18366\n",
      "a_18367\n",
      "a_18368\n",
      "a_18369\n",
      "a_18370\n",
      "a_18371\n",
      "a_18372\n",
      "a_18373\n",
      "a_18374\n",
      "a_18375\n",
      "a_18376\n",
      "a_18377\n",
      "a_18378\n",
      "a_18379\n",
      "a_18380\n",
      "a_18381\n",
      "a_18382\n",
      "a_18383\n",
      "a_18384\n",
      "a_18385\n",
      "a_18386\n",
      "a_18387\n",
      "a_18388\n",
      "a_18389\n",
      "a_18390\n",
      "a_18391\n",
      "a_18392\n",
      "a_18393\n",
      "a_18394\n",
      "a_18395\n",
      "a_18396\n",
      "a_18397\n",
      "a_18398\n",
      "a_18399\n",
      "a_18400\n",
      "a_18401\n",
      "a_18402\n",
      "a_18403\n",
      "a_18404\n",
      "a_18405\n",
      "a_18406\n",
      "a_18407\n",
      "a_18408\n",
      "a_18409\n",
      "a_18410\n",
      "a_18411\n",
      "a_18412\n",
      "a_18413\n",
      "a_18414\n",
      "a_18415\n",
      "a_18416\n",
      "a_18417\n",
      "a_18418\n",
      "a_18419\n",
      "a_18420\n",
      "a_18421\n",
      "a_18422\n",
      "a_18423\n",
      "a_18424\n",
      "a_18425\n",
      "a_18426\n",
      "a_18427\n",
      "a_18428\n",
      "a_18429\n",
      "a_18430\n",
      "a_18431\n",
      "a_18432\n",
      "a_18433\n",
      "a_18434\n",
      "a_18435\n",
      "a_18436\n",
      "a_18437\n",
      "a_18438\n",
      "a_18439\n",
      "a_18440\n",
      "a_18441\n",
      "a_18442\n",
      "a_18443\n",
      "a_18444\n",
      "a_18445\n",
      "a_18446\n",
      "a_18447\n",
      "a_18448\n",
      "a_18449\n",
      "a_18450\n",
      "a_18451\n",
      "a_18452\n",
      "a_18453\n",
      "a_18454\n",
      "a_18455\n",
      "a_18456\n",
      "a_18457\n",
      "a_18458\n",
      "a_18459\n",
      "a_18460\n",
      "a_18461\n",
      "a_18462\n",
      "a_18463\n",
      "a_18464\n",
      "a_18465\n",
      "a_18466\n",
      "a_18467\n",
      "a_18468\n",
      "a_18469\n",
      "a_18470\n",
      "a_18471\n",
      "a_18472\n",
      "a_18473\n",
      "a_18474\n",
      "a_18475\n",
      "a_18476\n",
      "a_18477\n",
      "a_18478\n",
      "a_18479\n",
      "a_18480\n",
      "a_18481\n",
      "a_18482\n",
      "a_18483\n",
      "a_18484\n",
      "a_18485\n",
      "a_18486\n",
      "a_18487\n",
      "a_18488\n",
      "a_18489\n",
      "a_18490\n",
      "a_18491\n",
      "a_18492\n",
      "a_18493\n",
      "a_18494\n",
      "a_18495\n",
      "a_18496\n",
      "a_18497\n",
      "a_18498\n",
      "a_18499\n",
      "a_18500\n",
      "a_18501\n",
      "a_18502\n",
      "a_18503\n",
      "a_18504\n",
      "a_18505\n",
      "a_18506\n",
      "a_18507\n",
      "a_18508\n",
      "a_18509\n",
      "a_18510\n",
      "a_18511\n",
      "a_18512\n",
      "a_18513\n",
      "a_18514\n",
      "a_18515\n",
      "a_18516\n",
      "a_18517\n",
      "a_18518\n",
      "a_18519\n",
      "a_18520\n",
      "a_18521\n",
      "a_18522\n",
      "a_18523\n",
      "a_18524\n",
      "a_18525\n",
      "a_18526\n",
      "a_18527\n",
      "a_18528\n",
      "a_18529\n",
      "a_18530\n",
      "a_18531\n",
      "a_18532\n",
      "a_18533\n",
      "a_18534\n",
      "a_18535\n",
      "a_18536\n",
      "a_18537\n",
      "a_18538\n",
      "a_18539\n",
      "a_18540\n",
      "a_18541\n",
      "a_18542\n",
      "a_18543\n",
      "a_18544\n",
      "a_18545\n",
      "a_18546\n",
      "a_18547\n",
      "a_18548\n",
      "a_18549\n",
      "a_18550\n",
      "a_18551\n",
      "a_18552\n",
      "a_18553\n",
      "a_18554\n",
      "a_18555\n",
      "a_18556\n",
      "a_18557\n",
      "a_18558\n",
      "a_18559\n",
      "a_18560\n",
      "a_18561\n",
      "a_18562\n",
      "a_18563\n",
      "a_18564\n",
      "a_18565\n",
      "a_18566\n",
      "a_18567\n",
      "a_18568\n",
      "a_18569\n",
      "a_18570\n",
      "a_18571\n",
      "a_18572\n",
      "a_18573\n",
      "a_18574\n",
      "a_18575\n",
      "a_18576\n",
      "a_18577\n",
      "a_18578\n",
      "a_18579\n",
      "a_18580\n",
      "a_18581\n",
      "a_18582\n",
      "a_18583\n",
      "a_18584\n",
      "a_18585\n",
      "a_18586\n",
      "a_18587\n",
      "a_18588\n",
      "a_18589\n",
      "a_18590\n",
      "a_18591\n",
      "a_18592\n",
      "a_18593\n",
      "a_18594\n",
      "a_18595\n",
      "a_18596\n",
      "a_18597\n",
      "a_18598\n",
      "a_18599\n",
      "a_18600\n",
      "a_18601\n",
      "a_18602\n",
      "a_18603\n",
      "a_18604\n",
      "a_18605\n",
      "a_18606\n",
      "a_18607\n",
      "a_18608\n",
      "a_18609\n",
      "a_18610\n",
      "a_18611\n",
      "a_18612\n",
      "a_18613\n",
      "a_18614\n",
      "a_18615\n",
      "a_18616\n",
      "a_18617\n",
      "a_18618\n",
      "a_18619\n",
      "a_18620\n",
      "a_17764\n",
      "a_17765\n",
      "a_17766\n",
      "a_17767\n",
      "a_17768\n",
      "a_17769\n",
      "a_17770\n",
      "a_17771\n",
      "a_17772\n",
      "a_17773\n",
      "a_17774\n",
      "a_17775\n",
      "a_17776\n",
      "a_17777\n",
      "a_17778\n",
      "a_17779\n",
      "a_17780\n",
      "a_17781\n",
      "a_17782\n",
      "a_17783\n",
      "a_17784\n",
      "a_17785\n",
      "a_17786\n",
      "a_17787\n",
      "a_17788\n",
      "a_17789\n",
      "a_17790\n",
      "a_17791\n",
      "a_17792\n",
      "a_17793\n",
      "a_17794\n",
      "a_17795\n",
      "a_17796\n",
      "a_17797\n",
      "a_17798\n",
      "a_17799\n",
      "a_17800\n",
      "a_17801\n",
      "a_17802\n",
      "a_17803\n",
      "a_17804\n",
      "a_17805\n",
      "a_17806\n",
      "a_17807\n",
      "a_17808\n",
      "a_17809\n",
      "a_17810\n",
      "a_17811\n",
      "a_17812\n",
      "a_17813\n",
      "a_17814\n",
      "a_17815\n",
      "a_17816\n",
      "a_17817\n",
      "a_17818\n",
      "a_17819\n",
      "a_17820\n",
      "a_17821\n",
      "a_17822\n",
      "a_17823\n",
      "a_17824\n",
      "a_17825\n",
      "a_17826\n",
      "a_17827\n",
      "a_17828\n",
      "a_17829\n",
      "a_17830\n",
      "a_17831\n",
      "a_17832\n",
      "a_17833\n",
      "a_17834\n",
      "a_17835\n",
      "a_17836\n",
      "a_17837\n",
      "a_17838\n",
      "a_17839\n",
      "a_17840\n",
      "a_17841\n",
      "a_17842\n",
      "a_17843\n",
      "a_17844\n",
      "a_17845\n",
      "a_17846\n",
      "a_17847\n",
      "a_17848\n",
      "a_17849\n",
      "a_17850\n",
      "a_17851\n",
      "a_17852\n",
      "a_17853\n",
      "a_17854\n",
      "a_17855\n",
      "a_17856\n",
      "a_17857\n",
      "a_17858\n",
      "a_17859\n",
      "a_17860\n",
      "a_17861\n",
      "a_17862\n",
      "a_17863\n",
      "a_17864\n",
      "a_17865\n",
      "a_17866\n",
      "a_17867\n",
      "a_17868\n",
      "a_17869\n",
      "a_17870\n",
      "a_17871\n",
      "a_17872\n",
      "a_17873\n",
      "a_17874\n",
      "a_17875\n",
      "a_17876\n",
      "a_17877\n",
      "a_17878\n",
      "a_17879\n",
      "a_17880\n",
      "a_17881\n",
      "a_17882\n",
      "a_17883\n",
      "a_17884\n",
      "a_17885\n",
      "a_17886\n",
      "a_17887\n",
      "a_17888\n",
      "a_17889\n",
      "a_17890\n",
      "a_17891\n",
      "a_17892\n",
      "a_17893\n",
      "a_17894\n",
      "a_17895\n",
      "a_17896\n",
      "a_17897\n",
      "a_17898\n",
      "a_17899\n",
      "a_17900\n",
      "a_17901\n",
      "a_17902\n",
      "a_17903\n",
      "a_17904\n",
      "a_17905\n",
      "a_17906\n",
      "a_17907\n",
      "a_17908\n",
      "a_17909\n",
      "a_17910\n",
      "a_17911\n",
      "a_17912\n",
      "a_17913\n",
      "a_17914\n",
      "a_17915\n",
      "a_17916\n",
      "a_17917\n",
      "a_17918\n",
      "a_17919\n",
      "a_17920\n",
      "a_17921\n",
      "a_17922\n",
      "a_17923\n",
      "a_17924\n",
      "a_17925\n",
      "a_17926\n",
      "a_17927\n",
      "a_17928\n",
      "a_17929\n",
      "a_17930\n",
      "a_17931\n",
      "a_17932\n",
      "a_17933\n",
      "a_17934\n",
      "a_17935\n",
      "a_17936\n",
      "a_17937\n",
      "a_17938\n",
      "a_17939\n",
      "a_17940\n",
      "a_17941\n",
      "a_17942\n",
      "a_17943\n",
      "a_17944\n",
      "a_17945\n",
      "a_17946\n",
      "a_17947\n",
      "a_17948\n",
      "a_17949\n",
      "a_17950\n",
      "a_17951\n",
      "a_17952\n",
      "a_17953\n",
      "a_17954\n",
      "a_17955\n",
      "a_17956\n",
      "a_17957\n",
      "a_17958\n",
      "a_17959\n",
      "a_17960\n",
      "a_17961\n",
      "a_17962\n",
      "a_17963\n",
      "a_17964\n",
      "a_17965\n",
      "a_17966\n",
      "a_17967\n",
      "a_17968\n",
      "a_17969\n",
      "a_17970\n",
      "a_17971\n",
      "a_17972\n",
      "a_17973\n",
      "a_17974\n",
      "a_17975\n",
      "a_17976\n",
      "a_17977\n",
      "a_17978\n",
      "a_17979\n",
      "a_17980\n",
      "a_17981\n",
      "a_17982\n",
      "a_17983\n",
      "a_17984\n",
      "a_17985\n",
      "a_17986\n",
      "a_17987\n",
      "a_17988\n",
      "a_17989\n",
      "a_17990\n",
      "a_17991\n",
      "a_17992\n",
      "a_17993\n",
      "a_17994\n",
      "a_17995\n",
      "a_17996\n",
      "a_17997\n",
      "a_17998\n",
      "a_17999\n",
      "a_18000\n",
      "a_18001\n",
      "a_18002\n",
      "a_18003\n",
      "a_18004\n",
      "a_18005\n",
      "a_18006\n",
      "a_18007\n",
      "a_18008\n",
      "a_18009\n",
      "a_18010\n",
      "a_18011\n",
      "a_18012\n",
      "a_18013\n",
      "a_18014\n",
      "a_18015\n",
      "a_18016\n",
      "a_18017\n",
      "a_18018\n",
      "a_18019\n",
      "a_18020\n",
      "a_18021\n",
      "a_18022\n",
      "a_18023\n",
      "a_18024\n",
      "a_18025\n",
      "a_18026\n",
      "a_18027\n",
      "a_18028\n",
      "a_18029\n",
      "a_18030\n",
      "a_18031\n",
      "a_18032\n",
      "a_18033\n",
      "a_18034\n",
      "a_18035\n",
      "a_18036\n",
      "a_18037\n",
      "a_18038\n",
      "a_18039\n",
      "a_18040\n",
      "a_18041\n",
      "a_18042\n",
      "a_18043\n",
      "a_18044\n",
      "a_18045\n",
      "a_18046\n",
      "a_18047\n",
      "a_18048\n",
      "a_18049\n",
      "a_18050\n",
      "a_18051\n",
      "a_18052\n",
      "a_18053\n",
      "a_18054\n",
      "a_18055\n",
      "a_18056\n",
      "a_18057\n",
      "a_18058\n",
      "a_18059\n",
      "a_18060\n",
      "a_18061\n",
      "a_18062\n",
      "a_18063\n",
      "a_18064\n",
      "a_18065\n",
      "a_18066\n",
      "a_18067\n",
      "a_18068\n",
      "a_18069\n",
      "a_18070\n",
      "a_18071\n",
      "a_18072\n",
      "a_18073\n",
      "a_18074\n",
      "a_18075\n",
      "a_18076\n",
      "a_18077\n",
      "a_18078\n",
      "a_18079\n",
      "a_18080\n",
      "a_18081\n",
      "a_18082\n",
      "a_18083\n",
      "a_18084\n",
      "a_18085\n",
      "a_18086\n",
      "a_18087\n",
      "a_18088\n",
      "a_18089\n",
      "a_18090\n",
      "a_18091\n",
      "a_18092\n",
      "a_18093\n",
      "a_18094\n",
      "a_18095\n",
      "a_18096\n",
      "a_18097\n",
      "a_18098\n",
      "a_18099\n",
      "a_18100\n",
      "a_18101\n",
      "a_18102\n",
      "a_18103\n",
      "a_18104\n",
      "a_18105\n",
      "a_18106\n",
      "a_18107\n",
      "a_18108\n",
      "a_18109\n",
      "a_18110\n",
      "a_18111\n",
      "a_18112\n",
      "a_18113\n",
      "a_18114\n",
      "a_18115\n",
      "a_18116\n",
      "a_18117\n",
      "a_18118\n",
      "a_18119\n",
      "a_18120\n",
      "a_18121\n",
      "a_18122\n",
      "a_18123\n",
      "a_18124\n",
      "a_18125\n",
      "a_18126\n",
      "a_18127\n",
      "a_18128\n",
      "a_18129\n",
      "a_18130\n",
      "a_18131\n",
      "a_18132\n",
      "a_18133\n",
      "a_18134\n",
      "a_18135\n",
      "a_18136\n",
      "a_18137\n",
      "a_18138\n",
      "a_18139\n",
      "a_18140\n",
      "a_18141\n",
      "a_18142\n",
      "a_18143\n",
      "a_18144\n",
      "a_18145\n",
      "a_18146\n",
      "a_18147\n",
      "a_18148\n",
      "a_18149\n",
      "a_18150\n",
      "a_18151\n",
      "a_18152\n",
      "a_18153\n",
      "a_18154\n",
      "a_18155\n",
      "a_18156\n",
      "a_18157\n",
      "a_18158\n",
      "a_18159\n",
      "a_18160\n",
      "a_18161\n",
      "a_18162\n",
      "a_18163\n",
      "a_18164\n",
      "a_18165\n",
      "a_18166\n",
      "a_18167\n",
      "a_18168\n",
      "a_18169\n",
      "a_18170\n",
      "a_18171\n",
      "a_18172\n",
      "a_18173\n",
      "a_18174\n",
      "a_18175\n",
      "a_18176\n",
      "a_18177\n",
      "a_18178\n",
      "a_18179\n",
      "a_18180\n",
      "a_18181\n",
      "a_18182\n",
      "a_18183\n",
      "a_18184\n",
      "a_18185\n",
      "a_18186\n",
      "a_18187\n",
      "a_18188\n",
      "a_18189\n",
      "a_18190\n",
      "a_18191\n",
      "a_18192\n",
      "a_18193\n",
      "a_18194\n",
      "a_18195\n",
      "a_18196\n",
      "a_18197\n",
      "a_18198\n",
      "a_18199\n",
      "a_18200\n",
      "a_18201\n",
      "a_18202\n",
      "a_18203\n",
      "a_18204\n",
      "a_18205\n",
      "a_18206\n",
      "a_18207\n",
      "a_18208\n",
      "a_18209\n",
      "a_18210\n",
      "a_18211\n",
      "a_18212\n",
      "a_18213\n",
      "a_18214\n",
      "a_18215\n",
      "a_18216\n",
      "a_18217\n",
      "a_18218\n",
      "a_18219\n",
      "a_18220\n",
      "a_18221\n",
      "a_18222\n",
      "a_18223\n",
      "a_18224\n",
      "a_18225\n",
      "a_18226\n",
      "a_18227\n",
      "a_18228\n",
      "a_18229\n",
      "a_18230\n",
      "a_18231\n",
      "a_18232\n",
      "a_18233\n",
      "a_18234\n",
      "a_18235\n",
      "a_18236\n",
      "a_18237\n",
      "a_18238\n",
      "a_18239\n",
      "a_18240\n",
      "a_18241\n",
      "a_18242\n",
      "a_18243\n",
      "a_18244\n",
      "a_18245\n",
      "a_18246\n",
      "a_18247\n",
      "a_18248\n",
      "a_18249\n",
      "a_18250\n",
      "a_18251\n",
      "a_18252\n",
      "a_18253\n",
      "a_18254\n",
      "a_18255\n",
      "a_18256\n",
      "a_18257\n",
      "a_18258\n",
      "a_18259\n",
      "a_18260\n",
      "a_18261\n",
      "a_18262\n",
      "a_18263\n",
      "a_18264\n",
      "a_18265\n",
      "a_18266\n",
      "a_18267\n",
      "a_18268\n",
      "a_18269\n",
      "a_18270\n",
      "a_18271\n",
      "a_18272\n",
      "a_18273\n",
      "a_18274\n",
      "a_18275\n",
      "a_18276\n",
      "a_18277\n",
      "a_18278\n",
      "a_18279\n",
      "a_18280\n",
      "a_18281\n",
      "a_18282\n",
      "a_18283\n",
      "a_18284\n",
      "a_18285\n",
      "a_18286\n",
      "a_18287\n",
      "a_18288\n",
      "a_18289\n",
      "a_18290\n",
      "a_18291\n",
      "a_18292\n",
      "a_18293\n",
      "a_18294\n",
      "a_18295\n",
      "a_18296\n",
      "a_18297\n",
      "a_18298\n",
      "a_18299\n",
      "a_18300\n",
      "a_18301\n",
      "a_18302\n",
      "a_18303\n",
      "a_18304\n",
      "a_18305\n",
      "a_18306\n",
      "a_18307\n",
      "a_18308\n",
      "a_18309\n",
      "a_18310\n",
      "a_18311\n",
      "a_18312\n",
      "a_18313\n",
      "a_18314\n",
      "a_18315\n",
      "a_18316\n",
      "a_18317\n",
      "a_18318\n",
      "a_18319\n",
      "a_18320\n",
      "a_18321\n",
      "a_18322\n",
      "a_18323\n",
      "a_18324\n",
      "a_18325\n",
      "a_18326\n",
      "a_18327\n",
      "a_18328\n",
      "a_18329\n",
      "a_18330\n",
      "a_18331\n",
      "a_18332\n",
      "a_18333\n",
      "a_18334\n",
      "a_18335\n",
      "a_18336\n",
      "a_18337\n",
      "a_18338\n",
      "a_18339\n",
      "a_18340\n",
      "a_18341\n",
      "a_18342\n",
      "a_18343\n",
      "a_18344\n",
      "a_18345\n",
      "a_18346\n",
      "a_18347\n",
      "a_18348\n",
      "a_18349\n",
      "a_18350\n",
      "a_18351\n",
      "a_18352\n",
      "a_18353\n",
      "a_18354\n",
      "a_18355\n",
      "a_18356\n",
      "a_18357\n",
      "a_18358\n",
      "a_18359\n",
      "a_18360\n",
      "a_18361\n",
      "a_18362\n",
      "a_18363\n",
      "a_18364\n",
      "a_18365\n",
      "a_18366\n",
      "a_18367\n",
      "a_18368\n",
      "a_18369\n",
      "a_18370\n",
      "a_18371\n",
      "a_18372\n",
      "a_18373\n",
      "a_18374\n",
      "a_18375\n",
      "a_18376\n",
      "a_18377\n",
      "a_18378\n",
      "a_18379\n",
      "a_18380\n",
      "a_18381\n",
      "a_18382\n",
      "a_18383\n",
      "a_18384\n",
      "a_18385\n",
      "a_18386\n",
      "a_18387\n",
      "a_18388\n",
      "a_18389\n",
      "a_18390\n",
      "a_18391\n",
      "a_18392\n",
      "a_18393\n",
      "a_18394\n",
      "a_18395\n",
      "a_18396\n",
      "a_18397\n",
      "a_18398\n",
      "a_18399\n",
      "a_18400\n",
      "a_18401\n",
      "a_18402\n",
      "a_18403\n",
      "a_18404\n",
      "a_18405\n",
      "a_18406\n",
      "a_18407\n",
      "a_18408\n",
      "a_18409\n",
      "a_18410\n",
      "a_18411\n",
      "a_18412\n",
      "a_18413\n",
      "a_18414\n",
      "a_18415\n",
      "a_18416\n",
      "a_18417\n",
      "a_18418\n",
      "a_18419\n",
      "a_18420\n",
      "a_18421\n",
      "a_18422\n",
      "a_18423\n",
      "a_18424\n",
      "a_18425\n",
      "a_18426\n",
      "a_18427\n",
      "a_18428\n",
      "a_18429\n",
      "a_18430\n",
      "a_18431\n",
      "a_18432\n",
      "a_18433\n",
      "a_18434\n",
      "a_18435\n",
      "a_18436\n",
      "a_18437\n",
      "a_18438\n",
      "a_18439\n",
      "a_18440\n",
      "a_18441\n",
      "a_18442\n",
      "a_18443\n",
      "a_18444\n",
      "a_18445\n",
      "a_18446\n",
      "a_18447\n",
      "a_18448\n",
      "a_18449\n",
      "a_18450\n",
      "a_18451\n",
      "a_18452\n",
      "a_18453\n",
      "a_18454\n",
      "a_18455\n",
      "a_18456\n",
      "a_18457\n",
      "a_18458\n",
      "a_18459\n",
      "a_18460\n",
      "a_18461\n",
      "a_18462\n",
      "a_18463\n",
      "a_18464\n",
      "a_18465\n",
      "a_18466\n",
      "a_18467\n",
      "a_18468\n",
      "a_18469\n",
      "a_18470\n",
      "a_18471\n",
      "a_18472\n",
      "a_18473\n",
      "a_18474\n",
      "a_18475\n",
      "a_18476\n",
      "a_18477\n",
      "a_18478\n",
      "a_18479\n",
      "a_18480\n",
      "a_18481\n",
      "a_18482\n",
      "a_18483\n",
      "a_18484\n",
      "a_18485\n",
      "a_18486\n",
      "a_18487\n",
      "a_18488\n",
      "a_18489\n",
      "a_18490\n",
      "a_18491\n",
      "a_18492\n",
      "a_18493\n",
      "a_18494\n",
      "a_18495\n",
      "a_18496\n",
      "a_18497\n",
      "a_18498\n",
      "a_18499\n",
      "a_18500\n",
      "a_18501\n",
      "a_18502\n",
      "a_18503\n",
      "a_18504\n",
      "a_18505\n",
      "a_18506\n",
      "a_18507\n",
      "a_18508\n",
      "a_18509\n",
      "a_18510\n",
      "a_18511\n",
      "a_18512\n",
      "a_18513\n",
      "a_18514\n",
      "a_18515\n",
      "a_18516\n",
      "a_18517\n",
      "a_18518\n",
      "a_18519\n",
      "a_18520\n",
      "a_18521\n",
      "a_18522\n",
      "a_18523\n",
      "a_18524\n",
      "a_18525\n",
      "a_18526\n",
      "a_18527\n",
      "a_18528\n",
      "a_18529\n",
      "a_18530\n",
      "a_18531\n",
      "a_18532\n",
      "a_18533\n",
      "a_18534\n",
      "a_18535\n",
      "a_18536\n",
      "a_18537\n",
      "a_18538\n",
      "a_18539\n",
      "a_18540\n",
      "a_18541\n",
      "a_18542\n",
      "a_18543\n",
      "a_18544\n",
      "a_18545\n",
      "a_18546\n",
      "a_18547\n",
      "a_18548\n",
      "a_18549\n",
      "a_18550\n",
      "a_18551\n",
      "a_18552\n",
      "a_18553\n",
      "a_18554\n",
      "a_18555\n",
      "a_18556\n",
      "a_18557\n",
      "a_18558\n",
      "a_18559\n",
      "a_18560\n",
      "a_18561\n",
      "a_18562\n",
      "a_18563\n",
      "a_18564\n",
      "a_18565\n",
      "a_18566\n",
      "a_18567\n",
      "a_18568\n",
      "a_18569\n",
      "a_18570\n",
      "a_18571\n",
      "a_18572\n",
      "a_18573\n",
      "a_18574\n",
      "a_18575\n",
      "a_18576\n",
      "a_18577\n",
      "a_18578\n",
      "a_18579\n",
      "a_18580\n",
      "a_18581\n",
      "a_18582\n",
      "a_18583\n",
      "a_18584\n",
      "a_18585\n",
      "a_18586\n",
      "a_18587\n",
      "a_18588\n",
      "a_18589\n",
      "a_18590\n",
      "a_18591\n",
      "a_18592\n",
      "a_18593\n",
      "a_18594\n",
      "a_18595\n",
      "a_18596\n",
      "a_18597\n",
      "a_18598\n",
      "a_18599\n",
      "a_18600\n",
      "a_18601\n",
      "a_18602\n",
      "a_18603\n",
      "a_18604\n",
      "a_18605\n",
      "a_18606\n",
      "a_18607\n",
      "a_18608\n",
      "a_18609\n",
      "a_18610\n",
      "a_18611\n",
      "a_18612\n",
      "a_18613\n",
      "a_18614\n",
      "a_18615\n",
      "a_18616\n",
      "a_18617\n",
      "a_18618\n",
      "a_18619\n",
      "a_18620\n",
      "a_17764\n",
      "a_17765\n",
      "a_17766\n",
      "a_17767\n",
      "a_17768\n",
      "a_17769\n",
      "a_17770\n",
      "a_17771\n",
      "a_17772\n",
      "a_17773\n",
      "a_17774\n",
      "a_17775\n",
      "a_17776\n",
      "a_17777\n",
      "a_17778\n",
      "a_17779\n",
      "a_17780\n",
      "a_17781\n",
      "a_17782\n",
      "a_17783\n",
      "a_17784\n",
      "a_17785\n",
      "a_17786\n",
      "a_17787\n",
      "a_17788\n",
      "a_17789\n",
      "a_17790\n",
      "a_17791\n",
      "a_17792\n",
      "a_17793\n",
      "a_17794\n",
      "a_17795\n",
      "a_17796\n",
      "a_17797\n",
      "a_17798\n",
      "a_17799\n",
      "a_17800\n",
      "a_17801\n",
      "a_17802\n",
      "a_17803\n",
      "a_17804\n",
      "a_17805\n",
      "a_17806\n",
      "a_17807\n",
      "a_17808\n",
      "a_17809\n",
      "a_17810\n",
      "a_17811\n",
      "a_17812\n",
      "a_17813\n",
      "a_17814\n",
      "a_17815\n",
      "a_17816\n",
      "a_17817\n",
      "a_17818\n",
      "a_17819\n",
      "a_17820\n",
      "a_17821\n",
      "a_17822\n",
      "a_17823\n",
      "a_17824\n",
      "a_17825\n",
      "a_17826\n",
      "a_17827\n",
      "a_17828\n",
      "a_17829\n",
      "a_17830\n",
      "a_17831\n",
      "a_17832\n",
      "a_17833\n",
      "a_17834\n",
      "a_17835\n",
      "a_17836\n",
      "a_17837\n",
      "a_17838\n",
      "a_17839\n",
      "a_17840\n",
      "a_17841\n",
      "a_17842\n",
      "a_17843\n",
      "a_17844\n",
      "a_17845\n",
      "a_17846\n",
      "a_17847\n",
      "a_17848\n",
      "a_17849\n",
      "a_17850\n",
      "a_17851\n",
      "a_17852\n",
      "a_17853\n",
      "a_17854\n",
      "a_17855\n",
      "a_17856\n",
      "a_17857\n",
      "a_17858\n",
      "a_17859\n",
      "a_17860\n",
      "a_17861\n",
      "a_17862\n",
      "a_17863\n",
      "a_17864\n",
      "a_17865\n",
      "a_17866\n",
      "a_17867\n",
      "a_17868\n",
      "a_17869\n",
      "a_17870\n",
      "a_17871\n",
      "a_17872\n",
      "a_17873\n",
      "a_17874\n",
      "a_17875\n",
      "a_17876\n",
      "a_17877\n",
      "a_17878\n",
      "a_17879\n",
      "a_17880\n",
      "a_17881\n",
      "a_17882\n",
      "a_17883\n",
      "a_17884\n",
      "a_17885\n",
      "a_17886\n",
      "a_17887\n",
      "a_17888\n",
      "a_17889\n",
      "a_17890\n",
      "a_17891\n",
      "a_17892\n",
      "a_17893\n",
      "a_17894\n",
      "a_17895\n",
      "a_17896\n",
      "a_17897\n",
      "a_17898\n",
      "a_17899\n",
      "a_17900\n",
      "a_17901\n",
      "a_17902\n",
      "a_17903\n",
      "a_17904\n",
      "a_17905\n",
      "a_17906\n",
      "a_17907\n",
      "a_17908\n",
      "a_17909\n",
      "a_17910\n",
      "a_17911\n",
      "a_17912\n",
      "a_17913\n",
      "a_17914\n",
      "a_17915\n",
      "a_17916\n",
      "a_17917\n",
      "a_17918\n",
      "a_17919\n",
      "a_17920\n",
      "a_17921\n",
      "a_17922\n",
      "a_17923\n",
      "a_17924\n",
      "a_17925\n",
      "a_17926\n",
      "a_17927\n",
      "a_17928\n",
      "a_17929\n",
      "a_17930\n",
      "a_17931\n",
      "a_17932\n",
      "a_17933\n",
      "a_17934\n",
      "a_17935\n",
      "a_17936\n",
      "a_17937\n",
      "a_17938\n",
      "a_17939\n",
      "a_17940\n",
      "a_17941\n",
      "a_17942\n",
      "a_17943\n",
      "a_17944\n",
      "a_17945\n",
      "a_17946\n",
      "a_17947\n",
      "a_17948\n",
      "a_17949\n",
      "a_17950\n",
      "a_17951\n",
      "a_17952\n",
      "a_17953\n",
      "a_17954\n",
      "a_17955\n",
      "a_17956\n",
      "a_17957\n",
      "a_17958\n",
      "a_17959\n",
      "a_17960\n",
      "a_17961\n",
      "a_17962\n",
      "a_17963\n",
      "a_17964\n",
      "a_17965\n",
      "a_17966\n",
      "a_17967\n",
      "a_17968\n",
      "a_17969\n",
      "a_17970\n",
      "a_17971\n",
      "a_17972\n",
      "a_17973\n",
      "a_17974\n",
      "a_17975\n",
      "a_17976\n",
      "a_17977\n",
      "a_17978\n",
      "a_17979\n",
      "a_17980\n",
      "a_17981\n",
      "a_17982\n",
      "a_17983\n",
      "a_17984\n",
      "a_17985\n",
      "a_17986\n",
      "a_17987\n",
      "a_17988\n",
      "a_17989\n",
      "a_17990\n",
      "a_17991\n",
      "a_17992\n",
      "a_17993\n",
      "a_17994\n",
      "a_17995\n",
      "a_17996\n",
      "a_17997\n",
      "a_17998\n",
      "a_17999\n",
      "a_18000\n",
      "a_18001\n",
      "a_18002\n",
      "a_18003\n",
      "a_18004\n",
      "a_18005\n",
      "a_18006\n",
      "a_18007\n",
      "a_18008\n",
      "a_18009\n",
      "a_18010\n",
      "a_18011\n",
      "a_18012\n",
      "a_18013\n",
      "a_18014\n",
      "a_18015\n",
      "a_18016\n",
      "a_18017\n",
      "a_18018\n",
      "a_18019\n",
      "a_18020\n",
      "a_18021\n",
      "a_18022\n",
      "a_18023\n",
      "a_18024\n",
      "a_18025\n",
      "a_18026\n",
      "a_18027\n",
      "a_18028\n",
      "a_18029\n",
      "a_18030\n",
      "a_18031\n",
      "a_18032\n",
      "a_18033\n",
      "a_18034\n",
      "a_18035\n",
      "a_18036\n",
      "a_18037\n",
      "a_18038\n",
      "a_18039\n",
      "a_18040\n",
      "a_18041\n",
      "a_18042\n",
      "a_18043\n",
      "a_18044\n",
      "a_18045\n",
      "a_18046\n",
      "a_18047\n",
      "a_18048\n",
      "a_18049\n",
      "a_18050\n",
      "a_18051\n",
      "a_18052\n",
      "a_18053\n",
      "a_18054\n",
      "a_18055\n",
      "a_18056\n",
      "a_18057\n",
      "a_18058\n",
      "a_18059\n",
      "a_18060\n",
      "a_18061\n",
      "a_18062\n",
      "a_18063\n",
      "a_18064\n",
      "a_18065\n",
      "a_18066\n",
      "a_18067\n",
      "a_18068\n",
      "a_18069\n",
      "a_18070\n",
      "a_18071\n",
      "a_18072\n",
      "a_18073\n",
      "a_18074\n",
      "a_18075\n",
      "a_18076\n",
      "a_18077\n",
      "a_18078\n",
      "a_18079\n",
      "a_18080\n",
      "a_18081\n",
      "a_18082\n",
      "a_18083\n",
      "a_18084\n",
      "a_18085\n",
      "a_18086\n",
      "a_18087\n",
      "a_18088\n",
      "a_18089\n",
      "a_18090\n",
      "a_18091\n",
      "a_18092\n",
      "a_18093\n",
      "a_18094\n",
      "a_18095\n",
      "a_18096\n",
      "a_18097\n",
      "a_18098\n",
      "a_18099\n",
      "a_18100\n",
      "a_18101\n",
      "a_18102\n",
      "a_18103\n",
      "a_18104\n",
      "a_18105\n",
      "a_18106\n",
      "a_18107\n",
      "a_18108\n",
      "a_18109\n",
      "a_18110\n",
      "a_18111\n",
      "a_18112\n",
      "a_18113\n",
      "a_18114\n",
      "a_18115\n",
      "a_18116\n",
      "a_18117\n",
      "a_18118\n",
      "a_18119\n",
      "a_18120\n",
      "a_18121\n",
      "a_18122\n",
      "a_18123\n",
      "a_18124\n",
      "a_18125\n",
      "a_18126\n",
      "a_18127\n",
      "a_18128\n",
      "a_18129\n",
      "a_18130\n",
      "a_18131\n",
      "a_18132\n",
      "a_18133\n",
      "a_18134\n",
      "a_18135\n",
      "a_18136\n",
      "a_18137\n",
      "a_18138\n",
      "a_18139\n",
      "a_18140\n",
      "a_18141\n",
      "a_18142\n",
      "a_18143\n",
      "a_18144\n",
      "a_18145\n",
      "a_18146\n",
      "a_18147\n",
      "a_18148\n",
      "a_18149\n",
      "a_18150\n",
      "a_18151\n",
      "a_18152\n",
      "a_18153\n",
      "a_18154\n",
      "a_18155\n",
      "a_18156\n",
      "a_18157\n",
      "a_18158\n",
      "a_18159\n",
      "a_18160\n",
      "a_18161\n",
      "a_18162\n",
      "a_18163\n",
      "a_18164\n",
      "a_18165\n",
      "a_18166\n",
      "a_18167\n",
      "a_18168\n",
      "a_18169\n",
      "a_18170\n",
      "a_18171\n",
      "a_18172\n",
      "a_18173\n",
      "a_18174\n",
      "a_18175\n",
      "a_18176\n",
      "a_18177\n",
      "a_18178\n",
      "a_18179\n",
      "a_18180\n",
      "a_18181\n",
      "a_18182\n",
      "a_18183\n",
      "a_18184\n",
      "a_18185\n",
      "a_18186\n",
      "a_18187\n",
      "a_18188\n",
      "a_18189\n",
      "a_18190\n",
      "a_18191\n",
      "a_18192\n",
      "a_18193\n",
      "a_18194\n",
      "a_18195\n",
      "a_18196\n",
      "a_18197\n",
      "a_18198\n",
      "a_18199\n",
      "a_18200\n",
      "a_18201\n",
      "a_18202\n",
      "a_18203\n",
      "a_18204\n",
      "a_18205\n",
      "a_18206\n",
      "a_18207\n",
      "a_18208\n",
      "a_18209\n",
      "a_18210\n",
      "a_18211\n",
      "a_18212\n",
      "a_18213\n",
      "a_18214\n",
      "a_18215\n",
      "a_18216\n",
      "a_18217\n",
      "a_18218\n",
      "a_18219\n",
      "a_18220\n",
      "a_18221\n",
      "a_18222\n",
      "a_18223\n",
      "a_18224\n",
      "a_18225\n",
      "a_18226\n",
      "a_18227\n",
      "a_18228\n",
      "a_18229\n",
      "a_18230\n",
      "a_18231\n",
      "a_18232\n",
      "a_18233\n",
      "a_18234\n",
      "a_18235\n",
      "a_18236\n",
      "a_18237\n",
      "a_18238\n",
      "a_18239\n",
      "a_18240\n",
      "a_18241\n",
      "a_18242\n",
      "a_18243\n",
      "a_18244\n",
      "a_18245\n",
      "a_18246\n",
      "a_18247\n",
      "a_18248\n",
      "a_18249\n",
      "a_18250\n",
      "a_18251\n",
      "a_18252\n",
      "a_18253\n",
      "a_18254\n",
      "a_18255\n",
      "a_18256\n",
      "a_18257\n",
      "a_18258\n",
      "a_18259\n",
      "a_18260\n",
      "a_18261\n",
      "a_18262\n",
      "a_18263\n",
      "a_18264\n",
      "a_18265\n",
      "a_18266\n",
      "a_18267\n",
      "a_18268\n",
      "a_18269\n",
      "a_18270\n",
      "a_18271\n",
      "a_18272\n",
      "a_18273\n",
      "a_18274\n",
      "a_18275\n",
      "a_18276\n",
      "a_18277\n",
      "a_18278\n",
      "a_18279\n",
      "a_18280\n",
      "a_18281\n",
      "a_18282\n",
      "a_18283\n",
      "a_18284\n",
      "a_18285\n",
      "a_18286\n",
      "a_18287\n",
      "a_18288\n",
      "a_18289\n",
      "a_18290\n",
      "a_18291\n",
      "a_18292\n",
      "a_18293\n",
      "a_18294\n",
      "a_18295\n",
      "a_18296\n",
      "a_18297\n",
      "a_18298\n",
      "a_18299\n",
      "a_18300\n",
      "a_18301\n",
      "a_18302\n",
      "a_18303\n",
      "a_18304\n",
      "a_18305\n",
      "a_18306\n",
      "a_18307\n",
      "a_18308\n",
      "a_18309\n",
      "a_18310\n",
      "a_18311\n",
      "a_18312\n",
      "a_18313\n",
      "a_18314\n",
      "a_18315\n",
      "a_18316\n",
      "a_18317\n",
      "a_18318\n",
      "a_18319\n",
      "a_18320\n",
      "a_18321\n",
      "a_18322\n",
      "a_18323\n",
      "a_18324\n",
      "a_18325\n",
      "a_18326\n",
      "a_18327\n",
      "a_18328\n",
      "a_18329\n",
      "a_18330\n",
      "a_18331\n",
      "a_18332\n",
      "a_18333\n",
      "a_18334\n",
      "a_18335\n",
      "a_18336\n",
      "a_18337\n",
      "a_18338\n",
      "a_18339\n",
      "a_18340\n",
      "a_18341\n",
      "a_18342\n",
      "a_18343\n",
      "a_18344\n",
      "a_18345\n",
      "a_18346\n",
      "a_18347\n",
      "a_18348\n",
      "a_18349\n",
      "a_18350\n",
      "a_18351\n",
      "a_18352\n",
      "a_18353\n",
      "a_18354\n",
      "a_18355\n",
      "a_18356\n",
      "a_18357\n",
      "a_18358\n",
      "a_18359\n",
      "a_18360\n",
      "a_18361\n",
      "a_18362\n",
      "a_18363\n",
      "a_18364\n",
      "a_18365\n",
      "a_18366\n",
      "a_18367\n",
      "a_18368\n",
      "a_18369\n",
      "a_18370\n",
      "a_18371\n",
      "a_18372\n",
      "a_18373\n",
      "a_18374\n",
      "a_18375\n",
      "a_18376\n",
      "a_18377\n",
      "a_18378\n",
      "a_18379\n",
      "a_18380\n",
      "a_18381\n",
      "a_18382\n",
      "a_18383\n",
      "a_18384\n",
      "a_18385\n",
      "a_18386\n",
      "a_18387\n",
      "a_18388\n",
      "a_18389\n",
      "a_18390\n",
      "a_18391\n",
      "a_18392\n",
      "a_18393\n",
      "a_18394\n",
      "a_18395\n",
      "a_18396\n",
      "a_18397\n",
      "a_18398\n",
      "a_18399\n",
      "a_18400\n",
      "a_18401\n",
      "a_18402\n",
      "a_18403\n",
      "a_18404\n",
      "a_18405\n",
      "a_18406\n",
      "a_18407\n",
      "a_18408\n",
      "a_18409\n",
      "a_18410\n",
      "a_18411\n",
      "a_18412\n",
      "a_18413\n",
      "a_18414\n",
      "a_18415\n",
      "a_18416\n",
      "a_18417\n",
      "a_18418\n",
      "a_18419\n",
      "a_18420\n",
      "a_18421\n",
      "a_18422\n",
      "a_18423\n",
      "a_18424\n",
      "a_18425\n",
      "a_18426\n",
      "a_18427\n",
      "a_18428\n",
      "a_18429\n",
      "a_18430\n",
      "a_18431\n",
      "a_18432\n",
      "a_18433\n",
      "a_18434\n",
      "a_18435\n",
      "a_18436\n",
      "a_18437\n",
      "a_18438\n",
      "a_18439\n",
      "a_18440\n",
      "a_18441\n",
      "a_18442\n",
      "a_18443\n",
      "a_18444\n",
      "a_18445\n",
      "a_18446\n",
      "a_18447\n",
      "a_18448\n",
      "a_18449\n",
      "a_18450\n",
      "a_18451\n",
      "a_18452\n",
      "a_18453\n",
      "a_18454\n",
      "a_18455\n",
      "a_18456\n",
      "a_18457\n",
      "a_18458\n",
      "a_18459\n",
      "a_18460\n",
      "a_18461\n",
      "a_18462\n",
      "a_18463\n",
      "a_18464\n",
      "a_18465\n",
      "a_18466\n",
      "a_18467\n",
      "a_18468\n",
      "a_18469\n",
      "a_18470\n",
      "a_18471\n",
      "a_18472\n",
      "a_18473\n",
      "a_18474\n",
      "a_18475\n",
      "a_18476\n",
      "a_18477\n",
      "a_18478\n",
      "a_18479\n",
      "a_18480\n",
      "a_18481\n",
      "a_18482\n",
      "a_18483\n",
      "a_18484\n",
      "a_18485\n",
      "a_18486\n",
      "a_18487\n",
      "a_18488\n",
      "a_18489\n",
      "a_18490\n",
      "a_18491\n",
      "a_18492\n",
      "a_18493\n",
      "a_18494\n",
      "a_18495\n",
      "a_18496\n",
      "a_18497\n",
      "a_18498\n",
      "a_18499\n",
      "a_18500\n",
      "a_18501\n",
      "a_18502\n",
      "a_18503\n",
      "a_18504\n",
      "a_18505\n",
      "a_18506\n",
      "a_18507\n",
      "a_18508\n",
      "a_18509\n",
      "a_18510\n",
      "a_18511\n",
      "a_18512\n",
      "a_18513\n",
      "a_18514\n",
      "a_18515\n",
      "a_18516\n",
      "a_18517\n",
      "a_18518\n",
      "a_18519\n",
      "a_18520\n",
      "a_18521\n",
      "a_18522\n",
      "a_18523\n",
      "a_18524\n",
      "a_18525\n",
      "a_18526\n",
      "a_18527\n",
      "a_18528\n",
      "a_18529\n",
      "a_18530\n",
      "a_18531\n",
      "a_18532\n",
      "a_18533\n",
      "a_18534\n",
      "a_18535\n",
      "a_18536\n",
      "a_18537\n",
      "a_18538\n",
      "a_18539\n",
      "a_18540\n",
      "a_18541\n",
      "a_18542\n",
      "a_18543\n",
      "a_18544\n",
      "a_18545\n",
      "a_18546\n",
      "a_18547\n",
      "a_18548\n",
      "a_18549\n",
      "a_18550\n",
      "a_18551\n",
      "a_18552\n",
      "a_18553\n",
      "a_18554\n",
      "a_18555\n",
      "a_18556\n",
      "a_18557\n",
      "a_18558\n",
      "a_18559\n",
      "a_18560\n",
      "a_18561\n",
      "a_18562\n",
      "a_18563\n",
      "a_18564\n",
      "a_18565\n",
      "a_18566\n",
      "a_18567\n",
      "a_18568\n",
      "a_18569\n",
      "a_18570\n",
      "a_18571\n",
      "a_18572\n",
      "a_18573\n",
      "a_18574\n",
      "a_18575\n",
      "a_18576\n",
      "a_18577\n",
      "a_18578\n",
      "a_18579\n",
      "a_18580\n",
      "a_18581\n",
      "a_18582\n",
      "a_18583\n",
      "a_18584\n",
      "a_18585\n",
      "a_18586\n",
      "a_18587\n",
      "a_18588\n",
      "a_18589\n",
      "a_18590\n",
      "a_18591\n",
      "a_18592\n",
      "a_18593\n",
      "a_18594\n",
      "a_18595\n",
      "a_18596\n",
      "a_18597\n",
      "a_18598\n",
      "a_18599\n",
      "a_18600\n",
      "a_18601\n",
      "a_18602\n",
      "a_18603\n",
      "a_18604\n",
      "a_18605\n",
      "a_18606\n",
      "a_18607\n",
      "a_18608\n",
      "a_18609\n",
      "a_18610\n",
      "a_18611\n",
      "a_18612\n",
      "a_18613\n",
      "a_18614\n",
      "a_18615\n",
      "a_18616\n",
      "a_18617\n",
      "a_18618\n",
      "a_18619\n",
      "a_18620\n",
      "a_17764\n",
      "a_17765\n",
      "a_17766\n",
      "a_17767\n",
      "a_17768\n",
      "a_17769\n",
      "a_17770\n",
      "a_17771\n",
      "a_17772\n",
      "a_17773\n",
      "a_17774\n",
      "a_17775\n",
      "a_17776\n",
      "a_17777\n",
      "a_17778\n",
      "a_17779\n",
      "a_17780\n",
      "a_17781\n",
      "a_17782\n",
      "a_17783\n",
      "a_17784\n",
      "a_17785\n",
      "a_17786\n",
      "a_17787\n",
      "a_17788\n",
      "a_17789\n",
      "a_17790\n",
      "a_17791\n",
      "a_17792\n",
      "a_17793\n",
      "a_17794\n",
      "a_17795\n",
      "a_17796\n",
      "a_17797\n",
      "a_17798\n",
      "a_17799\n",
      "a_17800\n",
      "a_17801\n",
      "a_17802\n",
      "a_17803\n",
      "a_17804\n",
      "a_17805\n",
      "a_17806\n",
      "a_17807\n",
      "a_17808\n",
      "a_17809\n",
      "a_17810\n",
      "a_17811\n",
      "a_17812\n",
      "a_17813\n",
      "a_17814\n",
      "a_17815\n",
      "a_17816\n",
      "a_17817\n",
      "a_17818\n",
      "a_17819\n",
      "a_17820\n",
      "a_17821\n",
      "a_17822\n",
      "a_17823\n",
      "a_17824\n",
      "a_17825\n",
      "a_17826\n",
      "a_17827\n",
      "a_17828\n",
      "a_17829\n",
      "a_17830\n",
      "a_17831\n",
      "a_17832\n",
      "a_17833\n",
      "a_17834\n",
      "a_17835\n",
      "a_17836\n",
      "a_17837\n",
      "a_17838\n",
      "a_17839\n",
      "a_17840\n",
      "a_17841\n",
      "a_17842\n",
      "a_17843\n",
      "a_17844\n",
      "a_17845\n",
      "a_17846\n",
      "a_17847\n",
      "a_17848\n",
      "a_17849\n",
      "a_17850\n",
      "a_17851\n",
      "a_17852\n",
      "a_17853\n",
      "a_17854\n",
      "a_17855\n",
      "a_17856\n",
      "a_17857\n",
      "a_17858\n",
      "a_17859\n",
      "a_17860\n",
      "a_17861\n",
      "a_17862\n",
      "a_17863\n",
      "a_17864\n",
      "a_17865\n",
      "a_17866\n",
      "a_17867\n",
      "a_17868\n",
      "a_17869\n",
      "a_17870\n",
      "a_17871\n",
      "a_17872\n",
      "a_17873\n",
      "a_17874\n",
      "a_17875\n",
      "a_17876\n",
      "a_17877\n",
      "a_17878\n",
      "a_17879\n",
      "a_17880\n",
      "a_17881\n",
      "a_17882\n",
      "a_17883\n",
      "a_17884\n",
      "a_17885\n",
      "a_17886\n",
      "a_17887\n",
      "a_17888\n",
      "a_17889\n",
      "a_17890\n",
      "a_17891\n",
      "a_17892\n",
      "a_17893\n",
      "a_17894\n",
      "a_17895\n",
      "a_17896\n",
      "a_17897\n",
      "a_17898\n",
      "a_17899\n",
      "a_17900\n",
      "a_17901\n",
      "a_17902\n",
      "a_17903\n",
      "a_17904\n",
      "a_17905\n",
      "a_17906\n",
      "a_17907\n",
      "a_17908\n",
      "a_17909\n",
      "a_17910\n",
      "a_17911\n",
      "a_17912\n",
      "a_17913\n",
      "a_17914\n",
      "a_17915\n",
      "a_17916\n",
      "a_17917\n",
      "a_17918\n",
      "a_17919\n",
      "a_17920\n",
      "a_17921\n",
      "a_17922\n",
      "a_17923\n",
      "a_17924\n",
      "a_17925\n",
      "a_17926\n",
      "a_17927\n",
      "a_17928\n",
      "a_17929\n",
      "a_17930\n",
      "a_17931\n",
      "a_17932\n",
      "a_17933\n",
      "a_17934\n",
      "a_17935\n",
      "a_17936\n",
      "a_17937\n",
      "a_17938\n",
      "a_17939\n",
      "a_17940\n",
      "a_17941\n",
      "a_17942\n",
      "a_17943\n",
      "a_17944\n",
      "a_17945\n",
      "a_17946\n",
      "a_17947\n",
      "a_17948\n",
      "a_17949\n",
      "a_17950\n",
      "a_17951\n",
      "a_17952\n",
      "a_17953\n",
      "a_17954\n",
      "a_17955\n",
      "a_17956\n",
      "a_17957\n",
      "a_17958\n",
      "a_17959\n",
      "a_17960\n",
      "a_17961\n",
      "a_17962\n",
      "a_17963\n",
      "a_17964\n",
      "a_17965\n",
      "a_17966\n",
      "a_17967\n",
      "a_17968\n",
      "a_17969\n",
      "a_17970\n",
      "a_17971\n",
      "a_17972\n",
      "a_17973\n",
      "a_17974\n",
      "a_17975\n",
      "a_17976\n",
      "a_17977\n",
      "a_17978\n",
      "a_17979\n",
      "a_17980\n",
      "a_17981\n",
      "a_17982\n",
      "a_17983\n",
      "a_17984\n",
      "a_17985\n",
      "a_17986\n",
      "a_17987\n",
      "a_17988\n",
      "a_17989\n",
      "a_17990\n",
      "a_17991\n",
      "a_17992\n",
      "a_17993\n",
      "a_17994\n",
      "a_17995\n",
      "a_17996\n",
      "a_17997\n",
      "a_17998\n",
      "a_17999\n",
      "a_18000\n",
      "a_18001\n",
      "a_18002\n",
      "a_18003\n",
      "a_18004\n",
      "a_18005\n",
      "a_18006\n",
      "a_18007\n",
      "a_18008\n",
      "a_18009\n",
      "a_18010\n",
      "a_18011\n",
      "a_18012\n",
      "a_18013\n",
      "a_18014\n",
      "a_18015\n",
      "a_18016\n",
      "a_18017\n",
      "a_18018\n",
      "a_18019\n",
      "a_18020\n",
      "a_18021\n",
      "a_18022\n",
      "a_18023\n",
      "a_18024\n",
      "a_18025\n",
      "a_18026\n",
      "a_18027\n",
      "a_18028\n",
      "a_18029\n",
      "a_18030\n",
      "a_18031\n",
      "a_18032\n",
      "a_18033\n",
      "a_18034\n",
      "a_18035\n",
      "a_18036\n",
      "a_18037\n",
      "a_18038\n",
      "a_18039\n",
      "a_18040\n",
      "a_18041\n",
      "a_18042\n",
      "a_18043\n",
      "a_18044\n",
      "a_18045\n",
      "a_18046\n",
      "a_18047\n",
      "a_18048\n",
      "a_18049\n",
      "a_18050\n",
      "a_18051\n",
      "a_18052\n",
      "a_18053\n",
      "a_18054\n",
      "a_18055\n",
      "a_18056\n",
      "a_18057\n",
      "a_18058\n",
      "a_18059\n",
      "a_18060\n",
      "a_18061\n",
      "a_18062\n",
      "a_18063\n",
      "a_18064\n",
      "a_18065\n",
      "a_18066\n",
      "a_18067\n",
      "a_18068\n",
      "a_18069\n",
      "a_18070\n",
      "a_18071\n",
      "a_18072\n",
      "a_18073\n",
      "a_18074\n",
      "a_18075\n",
      "a_18076\n",
      "a_18077\n",
      "a_18078\n",
      "a_18079\n",
      "a_18080\n",
      "a_18081\n",
      "a_18082\n",
      "a_18083\n",
      "a_18084\n",
      "a_18085\n",
      "a_18086\n",
      "a_18087\n",
      "a_18088\n",
      "a_18089\n",
      "a_18090\n",
      "a_18091\n",
      "a_18092\n",
      "a_18093\n",
      "a_18094\n",
      "a_18095\n",
      "a_18096\n",
      "a_18097\n",
      "a_18098\n",
      "a_18099\n",
      "a_18100\n",
      "a_18101\n",
      "a_18102\n",
      "a_18103\n",
      "a_18104\n",
      "a_18105\n",
      "a_18106\n",
      "a_18107\n",
      "a_18108\n",
      "a_18109\n",
      "a_18110\n",
      "a_18111\n",
      "a_18112\n",
      "a_18113\n",
      "a_18114\n",
      "a_18115\n",
      "a_18116\n",
      "a_18117\n",
      "a_18118\n",
      "a_18119\n",
      "a_18120\n",
      "a_18121\n",
      "a_18122\n",
      "a_18123\n",
      "a_18124\n",
      "a_18125\n",
      "a_18126\n",
      "a_18127\n",
      "a_18128\n",
      "a_18129\n",
      "a_18130\n",
      "a_18131\n",
      "a_18132\n",
      "a_18133\n",
      "a_18134\n",
      "a_18135\n",
      "a_18136\n",
      "a_18137\n",
      "a_18138\n",
      "a_18139\n",
      "a_18140\n",
      "a_18141\n",
      "a_18142\n",
      "a_18143\n",
      "a_18144\n",
      "a_18145\n",
      "a_18146\n",
      "a_18147\n",
      "a_18148\n",
      "a_18149\n",
      "a_18150\n",
      "a_18151\n",
      "a_18152\n",
      "a_18153\n",
      "a_18154\n",
      "a_18155\n",
      "a_18156\n",
      "a_18157\n",
      "a_18158\n",
      "a_18159\n",
      "a_18160\n",
      "a_18161\n",
      "a_18162\n",
      "a_18163\n",
      "a_18164\n",
      "a_18165\n",
      "a_18166\n",
      "a_18167\n",
      "a_18168\n",
      "a_18169\n",
      "a_18170\n",
      "a_18171\n",
      "a_18172\n",
      "a_18173\n",
      "a_18174\n",
      "a_18175\n",
      "a_18176\n",
      "a_18177\n",
      "a_18178\n",
      "a_18179\n",
      "a_18180\n",
      "a_18181\n",
      "a_18182\n",
      "a_18183\n",
      "a_18184\n",
      "a_18185\n",
      "a_18186\n",
      "a_18187\n",
      "a_18188\n",
      "a_18189\n",
      "a_18190\n",
      "a_18191\n",
      "a_18192\n",
      "a_18193\n",
      "a_18194\n",
      "a_18195\n",
      "a_18196\n",
      "a_18197\n",
      "a_18198\n",
      "a_18199\n",
      "a_18200\n",
      "a_18201\n",
      "a_18202\n",
      "a_18203\n",
      "a_18204\n",
      "a_18205\n",
      "a_18206\n",
      "a_18207\n",
      "a_18208\n",
      "a_18209\n",
      "a_18210\n",
      "a_18211\n",
      "a_18212\n",
      "a_18213\n",
      "a_18214\n",
      "a_18215\n",
      "a_18216\n",
      "a_18217\n",
      "a_18218\n",
      "a_18219\n",
      "a_18220\n",
      "a_18221\n",
      "a_18222\n",
      "a_18223\n",
      "a_18224\n",
      "a_18225\n",
      "a_18226\n",
      "a_18227\n",
      "a_18228\n",
      "a_18229\n",
      "a_18230\n",
      "a_18231\n",
      "a_18232\n",
      "a_18233\n",
      "a_18234\n",
      "a_18235\n",
      "a_18236\n",
      "a_18237\n",
      "a_18238\n",
      "a_18239\n",
      "a_18240\n",
      "a_18241\n",
      "a_18242\n",
      "a_18243\n",
      "a_18244\n",
      "a_18245\n",
      "a_18246\n",
      "a_18247\n",
      "a_18248\n",
      "a_18249\n",
      "a_18250\n",
      "a_18251\n",
      "a_18252\n",
      "a_18253\n",
      "a_18254\n",
      "a_18255\n",
      "a_18256\n",
      "a_18257\n",
      "a_18258\n",
      "a_18259\n",
      "a_18260\n",
      "a_18261\n",
      "a_18262\n",
      "a_18263\n",
      "a_18264\n",
      "a_18265\n",
      "a_18266\n",
      "a_18267\n",
      "a_18268\n",
      "a_18269\n",
      "a_18270\n",
      "a_18271\n",
      "a_18272\n",
      "a_18273\n",
      "a_18274\n",
      "a_18275\n",
      "a_18276\n",
      "a_18277\n",
      "a_18278\n",
      "a_18279\n",
      "a_18280\n",
      "a_18281\n",
      "a_18282\n",
      "a_18283\n",
      "a_18284\n",
      "a_18285\n",
      "a_18286\n",
      "a_18287\n",
      "a_18288\n",
      "a_18289\n",
      "a_18290\n",
      "a_18291\n",
      "a_18292\n",
      "a_18293\n",
      "a_18294\n",
      "a_18295\n",
      "a_18296\n",
      "a_18297\n",
      "a_18298\n",
      "a_18299\n",
      "a_18300\n",
      "a_18301\n",
      "a_18302\n",
      "a_18303\n",
      "a_18304\n",
      "a_18305\n",
      "a_18306\n",
      "a_18307\n",
      "a_18308\n",
      "a_18309\n",
      "a_18310\n",
      "a_18311\n",
      "a_18312\n",
      "a_18313\n",
      "a_18314\n",
      "a_18315\n",
      "a_18316\n",
      "a_18317\n",
      "a_18318\n",
      "a_18319\n",
      "a_18320\n",
      "a_18321\n",
      "a_18322\n",
      "a_18323\n",
      "a_18324\n",
      "a_18325\n",
      "a_18326\n",
      "a_18327\n",
      "a_18328\n",
      "a_18329\n",
      "a_18330\n",
      "a_18331\n",
      "a_18332\n",
      "a_18333\n",
      "a_18334\n",
      "a_18335\n",
      "a_18336\n",
      "a_18337\n",
      "a_18338\n",
      "a_18339\n",
      "a_18340\n",
      "a_18341\n",
      "a_18342\n",
      "a_18343\n",
      "a_18344\n",
      "a_18345\n",
      "a_18346\n",
      "a_18347\n",
      "a_18348\n",
      "a_18349\n",
      "a_18350\n",
      "a_18351\n",
      "a_18352\n",
      "a_18353\n",
      "a_18354\n",
      "a_18355\n",
      "a_18356\n",
      "a_18357\n",
      "a_18358\n",
      "a_18359\n",
      "a_18360\n",
      "a_18361\n",
      "a_18362\n",
      "a_18363\n",
      "a_18364\n",
      "a_18365\n",
      "a_18366\n",
      "a_18367\n",
      "a_18368\n",
      "a_18369\n",
      "a_18370\n",
      "a_18371\n",
      "a_18372\n",
      "a_18373\n",
      "a_18374\n",
      "a_18375\n",
      "a_18376\n",
      "a_18377\n",
      "a_18378\n",
      "a_18379\n",
      "a_18380\n",
      "a_18381\n",
      "a_18382\n",
      "a_18383\n",
      "a_18384\n",
      "a_18385\n",
      "a_18386\n",
      "a_18387\n",
      "a_18388\n",
      "a_18389\n",
      "a_18390\n",
      "a_18391\n",
      "a_18392\n",
      "a_18393\n",
      "a_18394\n",
      "a_18395\n",
      "a_18396\n",
      "a_18397\n",
      "a_18398\n",
      "a_18399\n",
      "a_18400\n",
      "a_18401\n",
      "a_18402\n",
      "a_18403\n",
      "a_18404\n",
      "a_18405\n",
      "a_18406\n",
      "a_18407\n",
      "a_18408\n",
      "a_18409\n",
      "a_18410\n",
      "a_18411\n",
      "a_18412\n",
      "a_18413\n",
      "a_18414\n",
      "a_18415\n",
      "a_18416\n",
      "a_18417\n",
      "a_18418\n",
      "a_18419\n",
      "a_18420\n",
      "a_18421\n",
      "a_18422\n",
      "a_18423\n",
      "a_18424\n",
      "a_18425\n",
      "a_18426\n",
      "a_18427\n",
      "a_18428\n",
      "a_18429\n",
      "a_18430\n",
      "a_18431\n",
      "a_18432\n",
      "a_18433\n",
      "a_18434\n",
      "a_18435\n",
      "a_18436\n",
      "a_18437\n",
      "a_18438\n",
      "a_18439\n",
      "a_18440\n",
      "a_18441\n",
      "a_18442\n",
      "a_18443\n",
      "a_18444\n",
      "a_18445\n",
      "a_18446\n",
      "a_18447\n",
      "a_18448\n",
      "a_18449\n",
      "a_18450\n",
      "a_18451\n",
      "a_18452\n",
      "a_18453\n",
      "a_18454\n",
      "a_18455\n",
      "a_18456\n",
      "a_18457\n",
      "a_18458\n",
      "a_18459\n",
      "a_18460\n",
      "a_18461\n",
      "a_18462\n",
      "a_18463\n",
      "a_18464\n",
      "a_18465\n",
      "a_18466\n",
      "a_18467\n",
      "a_18468\n",
      "a_18469\n",
      "a_18470\n",
      "a_18471\n",
      "a_18472\n",
      "a_18473\n",
      "a_18474\n",
      "a_18475\n",
      "a_18476\n",
      "a_18477\n",
      "a_18478\n",
      "a_18479\n",
      "a_18480\n",
      "a_18481\n",
      "a_18482\n",
      "a_18483\n",
      "a_18484\n",
      "a_18485\n",
      "a_18486\n",
      "a_18487\n",
      "a_18488\n",
      "a_18489\n",
      "a_18490\n",
      "a_18491\n",
      "a_18492\n",
      "a_18493\n",
      "a_18494\n",
      "a_18495\n",
      "a_18496\n",
      "a_18497\n",
      "a_18498\n",
      "a_18499\n",
      "a_18500\n",
      "a_18501\n",
      "a_18502\n",
      "a_18503\n",
      "a_18504\n",
      "a_18505\n",
      "a_18506\n",
      "a_18507\n",
      "a_18508\n",
      "a_18509\n",
      "a_18510\n",
      "a_18511\n",
      "a_18512\n",
      "a_18513\n",
      "a_18514\n",
      "a_18515\n",
      "a_18516\n",
      "a_18517\n",
      "a_18518\n",
      "a_18519\n",
      "a_18520\n",
      "a_18521\n",
      "a_18522\n",
      "a_18523\n",
      "a_18524\n",
      "a_18525\n",
      "a_18526\n",
      "a_18527\n",
      "a_18528\n",
      "a_18529\n",
      "a_18530\n",
      "a_18531\n",
      "a_18532\n",
      "a_18533\n",
      "a_18534\n",
      "a_18535\n",
      "a_18536\n",
      "a_18537\n",
      "a_18538\n",
      "a_18539\n",
      "a_18540\n",
      "a_18541\n",
      "a_18542\n",
      "a_18543\n",
      "a_18544\n",
      "a_18545\n",
      "a_18546\n",
      "a_18547\n",
      "a_18548\n",
      "a_18549\n",
      "a_18550\n",
      "a_18551\n",
      "a_18552\n",
      "a_18553\n",
      "a_18554\n",
      "a_18555\n",
      "a_18556\n",
      "a_18557\n",
      "a_18558\n",
      "a_18559\n",
      "a_18560\n",
      "a_18561\n",
      "a_18562\n",
      "a_18563\n",
      "a_18564\n",
      "a_18565\n",
      "a_18566\n",
      "a_18567\n",
      "a_18568\n",
      "a_18569\n",
      "a_18570\n",
      "a_18571\n",
      "a_18572\n",
      "a_18573\n",
      "a_18574\n",
      "a_18575\n",
      "a_18576\n",
      "a_18577\n",
      "a_18578\n",
      "a_18579\n",
      "a_18580\n",
      "a_18581\n",
      "a_18582\n",
      "a_18583\n",
      "a_18584\n",
      "a_18585\n",
      "a_18586\n",
      "a_18587\n",
      "a_18588\n",
      "a_18589\n",
      "a_18590\n",
      "a_18591\n",
      "a_18592\n",
      "a_18593\n",
      "a_18594\n",
      "a_18595\n",
      "a_18596\n",
      "a_18597\n",
      "a_18598\n",
      "a_18599\n",
      "a_18600\n",
      "a_18601\n",
      "a_18602\n",
      "a_18603\n",
      "a_18604\n",
      "a_18605\n",
      "a_18606\n",
      "a_18607\n",
      "a_18608\n",
      "a_18609\n",
      "a_18610\n",
      "a_18611\n",
      "a_18612\n",
      "a_18613\n",
      "a_18614\n",
      "a_18615\n",
      "a_18616\n",
      "a_18617\n",
      "a_18618\n",
      "a_18619\n",
      "a_18620\n",
      "a_17764\n",
      "a_17765\n",
      "a_17766\n",
      "a_17767\n",
      "a_17768\n",
      "a_17769\n",
      "a_17770\n",
      "a_17771\n",
      "a_17772\n",
      "a_17773\n",
      "a_17774\n",
      "a_17775\n",
      "a_17776\n",
      "a_17777\n",
      "a_17778\n",
      "a_17779\n",
      "a_17780\n",
      "a_17781\n",
      "a_17782\n",
      "a_17783\n",
      "a_17784\n",
      "a_17785\n",
      "a_17786\n",
      "a_17787\n",
      "a_17788\n",
      "a_17789\n",
      "a_17790\n",
      "a_17791\n",
      "a_17792\n",
      "a_17793\n",
      "a_17794\n",
      "a_17795\n",
      "a_17796\n",
      "a_17797\n",
      "a_17798\n",
      "a_17799\n",
      "a_17800\n",
      "a_17801\n",
      "a_17802\n",
      "a_17803\n",
      "a_17804\n",
      "a_17805\n",
      "a_17806\n",
      "a_17807\n",
      "a_17808\n",
      "a_17809\n",
      "a_17810\n",
      "a_17811\n",
      "a_17812\n",
      "a_17813\n",
      "a_17814\n",
      "a_17815\n",
      "a_17816\n",
      "a_17817\n",
      "a_17818\n",
      "a_17819\n",
      "a_17820\n",
      "a_17821\n",
      "a_17822\n",
      "a_17823\n",
      "a_17824\n",
      "a_17825\n",
      "a_17826\n",
      "a_17827\n",
      "a_17828\n",
      "a_17829\n",
      "a_17830\n",
      "a_17831\n",
      "a_17832\n",
      "a_17833\n",
      "a_17834\n",
      "a_17835\n",
      "a_17836\n",
      "a_17837\n",
      "a_17838\n",
      "a_17839\n",
      "a_17840\n",
      "a_17841\n",
      "a_17842\n",
      "a_17843\n",
      "a_17844\n",
      "a_17845\n",
      "a_17846\n",
      "a_17847\n",
      "a_17848\n",
      "a_17849\n",
      "a_17850\n",
      "a_17851\n",
      "a_17852\n",
      "a_17853\n",
      "a_17854\n",
      "a_17855\n",
      "a_17856\n",
      "a_17857\n",
      "a_17858\n",
      "a_17859\n",
      "a_17860\n",
      "a_17861\n",
      "a_17862\n",
      "a_17863\n",
      "a_17864\n",
      "a_17865\n",
      "a_17866\n",
      "a_17867\n",
      "a_17868\n",
      "a_17869\n",
      "a_17870\n",
      "a_17871\n",
      "a_17872\n",
      "a_17873\n",
      "a_17874\n",
      "a_17875\n",
      "a_17876\n",
      "a_17877\n",
      "a_17878\n",
      "a_17879\n",
      "a_17880\n",
      "a_17881\n",
      "a_17882\n",
      "a_17883\n",
      "a_17884\n",
      "a_17885\n",
      "a_17886\n",
      "a_17887\n",
      "a_17888\n",
      "a_17889\n",
      "a_17890\n",
      "a_17891\n",
      "a_17892\n",
      "a_17893\n",
      "a_17894\n",
      "a_17895\n",
      "a_17896\n",
      "a_17897\n",
      "a_17898\n",
      "a_17899\n",
      "a_17900\n",
      "a_17901\n",
      "a_17902\n",
      "a_17903\n",
      "a_17904\n",
      "a_17905\n",
      "a_17906\n",
      "a_17907\n",
      "a_17908\n",
      "a_17909\n",
      "a_17910\n",
      "a_17911\n",
      "a_17912\n",
      "a_17913\n",
      "a_17914\n",
      "a_17915\n",
      "a_17916\n",
      "a_17917\n",
      "a_17918\n",
      "a_17919\n",
      "a_17920\n",
      "a_17921\n",
      "a_17922\n",
      "a_17923\n",
      "a_17924\n",
      "a_17925\n",
      "a_17926\n",
      "a_17927\n",
      "a_17928\n",
      "a_17929\n",
      "a_17930\n",
      "a_17931\n",
      "a_17932\n",
      "a_17933\n",
      "a_17934\n",
      "a_17935\n",
      "a_17936\n",
      "a_17937\n",
      "a_17938\n",
      "a_17939\n",
      "a_17940\n",
      "a_17941\n",
      "a_17942\n",
      "a_17943\n",
      "a_17944\n",
      "a_17945\n",
      "a_17946\n",
      "a_17947\n",
      "a_17948\n",
      "a_17949\n",
      "a_17950\n",
      "a_17951\n",
      "a_17952\n",
      "a_17953\n",
      "a_17954\n",
      "a_17955\n",
      "a_17956\n",
      "a_17957\n",
      "a_17958\n",
      "a_17959\n",
      "a_17960\n",
      "a_17961\n",
      "a_17962\n",
      "a_17963\n",
      "a_17964\n",
      "a_17965\n",
      "a_17966\n",
      "a_17967\n",
      "a_17968\n",
      "a_17969\n",
      "a_17970\n",
      "a_17971\n",
      "a_17972\n",
      "a_17973\n",
      "a_17974\n",
      "a_17975\n",
      "a_17976\n",
      "a_17977\n",
      "a_17978\n",
      "a_17979\n",
      "a_17980\n",
      "a_17981\n",
      "a_17982\n",
      "a_17983\n",
      "a_17984\n",
      "a_17985\n",
      "a_17986\n",
      "a_17987\n",
      "a_17988\n",
      "a_17989\n",
      "a_17990\n",
      "a_17991\n",
      "a_17992\n",
      "a_17993\n",
      "a_17994\n",
      "a_17995\n",
      "a_17996\n",
      "a_17997\n",
      "a_17998\n",
      "a_17999\n",
      "a_18000\n",
      "a_18001\n",
      "a_18002\n",
      "a_18003\n",
      "a_18004\n",
      "a_18005\n",
      "a_18006\n",
      "a_18007\n",
      "a_18008\n",
      "a_18009\n",
      "a_18010\n",
      "a_18011\n",
      "a_18012\n",
      "a_18013\n",
      "a_18014\n",
      "a_18015\n",
      "a_18016\n",
      "a_18017\n",
      "a_18018\n",
      "a_18019\n",
      "a_18020\n",
      "a_18021\n",
      "a_18022\n",
      "a_18023\n",
      "a_18024\n",
      "a_18025\n",
      "a_18026\n",
      "a_18027\n",
      "a_18028\n",
      "a_18029\n",
      "a_18030\n",
      "a_18031\n",
      "a_18032\n",
      "a_18033\n",
      "a_18034\n",
      "a_18035\n",
      "a_18036\n",
      "a_18037\n",
      "a_18038\n",
      "a_18039\n",
      "a_18040\n",
      "a_18041\n",
      "a_18042\n",
      "a_18043\n",
      "a_18044\n",
      "a_18045\n",
      "a_18046\n",
      "a_18047\n",
      "a_18048\n",
      "a_18049\n",
      "a_18050\n",
      "a_18051\n",
      "a_18052\n",
      "a_18053\n",
      "a_18054\n",
      "a_18055\n",
      "a_18056\n",
      "a_18057\n",
      "a_18058\n",
      "a_18059\n",
      "a_18060\n",
      "a_18061\n",
      "a_18062\n",
      "a_18063\n",
      "a_18064\n",
      "a_18065\n",
      "a_18066\n",
      "a_18067\n",
      "a_18068\n",
      "a_18069\n",
      "a_18070\n",
      "a_18071\n",
      "a_18072\n",
      "a_18073\n",
      "a_18074\n",
      "a_18075\n",
      "a_18076\n",
      "a_18077\n",
      "a_18078\n",
      "a_18079\n",
      "a_18080\n",
      "a_18081\n",
      "a_18082\n",
      "a_18083\n",
      "a_18084\n",
      "a_18085\n",
      "a_18086\n",
      "a_18087\n",
      "a_18088\n",
      "a_18089\n",
      "a_18090\n",
      "a_18091\n",
      "a_18092\n",
      "a_18093\n",
      "a_18094\n",
      "a_18095\n",
      "a_18096\n",
      "a_18097\n",
      "a_18098\n",
      "a_18099\n",
      "a_18100\n",
      "a_18101\n",
      "a_18102\n",
      "a_18103\n",
      "a_18104\n",
      "a_18105\n",
      "a_18106\n",
      "a_18107\n",
      "a_18108\n",
      "a_18109\n",
      "a_18110\n",
      "a_18111\n",
      "a_18112\n",
      "a_18113\n",
      "a_18114\n",
      "a_18115\n",
      "a_18116\n",
      "a_18117\n",
      "a_18118\n",
      "a_18119\n",
      "a_18120\n",
      "a_18121\n",
      "a_18122\n",
      "a_18123\n",
      "a_18124\n",
      "a_18125\n",
      "a_18126\n",
      "a_18127\n",
      "a_18128\n",
      "a_18129\n",
      "a_18130\n",
      "a_18131\n",
      "a_18132\n",
      "a_18133\n",
      "a_18134\n",
      "a_18135\n",
      "a_18136\n",
      "a_18137\n",
      "a_18138\n",
      "a_18139\n",
      "a_18140\n",
      "a_18141\n",
      "a_18142\n",
      "a_18143\n",
      "a_18144\n",
      "a_18145\n",
      "a_18146\n",
      "a_18147\n",
      "a_18148\n",
      "a_18149\n",
      "a_18150\n",
      "a_18151\n",
      "a_18152\n",
      "a_18153\n",
      "a_18154\n",
      "a_18155\n",
      "a_18156\n",
      "a_18157\n",
      "a_18158\n",
      "a_18159\n",
      "a_18160\n",
      "a_18161\n",
      "a_18162\n",
      "a_18163\n",
      "a_18164\n",
      "a_18165\n",
      "a_18166\n",
      "a_18167\n",
      "a_18168\n",
      "a_18169\n",
      "a_18170\n",
      "a_18171\n",
      "a_18172\n",
      "a_18173\n",
      "a_18174\n",
      "a_18175\n",
      "a_18176\n",
      "a_18177\n",
      "a_18178\n",
      "a_18179\n",
      "a_18180\n",
      "a_18181\n",
      "a_18182\n",
      "a_18183\n",
      "a_18184\n",
      "a_18185\n",
      "a_18186\n",
      "a_18187\n",
      "a_18188\n",
      "a_18189\n",
      "a_18190\n",
      "a_18191\n",
      "a_18192\n",
      "a_18193\n",
      "a_18194\n",
      "a_18195\n",
      "a_18196\n",
      "a_18197\n",
      "a_18198\n",
      "a_18199\n",
      "a_18200\n",
      "a_18201\n",
      "a_18202\n",
      "a_18203\n",
      "a_18204\n",
      "a_18205\n",
      "a_18206\n",
      "a_18207\n",
      "a_18208\n",
      "a_18209\n",
      "a_18210\n",
      "a_18211\n",
      "a_18212\n",
      "a_18213\n",
      "a_18214\n",
      "a_18215\n",
      "a_18216\n",
      "a_18217\n",
      "a_18218\n",
      "a_18219\n",
      "a_18220\n",
      "a_18221\n",
      "a_18222\n",
      "a_18223\n",
      "a_18224\n",
      "a_18225\n",
      "a_18226\n",
      "a_18227\n",
      "a_18228\n",
      "a_18229\n",
      "a_18230\n",
      "a_18231\n",
      "a_18232\n",
      "a_18233\n",
      "a_18234\n",
      "a_18235\n",
      "a_18236\n",
      "a_18237\n",
      "a_18238\n",
      "a_18239\n",
      "a_18240\n",
      "a_18241\n",
      "a_18242\n",
      "a_18243\n",
      "a_18244\n",
      "a_18245\n",
      "a_18246\n",
      "a_18247\n",
      "a_18248\n",
      "a_18249\n",
      "a_18250\n",
      "a_18251\n",
      "a_18252\n",
      "a_18253\n",
      "a_18254\n",
      "a_18255\n",
      "a_18256\n",
      "a_18257\n",
      "a_18258\n",
      "a_18259\n",
      "a_18260\n",
      "a_18261\n",
      "a_18262\n",
      "a_18263\n",
      "a_18264\n",
      "a_18265\n",
      "a_18266\n",
      "a_18267\n",
      "a_18268\n",
      "a_18269\n",
      "a_18270\n",
      "a_18271\n",
      "a_18272\n",
      "a_18273\n",
      "a_18274\n",
      "a_18275\n",
      "a_18276\n",
      "a_18277\n",
      "a_18278\n",
      "a_18279\n",
      "a_18280\n",
      "a_18281\n",
      "a_18282\n",
      "a_18283\n",
      "a_18284\n",
      "a_18285\n",
      "a_18286\n",
      "a_18287\n",
      "a_18288\n",
      "a_18289\n",
      "a_18290\n",
      "a_18291\n",
      "a_18292\n",
      "a_18293\n",
      "a_18294\n",
      "a_18295\n",
      "a_18296\n",
      "a_18297\n",
      "a_18298\n",
      "a_18299\n",
      "a_18300\n",
      "a_18301\n",
      "a_18302\n",
      "a_18303\n",
      "a_18304\n",
      "a_18305\n",
      "a_18306\n",
      "a_18307\n",
      "a_18308\n",
      "a_18309\n",
      "a_18310\n",
      "a_18311\n",
      "a_18312\n",
      "a_18313\n",
      "a_18314\n",
      "a_18315\n",
      "a_18316\n",
      "a_18317\n",
      "a_18318\n",
      "a_18319\n",
      "a_18320\n",
      "a_18321\n",
      "a_18322\n",
      "a_18323\n",
      "a_18324\n",
      "a_18325\n",
      "a_18326\n",
      "a_18327\n",
      "a_18328\n",
      "a_18329\n",
      "a_18330\n",
      "a_18331\n",
      "a_18332\n",
      "a_18333\n",
      "a_18334\n",
      "a_18335\n",
      "a_18336\n",
      "a_18337\n",
      "a_18338\n",
      "a_18339\n",
      "a_18340\n",
      "a_18341\n",
      "a_18342\n",
      "a_18343\n",
      "a_18344\n",
      "a_18345\n",
      "a_18346\n",
      "a_18347\n",
      "a_18348\n",
      "a_18349\n",
      "a_18350\n",
      "a_18351\n",
      "a_18352\n",
      "a_18353\n",
      "a_18354\n",
      "a_18355\n",
      "a_18356\n",
      "a_18357\n",
      "a_18358\n",
      "a_18359\n",
      "a_18360\n",
      "a_18361\n",
      "a_18362\n",
      "a_18363\n",
      "a_18364\n",
      "a_18365\n",
      "a_18366\n",
      "a_18367\n",
      "a_18368\n",
      "a_18369\n",
      "a_18370\n",
      "a_18371\n",
      "a_18372\n",
      "a_18373\n",
      "a_18374\n",
      "a_18375\n",
      "a_18376\n",
      "a_18377\n",
      "a_18378\n",
      "a_18379\n",
      "a_18380\n",
      "a_18381\n",
      "a_18382\n",
      "a_18383\n",
      "a_18384\n",
      "a_18385\n",
      "a_18386\n",
      "a_18387\n",
      "a_18388\n",
      "a_18389\n",
      "a_18390\n",
      "a_18391\n",
      "a_18392\n",
      "a_18393\n",
      "a_18394\n",
      "a_18395\n",
      "a_18396\n",
      "a_18397\n",
      "a_18398\n",
      "a_18399\n",
      "a_18400\n",
      "a_18401\n",
      "a_18402\n",
      "a_18403\n",
      "a_18404\n",
      "a_18405\n",
      "a_18406\n",
      "a_18407\n",
      "a_18408\n",
      "a_18409\n",
      "a_18410\n",
      "a_18411\n",
      "a_18412\n",
      "a_18413\n",
      "a_18414\n",
      "a_18415\n",
      "a_18416\n",
      "a_18417\n",
      "a_18418\n",
      "a_18419\n",
      "a_18420\n",
      "a_18421\n",
      "a_18422\n",
      "a_18423\n",
      "a_18424\n",
      "a_18425\n",
      "a_18426\n",
      "a_18427\n",
      "a_18428\n",
      "a_18429\n",
      "a_18430\n",
      "a_18431\n",
      "a_18432\n",
      "a_18433\n",
      "a_18434\n",
      "a_18435\n",
      "a_18436\n",
      "a_18437\n",
      "a_18438\n",
      "a_18439\n",
      "a_18440\n",
      "a_18441\n",
      "a_18442\n",
      "a_18443\n",
      "a_18444\n",
      "a_18445\n",
      "a_18446\n",
      "a_18447\n",
      "a_18448\n",
      "a_18449\n",
      "a_18450\n",
      "a_18451\n",
      "a_18452\n",
      "a_18453\n",
      "a_18454\n",
      "a_18455\n",
      "a_18456\n",
      "a_18457\n",
      "a_18458\n",
      "a_18459\n",
      "a_18460\n",
      "a_18461\n",
      "a_18462\n",
      "a_18463\n",
      "a_18464\n",
      "a_18465\n",
      "a_18466\n",
      "a_18467\n",
      "a_18468\n",
      "a_18469\n",
      "a_18470\n",
      "a_18471\n",
      "a_18472\n",
      "a_18473\n",
      "a_18474\n",
      "a_18475\n",
      "a_18476\n",
      "a_18477\n",
      "a_18478\n",
      "a_18479\n",
      "a_18480\n",
      "a_18481\n",
      "a_18482\n",
      "a_18483\n",
      "a_18484\n",
      "a_18485\n",
      "a_18486\n",
      "a_18487\n",
      "a_18488\n",
      "a_18489\n",
      "a_18490\n",
      "a_18491\n",
      "a_18492\n",
      "a_18493\n",
      "a_18494\n",
      "a_18495\n",
      "a_18496\n",
      "a_18497\n",
      "a_18498\n",
      "a_18499\n",
      "a_18500\n",
      "a_18501\n",
      "a_18502\n",
      "a_18503\n",
      "a_18504\n",
      "a_18505\n",
      "a_18506\n",
      "a_18507\n",
      "a_18508\n",
      "a_18509\n",
      "a_18510\n",
      "a_18511\n",
      "a_18512\n",
      "a_18513\n",
      "a_18514\n",
      "a_18515\n",
      "a_18516\n",
      "a_18517\n",
      "a_18518\n",
      "a_18519\n",
      "a_18520\n",
      "a_18521\n",
      "a_18522\n",
      "a_18523\n",
      "a_18524\n",
      "a_18525\n",
      "a_18526\n",
      "a_18527\n",
      "a_18528\n",
      "a_18529\n",
      "a_18530\n",
      "a_18531\n",
      "a_18532\n",
      "a_18533\n",
      "a_18534\n",
      "a_18535\n",
      "a_18536\n",
      "a_18537\n",
      "a_18538\n",
      "a_18539\n",
      "a_18540\n",
      "a_18541\n",
      "a_18542\n",
      "a_18543\n",
      "a_18544\n",
      "a_18545\n",
      "a_18546\n",
      "a_18547\n",
      "a_18548\n",
      "a_18549\n",
      "a_18550\n",
      "a_18551\n",
      "a_18552\n",
      "a_18553\n",
      "a_18554\n",
      "a_18555\n",
      "a_18556\n",
      "a_18557\n",
      "a_18558\n",
      "a_18559\n",
      "a_18560\n",
      "a_18561\n",
      "a_18562\n",
      "a_18563\n",
      "a_18564\n",
      "a_18565\n",
      "a_18566\n",
      "a_18567\n",
      "a_18568\n",
      "a_18569\n",
      "a_18570\n",
      "a_18571\n",
      "a_18572\n",
      "a_18573\n",
      "a_18574\n",
      "a_18575\n",
      "a_18576\n",
      "a_18577\n",
      "a_18578\n",
      "a_18579\n",
      "a_18580\n",
      "a_18581\n",
      "a_18582\n",
      "a_18583\n",
      "a_18584\n",
      "a_18585\n",
      "a_18586\n",
      "a_18587\n",
      "a_18588\n",
      "a_18589\n",
      "a_18590\n",
      "a_18591\n",
      "a_18592\n",
      "a_18593\n",
      "a_18594\n",
      "a_18595\n",
      "a_18596\n",
      "a_18597\n",
      "a_18598\n",
      "a_18599\n",
      "a_18600\n",
      "a_18601\n",
      "a_18602\n",
      "a_18603\n",
      "a_18604\n",
      "a_18605\n",
      "a_18606\n",
      "a_18607\n",
      "a_18608\n",
      "a_18609\n",
      "a_18610\n",
      "a_18611\n",
      "a_18612\n",
      "a_18613\n",
      "a_18614\n",
      "a_18615\n",
      "a_18616\n",
      "a_18617\n",
      "a_18618\n",
      "a_18619\n",
      "a_18620\n",
      "a_17764\n",
      "a_17765\n",
      "a_17766\n",
      "a_17767\n",
      "a_17768\n",
      "a_17769\n",
      "a_17770\n",
      "a_17771\n",
      "a_17772\n",
      "a_17773\n",
      "a_17774\n",
      "a_17775\n",
      "a_17776\n",
      "a_17777\n",
      "a_17778\n",
      "a_17779\n",
      "a_17780\n",
      "a_17781\n",
      "a_17782\n",
      "a_17783\n",
      "a_17784\n",
      "a_17785\n",
      "a_17786\n",
      "a_17787\n",
      "a_17788\n",
      "a_17789\n",
      "a_17790\n",
      "a_17791\n",
      "a_17792\n",
      "a_17793\n",
      "a_17794\n",
      "a_17795\n",
      "a_17796\n",
      "a_17797\n",
      "a_17798\n",
      "a_17799\n",
      "a_17800\n",
      "a_17801\n",
      "a_17802\n",
      "a_17803\n",
      "a_17804\n",
      "a_17805\n",
      "a_17806\n",
      "a_17807\n",
      "a_17808\n",
      "a_17809\n",
      "a_17810\n",
      "a_17811\n",
      "a_17812\n",
      "a_17813\n",
      "a_17814\n",
      "a_17815\n",
      "a_17816\n",
      "a_17817\n",
      "a_17818\n",
      "a_17819\n",
      "a_17820\n",
      "a_17821\n",
      "a_17822\n",
      "a_17823\n",
      "a_17824\n",
      "a_17825\n",
      "a_17826\n",
      "a_17827\n",
      "a_17828\n",
      "a_17829\n",
      "a_17830\n",
      "a_17831\n",
      "a_17832\n",
      "a_17833\n",
      "a_17834\n",
      "a_17835\n",
      "a_17836\n",
      "a_17837\n",
      "a_17838\n",
      "a_17839\n",
      "a_17840\n",
      "a_17841\n",
      "a_17842\n",
      "a_17843\n",
      "a_17844\n",
      "a_17845\n",
      "a_17846\n",
      "a_17847\n",
      "a_17848\n",
      "a_17849\n",
      "a_17850\n",
      "a_17851\n",
      "a_17852\n",
      "a_17853\n",
      "a_17854\n",
      "a_17855\n",
      "a_17856\n",
      "a_17857\n",
      "a_17858\n",
      "a_17859\n",
      "a_17860\n",
      "a_17861\n",
      "a_17862\n",
      "a_17863\n",
      "a_17864\n",
      "a_17865\n",
      "a_17866\n",
      "a_17867\n",
      "a_17868\n",
      "a_17869\n",
      "a_17870\n",
      "a_17871\n",
      "a_17872\n",
      "a_17873\n",
      "a_17874\n",
      "a_17875\n",
      "a_17876\n",
      "a_17877\n",
      "a_17878\n",
      "a_17879\n",
      "a_17880\n",
      "a_17881\n",
      "a_17882\n",
      "a_17883\n",
      "a_17884\n",
      "a_17885\n",
      "a_17886\n",
      "a_17887\n",
      "a_17888\n",
      "a_17889\n",
      "a_17890\n",
      "a_17891\n",
      "a_17892\n",
      "a_17893\n",
      "a_17894\n",
      "a_17895\n",
      "a_17896\n",
      "a_17897\n",
      "a_17898\n",
      "a_17899\n",
      "a_17900\n",
      "a_17901\n",
      "a_17902\n",
      "a_17903\n",
      "a_17904\n",
      "a_17905\n",
      "a_17906\n",
      "a_17907\n",
      "a_17908\n",
      "a_17909\n",
      "a_17910\n",
      "a_17911\n",
      "a_17912\n",
      "a_17913\n",
      "a_17914\n",
      "a_17915\n",
      "a_17916\n",
      "a_17917\n",
      "a_17918\n",
      "a_17919\n",
      "a_17920\n",
      "a_17921\n",
      "a_17922\n",
      "a_17923\n",
      "a_17924\n",
      "a_17925\n",
      "a_17926\n",
      "a_17927\n",
      "a_17928\n",
      "a_17929\n",
      "a_17930\n",
      "a_17931\n",
      "a_17932\n",
      "a_17933\n",
      "a_17934\n",
      "a_17935\n",
      "a_17936\n",
      "a_17937\n",
      "a_17938\n",
      "a_17939\n",
      "a_17940\n",
      "a_17941\n",
      "a_17942\n",
      "a_17943\n",
      "a_17944\n",
      "a_17945\n",
      "a_17946\n",
      "a_17947\n",
      "a_17948\n",
      "a_17949\n",
      "a_17950\n",
      "a_17951\n",
      "a_17952\n",
      "a_17953\n",
      "a_17954\n",
      "a_17955\n",
      "a_17956\n",
      "a_17957\n",
      "a_17958\n",
      "a_17959\n",
      "a_17960\n",
      "a_17961\n",
      "a_17962\n",
      "a_17963\n",
      "a_17964\n",
      "a_17965\n",
      "a_17966\n",
      "a_17967\n",
      "a_17968\n",
      "a_17969\n",
      "a_17970\n",
      "a_17971\n",
      "a_17972\n",
      "a_17973\n",
      "a_17974\n",
      "a_17975\n",
      "a_17976\n",
      "a_17977\n",
      "a_17978\n",
      "a_17979\n",
      "a_17980\n",
      "a_17981\n",
      "a_17982\n",
      "a_17983\n",
      "a_17984\n",
      "a_17985\n",
      "a_17986\n",
      "a_17987\n",
      "a_17988\n",
      "a_17989\n",
      "a_17990\n",
      "a_17991\n",
      "a_17992\n",
      "a_17993\n",
      "a_17994\n",
      "a_17995\n",
      "a_17996\n",
      "a_17997\n",
      "a_17998\n",
      "a_17999\n",
      "a_18000\n",
      "a_18001\n",
      "a_18002\n",
      "a_18003\n",
      "a_18004\n",
      "a_18005\n",
      "a_18006\n",
      "a_18007\n",
      "a_18008\n",
      "a_18009\n",
      "a_18010\n",
      "a_18011\n",
      "a_18012\n",
      "a_18013\n",
      "a_18014\n",
      "a_18015\n",
      "a_18016\n",
      "a_18017\n",
      "a_18018\n",
      "a_18019\n",
      "a_18020\n",
      "a_18021\n",
      "a_18022\n",
      "a_18023\n",
      "a_18024\n",
      "a_18025\n",
      "a_18026\n",
      "a_18027\n",
      "a_18028\n",
      "a_18029\n",
      "a_18030\n",
      "a_18031\n",
      "a_18032\n",
      "a_18033\n",
      "a_18034\n",
      "a_18035\n",
      "a_18036\n",
      "a_18037\n",
      "a_18038\n",
      "a_18039\n",
      "a_18040\n",
      "a_18041\n",
      "a_18042\n",
      "a_18043\n",
      "a_18044\n",
      "a_18045\n",
      "a_18046\n",
      "a_18047\n",
      "a_18048\n",
      "a_18049\n",
      "a_18050\n",
      "a_18051\n",
      "a_18052\n",
      "a_18053\n",
      "a_18054\n",
      "a_18055\n",
      "a_18056\n",
      "a_18057\n",
      "a_18058\n",
      "a_18059\n",
      "a_18060\n",
      "a_18061\n",
      "a_18062\n",
      "a_18063\n",
      "a_18064\n",
      "a_18065\n",
      "a_18066\n",
      "a_18067\n",
      "a_18068\n",
      "a_18069\n",
      "a_18070\n",
      "a_18071\n",
      "a_18072\n",
      "a_18073\n",
      "a_18074\n",
      "a_18075\n",
      "a_18076\n",
      "a_18077\n",
      "a_18078\n",
      "a_18079\n",
      "a_18080\n",
      "a_18081\n",
      "a_18082\n",
      "a_18083\n",
      "a_18084\n",
      "a_18085\n",
      "a_18086\n",
      "a_18087\n",
      "a_18088\n",
      "a_18089\n",
      "a_18090\n",
      "a_18091\n",
      "a_18092\n",
      "a_18093\n",
      "a_18094\n",
      "a_18095\n",
      "a_18096\n",
      "a_18097\n",
      "a_18098\n",
      "a_18099\n",
      "a_18100\n",
      "a_18101\n",
      "a_18102\n",
      "a_18103\n",
      "a_18104\n",
      "a_18105\n",
      "a_18106\n",
      "a_18107\n",
      "a_18108\n",
      "a_18109\n",
      "a_18110\n",
      "a_18111\n",
      "a_18112\n",
      "a_18113\n",
      "a_18114\n",
      "a_18115\n",
      "a_18116\n",
      "a_18117\n",
      "a_18118\n",
      "a_18119\n",
      "a_18120\n",
      "a_18121\n",
      "a_18122\n",
      "a_18123\n",
      "a_18124\n",
      "a_18125\n",
      "a_18126\n",
      "a_18127\n",
      "a_18128\n",
      "a_18129\n",
      "a_18130\n",
      "a_18131\n",
      "a_18132\n",
      "a_18133\n",
      "a_18134\n",
      "a_18135\n",
      "a_18136\n",
      "a_18137\n",
      "a_18138\n",
      "a_18139\n",
      "a_18140\n",
      "a_18141\n",
      "a_18142\n",
      "a_18143\n",
      "a_18144\n",
      "a_18145\n",
      "a_18146\n",
      "a_18147\n",
      "a_18148\n",
      "a_18149\n",
      "a_18150\n",
      "a_18151\n",
      "a_18152\n",
      "a_18153\n",
      "a_18154\n",
      "a_18155\n",
      "a_18156\n",
      "a_18157\n",
      "a_18158\n",
      "a_18159\n",
      "a_18160\n",
      "a_18161\n",
      "a_18162\n",
      "a_18163\n",
      "a_18164\n",
      "a_18165\n",
      "a_18166\n",
      "a_18167\n",
      "a_18168\n",
      "a_18169\n",
      "a_18170\n",
      "a_18171\n",
      "a_18172\n",
      "a_18173\n",
      "a_18174\n",
      "a_18175\n",
      "a_18176\n",
      "a_18177\n",
      "a_18178\n",
      "a_18179\n",
      "a_18180\n",
      "a_18181\n",
      "a_18182\n",
      "a_18183\n",
      "a_18184\n",
      "a_18185\n",
      "a_18186\n",
      "a_18187\n",
      "a_18188\n",
      "a_18189\n",
      "a_18190\n",
      "a_18191\n",
      "a_18192\n",
      "a_18193\n",
      "a_18194\n",
      "a_18195\n",
      "a_18196\n",
      "a_18197\n",
      "a_18198\n",
      "a_18199\n",
      "a_18200\n",
      "a_18201\n",
      "a_18202\n",
      "a_18203\n",
      "a_18204\n",
      "a_18205\n",
      "a_18206\n",
      "a_18207\n",
      "a_18208\n",
      "a_18209\n",
      "a_18210\n",
      "a_18211\n",
      "a_18212\n",
      "a_18213\n",
      "a_18214\n",
      "a_18215\n",
      "a_18216\n",
      "a_18217\n",
      "a_18218\n",
      "a_18219\n",
      "a_18220\n",
      "a_18221\n",
      "a_18222\n",
      "a_18223\n",
      "a_18224\n",
      "a_18225\n",
      "a_18226\n",
      "a_18227\n",
      "a_18228\n",
      "a_18229\n",
      "a_18230\n",
      "a_18231\n",
      "a_18232\n",
      "a_18233\n",
      "a_18234\n",
      "a_18235\n",
      "a_18236\n",
      "a_18237\n",
      "a_18238\n",
      "a_18239\n",
      "a_18240\n",
      "a_18241\n",
      "a_18242\n",
      "a_18243\n",
      "a_18244\n",
      "a_18245\n",
      "a_18246\n",
      "a_18247\n",
      "a_18248\n",
      "a_18249\n",
      "a_18250\n",
      "a_18251\n",
      "a_18252\n",
      "a_18253\n",
      "a_18254\n",
      "a_18255\n",
      "a_18256\n",
      "a_18257\n",
      "a_18258\n",
      "a_18259\n",
      "a_18260\n",
      "a_18261\n",
      "a_18262\n",
      "a_18263\n",
      "a_18264\n",
      "a_18265\n",
      "a_18266\n",
      "a_18267\n",
      "a_18268\n",
      "a_18269\n",
      "a_18270\n",
      "a_18271\n",
      "a_18272\n",
      "a_18273\n",
      "a_18274\n",
      "a_18275\n",
      "a_18276\n",
      "a_18277\n",
      "a_18278\n",
      "a_18279\n",
      "a_18280\n",
      "a_18281\n",
      "a_18282\n",
      "a_18283\n",
      "a_18284\n",
      "a_18285\n",
      "a_18286\n",
      "a_18287\n",
      "a_18288\n",
      "a_18289\n",
      "a_18290\n",
      "a_18291\n",
      "a_18292\n",
      "a_18293\n",
      "a_18294\n",
      "a_18295\n",
      "a_18296\n",
      "a_18297\n",
      "a_18298\n",
      "a_18299\n",
      "a_18300\n",
      "a_18301\n",
      "a_18302\n",
      "a_18303\n",
      "a_18304\n",
      "a_18305\n",
      "a_18306\n",
      "a_18307\n",
      "a_18308\n",
      "a_18309\n",
      "a_18310\n",
      "a_18311\n",
      "a_18312\n",
      "a_18313\n",
      "a_18314\n",
      "a_18315\n",
      "a_18316\n",
      "a_18317\n",
      "a_18318\n",
      "a_18319\n",
      "a_18320\n",
      "a_18321\n",
      "a_18322\n",
      "a_18323\n",
      "a_18324\n",
      "a_18325\n",
      "a_18326\n",
      "a_18327\n",
      "a_18328\n",
      "a_18329\n",
      "a_18330\n",
      "a_18331\n",
      "a_18332\n",
      "a_18333\n",
      "a_18334\n",
      "a_18335\n",
      "a_18336\n",
      "a_18337\n",
      "a_18338\n",
      "a_18339\n",
      "a_18340\n",
      "a_18341\n",
      "a_18342\n",
      "a_18343\n",
      "a_18344\n",
      "a_18345\n",
      "a_18346\n",
      "a_18347\n",
      "a_18348\n",
      "a_18349\n",
      "a_18350\n",
      "a_18351\n",
      "a_18352\n",
      "a_18353\n",
      "a_18354\n",
      "a_18355\n",
      "a_18356\n",
      "a_18357\n",
      "a_18358\n",
      "a_18359\n",
      "a_18360\n",
      "a_18361\n",
      "a_18362\n",
      "a_18363\n",
      "a_18364\n",
      "a_18365\n",
      "a_18366\n",
      "a_18367\n",
      "a_18368\n",
      "a_18369\n",
      "a_18370\n",
      "a_18371\n",
      "a_18372\n",
      "a_18373\n",
      "a_18374\n",
      "a_18375\n",
      "a_18376\n",
      "a_18377\n",
      "a_18378\n",
      "a_18379\n",
      "a_18380\n",
      "a_18381\n",
      "a_18382\n",
      "a_18383\n",
      "a_18384\n",
      "a_18385\n",
      "a_18386\n",
      "a_18387\n",
      "a_18388\n",
      "a_18389\n",
      "a_18390\n",
      "a_18391\n",
      "a_18392\n",
      "a_18393\n",
      "a_18394\n",
      "a_18395\n",
      "a_18396\n",
      "a_18397\n",
      "a_18398\n",
      "a_18399\n",
      "a_18400\n",
      "a_18401\n",
      "a_18402\n",
      "a_18403\n",
      "a_18404\n",
      "a_18405\n",
      "a_18406\n",
      "a_18407\n",
      "a_18408\n",
      "a_18409\n",
      "a_18410\n",
      "a_18411\n",
      "a_18412\n",
      "a_18413\n",
      "a_18414\n",
      "a_18415\n",
      "a_18416\n",
      "a_18417\n",
      "a_18418\n",
      "a_18419\n",
      "a_18420\n",
      "a_18421\n",
      "a_18422\n",
      "a_18423\n",
      "a_18424\n",
      "a_18425\n",
      "a_18426\n",
      "a_18427\n",
      "a_18428\n",
      "a_18429\n",
      "a_18430\n",
      "a_18431\n",
      "a_18432\n",
      "a_18433\n",
      "a_18434\n",
      "a_18435\n",
      "a_18436\n",
      "a_18437\n",
      "a_18438\n",
      "a_18439\n",
      "a_18440\n",
      "a_18441\n",
      "a_18442\n",
      "a_18443\n",
      "a_18444\n",
      "a_18445\n",
      "a_18446\n",
      "a_18447\n",
      "a_18448\n",
      "a_18449\n",
      "a_18450\n",
      "a_18451\n",
      "a_18452\n",
      "a_18453\n",
      "a_18454\n",
      "a_18455\n",
      "a_18456\n",
      "a_18457\n",
      "a_18458\n",
      "a_18459\n",
      "a_18460\n",
      "a_18461\n",
      "a_18462\n",
      "a_18463\n",
      "a_18464\n",
      "a_18465\n",
      "a_18466\n",
      "a_18467\n",
      "a_18468\n",
      "a_18469\n",
      "a_18470\n",
      "a_18471\n",
      "a_18472\n",
      "a_18473\n",
      "a_18474\n",
      "a_18475\n",
      "a_18476\n",
      "a_18477\n",
      "a_18478\n",
      "a_18479\n",
      "a_18480\n",
      "a_18481\n",
      "a_18482\n",
      "a_18483\n",
      "a_18484\n",
      "a_18485\n",
      "a_18486\n",
      "a_18487\n",
      "a_18488\n",
      "a_18489\n",
      "a_18490\n",
      "a_18491\n",
      "a_18492\n",
      "a_18493\n",
      "a_18494\n",
      "a_18495\n",
      "a_18496\n",
      "a_18497\n",
      "a_18498\n",
      "a_18499\n",
      "a_18500\n",
      "a_18501\n",
      "a_18502\n",
      "a_18503\n",
      "a_18504\n",
      "a_18505\n",
      "a_18506\n",
      "a_18507\n",
      "a_18508\n",
      "a_18509\n",
      "a_18510\n",
      "a_18511\n",
      "a_18512\n",
      "a_18513\n",
      "a_18514\n",
      "a_18515\n",
      "a_18516\n",
      "a_18517\n",
      "a_18518\n",
      "a_18519\n",
      "a_18520\n",
      "a_18521\n",
      "a_18522\n",
      "a_18523\n",
      "a_18524\n",
      "a_18525\n",
      "a_18526\n",
      "a_18527\n",
      "a_18528\n",
      "a_18529\n",
      "a_18530\n",
      "a_18531\n",
      "a_18532\n",
      "a_18533\n",
      "a_18534\n",
      "a_18535\n",
      "a_18536\n",
      "a_18537\n",
      "a_18538\n",
      "a_18539\n",
      "a_18540\n",
      "a_18541\n",
      "a_18542\n",
      "a_18543\n",
      "a_18544\n",
      "a_18545\n",
      "a_18546\n",
      "a_18547\n",
      "a_18548\n",
      "a_18549\n",
      "a_18550\n",
      "a_18551\n",
      "a_18552\n",
      "a_18553\n",
      "a_18554\n",
      "a_18555\n",
      "a_18556\n",
      "a_18557\n",
      "a_18558\n",
      "a_18559\n",
      "a_18560\n",
      "a_18561\n",
      "a_18562\n",
      "a_18563\n",
      "a_18564\n",
      "a_18565\n",
      "a_18566\n",
      "a_18567\n",
      "a_18568\n",
      "a_18569\n",
      "a_18570\n",
      "a_18571\n",
      "a_18572\n",
      "a_18573\n",
      "a_18574\n",
      "a_18575\n",
      "a_18576\n",
      "a_18577\n",
      "a_18578\n",
      "a_18579\n",
      "a_18580\n",
      "a_18581\n",
      "a_18582\n",
      "a_18583\n",
      "a_18584\n",
      "a_18585\n",
      "a_18586\n",
      "a_18587\n",
      "a_18588\n",
      "a_18589\n",
      "a_18590\n",
      "a_18591\n",
      "a_18592\n",
      "a_18593\n",
      "a_18594\n",
      "a_18595\n",
      "a_18596\n",
      "a_18597\n",
      "a_18598\n",
      "a_18599\n",
      "a_18600\n",
      "a_18601\n",
      "a_18602\n",
      "a_18603\n",
      "a_18604\n",
      "a_18605\n",
      "a_18606\n",
      "a_18607\n",
      "a_18608\n",
      "a_18609\n",
      "a_18610\n",
      "a_18611\n",
      "a_18612\n",
      "a_18613\n",
      "a_18614\n",
      "a_18615\n",
      "a_18616\n",
      "a_18617\n",
      "a_18618\n",
      "a_18619\n",
      "a_18620\n",
      "generating train, val, test sets \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m time_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mload_MAG_data_acled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/niamatzawad/HTGNN/utils/data.py:227\u001b[0m, in \u001b[0;36mload_MAG_data_acled\u001b[0;34m(glist, time_window, device)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(glist)):\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m time_window:\n\u001b[0;32m--> 227\u001b[0m         G_feat \u001b[38;5;241m=\u001b[39m construct_htg_mag(glist, i, time_window)\n\u001b[1;32m    228\u001b[0m         pos_label, neg_label \u001b[38;5;241m=\u001b[39m construct_htg_label_mag_acled(glist, i, device)\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(glist)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/niamatzawad/HTGNN/utils/data.py:184\u001b[0m, in \u001b[0;36mconstruct_htg_label_mag_acled\u001b[0;34m(glist, idx, device)\u001b[0m\n\u001b[1;32m    181\u001b[0m neg_src \u001b[38;5;241m=\u001b[39m indices_false[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    182\u001b[0m neg_dst \u001b[38;5;241m=\u001b[39m indices_false[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 184\u001b[0m neg_idx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandperm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneg_src\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:size]\n\u001b[1;32m    185\u001b[0m neg_src \u001b[38;5;241m=\u001b[39m neg_src[neg_idx]\n\u001b[1;32m    186\u001b[0m neg_dst \u001b[38;5;241m=\u001b[39m neg_dst[neg_idx]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "time_window = 2\n",
    "\n",
    "load_MAG_data_acled(glist, time_window, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mp2vec\n",
      "generating train, val, test sets \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'actor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m time_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 5\u001b[0m train_feats, train_labels, val_feats, val_labels, test_feats, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_MAG_data_acled_time_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglist\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/niamatzawad/HTGNN/utils/data.py:262\u001b[0m, in \u001b[0;36mload_MAG_data_acled_time_split\u001b[0;34m(glist, val_start, val_end, device)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(glist)):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m val_start:\n\u001b[0;32m--> 262\u001b[0m         G_feat \u001b[38;5;241m=\u001b[39m \u001b[43mconstruct_htg_mag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_start\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m         pos_label, neg_label \u001b[38;5;241m=\u001b[39m construct_htg_label_mag_acled(glist, i, device)\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m val_end:\n",
      "File \u001b[0;32m~/niamatzawad/HTGNN/utils/data.py:87\u001b[0m, in \u001b[0;36mconstruct_htg_mag\u001b[0;34m(glist, idx, time_window)\u001b[0m\n\u001b[1;32m     83\u001b[0m         hetero_dict[(srctype, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00metype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_t\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, dsttype)] \u001b[38;5;241m=\u001b[39m (new_new_src, new_new_dst)\n\u001b[1;32m     84\u001b[0m         hetero_dict[(dsttype, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00metype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_r_t\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, srctype)] \u001b[38;5;241m=\u001b[39m (new_new_dst, new_new_src)\n\u001b[1;32m     86\u001b[0m node_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactor\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(\u001b[43mglist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m),\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(glist[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_ID\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     89\u001b[0m }\n\u001b[1;32m     90\u001b[0m G_feat \u001b[38;5;241m=\u001b[39m dgl\u001b[38;5;241m.\u001b[39mheterograph(hetero_dict, num_nodes_dict\u001b[38;5;241m=\u001b[39mnode_data)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (t, g_s) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sub_glist):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'actor'"
     ]
    }
   ],
   "source": [
    "glist, label_dict = load_graphs('data/ogbn_graphs.bin')\n",
    "device = torch.device('cuda:0')\n",
    "time_window = 2\n",
    "\n",
    "train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = load_MAG_data(glist, time_window, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glist[0].nodes['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 420, ('actor', 'involved_with', 'actor'): 460},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 493, ('actor', 'involved_with', 'actor'): 514},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 559, ('actor', 'involved_with', 'actor'): 594},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 538, ('actor', 'involved_with', 'actor'): 562},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 502, ('actor', 'involved_with', 'actor'): 544},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 528, ('actor', 'involved_with', 'actor'): 582},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 481, ('actor', 'involved_with', 'actor'): 506},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 457, ('actor', 'involved_with', 'actor'): 516},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 506, ('actor', 'involved_with', 'actor'): 584},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('actor', 'involved_in', 'action'): 526, ('actor', 'involved_with', 'actor'): 591},\n",
       "       metagraph=[('actor', 'action', 'involved_in'), ('actor', 'actor', 'involved_with')])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'actor1': 14328, 'actor2': 14328},\n",
       "      num_edges={('actor1', 'involved_with_t0', 'actor2'): 832, ('actor1', 'involved_with_t1', 'actor2'): 3176, ('actor2', 'involved_with_r_t0', 'actor1'): 832, ('actor2', 'involved_with_r_t1', 'actor1'): 3176},\n",
       "      metagraph=[('actor1', 'actor2', 'involved_with_t0'), ('actor1', 'actor2', 'involved_with_t1'), ('actor2', 'actor1', 'involved_with_r_t0'), ('actor2', 'actor1', 'involved_with_r_t1')])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Graph(num_nodes=18622, num_edges=4209,\n",
       "        ndata_schemes={}\n",
       "        edata_schemes={}),\n",
       "  Graph(num_nodes=18622, num_edges=4209,\n",
       "        ndata_schemes={}\n",
       "        edata_schemes={}))]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mp2vec\n",
      "generating train, val, test sets \n"
     ]
    }
   ],
   "source": [
    "glist, label_dict = load_graphs('graph_data_acled.bin')\n",
    "time_window = 2\n",
    "device = torch.device('cuda:0')\n",
    "train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = load_MAG_data_acled_time_split(glist[:7], 2, 3, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1997,2025)]\n",
    "y = [i for i in range(len(x))]\n",
    "dict_year_int = dict(zip(x,y))\n",
    "dict_ind_year = dict(zip(y,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997 2000 2001 2004 2005 2024\n",
      "1997 2000 2005 2008 2009 2024\n",
      "1997 2000 2009 2012 2013 2024\n",
      "1997 2000 2013 2016 2017 2024\n",
      "1997 2000 2017 2020 2021 2024\n",
      "2001 2004 2005 2008 2009 2024\n",
      "2001 2004 2009 2012 2013 2024\n",
      "2001 2004 2013 2016 2017 2024\n",
      "2001 2004 2017 2020 2021 2024\n",
      "2005 2008 2009 2012 2013 2024\n",
      "2005 2008 2013 2016 2017 2024\n",
      "2005 2008 2017 2020 2021 2024\n",
      "2009 2012 2013 2016 2017 2024\n",
      "2009 2012 2017 2020 2021 2024\n",
      "2013 2016 2017 2020 2021 2024\n"
     ]
    }
   ],
   "source": [
    "for train_start in range(1997, 2018, 4):\n",
    "    train_end = train_start+3 if train_start+3<2018 else 2017\n",
    "    if train_start == train_end:continue\n",
    "    for val_start in range(train_end+1, 2022, 4):\n",
    "        val_end = val_start+3 if val_start+3<2022 else 2021\n",
    "        if val_start == val_end:continue\n",
    "        test_start = val_end+1 if val_end+1<2025 else 2024\n",
    "        test_end = 2024\n",
    "        if test_start == test_end:continue\n",
    "        print(train_start, train_end, val_start, val_end, test_start, test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997 2000 2001 2004 2005 2024\n",
      "creating splits train_0-3_valid_4-7_test_8-27\n",
      "generating feats and labels \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import utils.data\n",
    "importlib.reload(utils)\n",
    "importlib.reload(utils.data)\n",
    "from utils.data import load_MAG_data,load_MAG_data_acled,load_MAG_data_acled_time_split, generate_APA_acled, construct_htg_label_mag_acled, load_MAG_data_acled_general\n",
    "import os\n",
    "\n",
    "\n",
    "glist, label_dict = load_graphs('graph_data_acled.bin')\n",
    "device = torch.device('cuda:0')\n",
    "time_window = 1\n",
    "\n",
    "folder_path = \"splits/train_1997-2000_valid_2001-2002_test_2003-2005\"\n",
    "\n",
    "for train_start in range(1997, 2018, 4):\n",
    "    train_end = train_start+3 if train_start+3<2018 else 2017\n",
    "    if train_start == train_end:continue\n",
    "    for val_start in range(train_end+1, 2022, 4):\n",
    "        val_end = val_start+3 if val_start+3<2022 else 2021\n",
    "        if val_start == val_end:continue\n",
    "        test_start = val_end+1 if val_end+1<2025 else 2024\n",
    "        test_end = 2024\n",
    "        if test_start == test_end:continue\n",
    "        print(train_start, train_end, val_start, val_end, test_start, test_end)\n",
    "        print(f\"creating splits train_{dict_ind_year[train_start]}-{dict_ind_year[train_end]}_valid_{dict_ind_year[val_start]}-{dict_ind_year[val_end]}_test_{dict_ind_year[test_start]}-{dict_ind_year[test_end]}\")\n",
    "        \n",
    "        train_feats, train_labels = load_MAG_data_acled_general(glist, dict_ind_year[train_start], dict_ind_year[train_end], time_window, device)\n",
    "        val_feats, val_labels = load_MAG_data_acled_general(glist, dict_ind_year[val_start], dict_ind_year[val_end], time_window, device)\n",
    "        test_feats, test_labels = load_MAG_data_acled_general(glist, dict_ind_year[test_start], dict_ind_year[test_end], time_window, device)\n",
    "\n",
    "        current_folder = f\"splits/train_{dict_ind_year[train_start]}-{dict_ind_year[train_end]}_valid_{dict_ind_year[val_start]}-{dict_ind_year[val_end]}_test_{dict_ind_year[test_start]}-{dict_ind_year[test_end]}\"\n",
    "        os.makedirs(current_folder, exist_ok=True)\n",
    "\n",
    "        torch.save(train_feats, current_folder + '/train_feats.pt')\n",
    "        torch.save(train_labels, current_folder + '/train_labels.pt')\n",
    "        torch.save(val_feats, current_folder + '/val_feats.pt')\n",
    "        torch.save(val_labels, current_folder + '/val_labels.pt')\n",
    "        torch.save(test_feats, current_folder + '/test_feats.pt')\n",
    "        torch.save(test_labels, current_folder + '/test_labels.pt')\n",
    "\n",
    "            \n",
    "        \n",
    "# train_feats, train_labels = load_MAG_data_acled_general(glist, 0, 5, time_window, device)\n",
    "# val_feats, val_labels = load_MAG_data_acled_general(glist, 5, 7, time_window, device)\n",
    "# test_feats, test_labels = load_MAG_data_acled_general(glist, 7, 10, time_window, device)\n",
    "\n",
    "\n",
    "# os.makedirs(folder_path, exist_ok=True)  # The `exist_ok` avoids error if the directory exists\n",
    "\n",
    "# torch.save(train_feats, folder_path + '/train_feats.pt')\n",
    "# torch.save(train_labels, folder_path + '/train_labels.pt')\n",
    "# torch.save(val_feats, folder_path + '/val_feats.pt')\n",
    "# torch.save(val_labels, folder_path + '/val_labels.pt')\n",
    "# torch.save(test_feats, folder_path + '/test_feats.pt')\n",
    "# torch.save(test_labels, folder_path + '/test_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'splits/time_window_1/train_0-3_valid_4-7_test_8-27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2785515/2441314985.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    }
   ],
   "source": [
    "train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('action', 'involved_in_r_t0', 'actor'): 559, ('actor', 'involved_in_t0', 'action'): 559, ('actor', 'involved_with_r_t0', 'actor'): 594, ('actor', 'involved_with_t0', 'actor'): 594},\n",
       "       metagraph=[('action', 'actor', 'involved_in_r_t0'), ('actor', 'action', 'involved_in_t0'), ('actor', 'actor', 'involved_with_r_t0'), ('actor', 'actor', 'involved_with_t0')])]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the data\n",
    "with open(\"splits/train_1997_1999/val_2000_test_2001.pkl\", \"wb\") as f:\n",
    "    pickle.dump((train_feats, train_labels, val_feats, val_labels, test_feats, test_labels), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_feats[0].nodes['actor'].data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# glist, label_dict = load_graphs('data/ogbn_graphs.bin')\n",
    "# glist, label_dict = load_graphs('graph_data_acled.bin')\n",
    "# device = torch.device('cuda:0')\n",
    "# time_window = 2\n",
    "import model.model\n",
    "import importlib\n",
    "importlib.reload(model.model)\n",
    "from model.model import HTGNN, LinkPredictor\n",
    "model_out_path = 'output/acled-MAG'\n",
    "import pdb\n",
    "\n",
    "import utils.utils\n",
    "importlib.reload(utils.utils)\n",
    "from utils.utils import compute_metric, compute_loss\n",
    "\n",
    "\n",
    "auc_list, ap_list  = [], []\n",
    "time_window=2\n",
    "\n",
    "\n",
    "\n",
    "def initialize_model(time_window, graph_atom):\n",
    "    device = torch.device('cuda:0')\n",
    "    htgnn = HTGNN(graph=graph_atom, n_inp=128, n_hid=32, n_layers=2, n_heads=1, \n",
    "                time_window=time_window, norm=True, device=device)\n",
    "    predictor = LinkPredictor(n_inp=32, n_classes=1)\n",
    "    new_model = nn.Sequential(htgnn, predictor).to(device)\n",
    "    return new_model\n",
    "\n",
    "# train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = load_MAG_data_acled(glist[:5], time_window, device)\n",
    "\n",
    "def train_eval_model(time_window, train_feats, train_labels, val_feats, val_labels, test_feats, test_labels):\n",
    "    f1_list_val = []\n",
    "    f1_list_test = []\n",
    "    device = torch.device('cuda:0')\n",
    "    for k in range(1):\n",
    "        # model = initialize_model(len(train_feats[0].nodes['actor'].data.keys()))\n",
    "        model = initialize_model(time_window, test_feats[0])\n",
    "        print(f'---------------Repeat time: {k+1}---------------------')\n",
    "        print(f'# params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=5e-4)\n",
    "\n",
    "        early_stopping = EarlyStopping(patience=50, verbose=True, path=f'{model_out_path}/checkpoint_HTGNN_{k}.pt')\n",
    "        for epoch in tqdm(range(10)):\n",
    "        # for epoch in tqdm(range(500)):\n",
    "            model.train()\n",
    "            for (G_feat, (pos_label, neg_label)) in zip(train_feats, train_labels):\n",
    "\n",
    "                G_feat = G_feat.to(device)\n",
    "\n",
    "                pos_label = pos_label.to(device)\n",
    "                neg_label = neg_label.to(device)\n",
    "                \n",
    "                # h = model[0](G_feat, 'author')\n",
    "                h = model[0](G_feat, 'actor')\n",
    "                pos_score = model[1](pos_label, h)\n",
    "                neg_score = model[1](neg_label, h)\n",
    "\n",
    "                loss = compute_loss(pos_score, neg_score, device)\n",
    "                auc, ap, acc, f1 = compute_metric(pos_score, neg_score)\n",
    "                \n",
    "                # if epoch==4:\n",
    "                #     pdb.set_trace()\n",
    "\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "            \n",
    "\n",
    "            auc, ap, auc_mean, ap_mean, acc_mean, f1_mean = evaluate(model, val_feats, val_labels)\n",
    "            f1_list_val.append(f1_mean)\n",
    "\n",
    "            auc, ap, auc_mean, ap_mean, acc_mean, f1_mean = evaluate(model, test_feats, test_labels)\n",
    "            f1_list_test.append(f1_mean)\n",
    "\n",
    "            early_stopping(loss, model)\n",
    "\n",
    "            # model = initialize_model(len(val_feats[0].nodes['actor'].data.keys()))\n",
    "            # auc, ap = evaluate(model, val_feats, val_labels)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        # model = initialize_model(len(test_feats[0].nodes['actor'].data.keys()))\n",
    "        # auc, ap, auc_mean, ap_mean, acc_mean, f1_mean = evaluate(model, test_feats, test_labels)\n",
    "\n",
    "        print(f'auc: {auc}, ap: {ap}')\n",
    "        print(f'auc mean: {auc_mean}, ap mean: {ap_mean}, acc mean: {acc_mean}, f1 mean: {f1_mean} ')\n",
    "        auc_list.append(auc)\n",
    "        ap_list.append(ap)\n",
    "    return f1_list_val, f1_list_test\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model for each of the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.037037037037037035\n",
      "0.6666666666666666\n",
      "0.0\n",
      "0.0\n",
      "0.6282722513089005\n",
      "0.9420289855072463\n",
      "0.6776315789473685\n",
      "0.9045226130653267\n",
      "0.9317738791423001\n",
      "0.9333333333333333\n",
      "0.9196261682242991\n",
      "0.6837242359630419\n",
      "0.7702805155420773\n",
      "0.8159057437407953\n",
      "0.8216650898770104\n",
      "0.819954128440367\n",
      "0.6801593625498008\n",
      "0.7390865222758388\n",
      "0.6682049276495894\n",
      "0.7528136723634847\n",
      "0.5581582902599069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:15,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5654320987654321\n",
      "0.7131665975077647\n",
      "0.7504343091243809\n",
      "Validation loss decreased (inf --> 0.355949).  Saving model ...\n",
      "0.926208651399491\n",
      "0.8984375\n",
      "0.9347826086956522\n",
      "0.9534883720930233\n",
      "0.8870967741935484\n",
      "0.9701492537313433\n",
      "0.8274231678486997\n",
      "0.906801007556675\n",
      "0.9487666034155597\n",
      "0.941398865784499\n",
      "0.9236363636363636\n",
      "0.7019687712152071\n",
      "0.7736248236953456\n",
      "0.8303330333033303\n",
      "0.8212775428444247\n",
      "0.8161626973508161\n",
      "0.6761067223133105\n",
      "0.7273684210526316\n",
      "0.6611587830650308\n",
      "0.7238446271618939\n",
      "0.5238993301684334\n",
      "0.528720425528059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:13,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6830018103772189\n",
      "0.7196148092744952\n",
      "Validation loss decreased (0.355949 --> 0.253046).  Saving model ...\n",
      "0.9519230769230769\n",
      "0.9338235294117647\n",
      "0.9469964664310954\n",
      "0.9452449567723343\n",
      "0.8906882591093117\n",
      "0.9701492537313433\n",
      "0.815347721822542\n",
      "0.906801007556675\n",
      "0.950381679389313\n",
      "0.9449715370018975\n",
      "0.9253187613843351\n",
      "0.7031621897313839\n",
      "0.7704918032786885\n",
      "0.8309287646528404\n",
      "0.8232931726907631\n",
      "0.8165680473372781\n",
      "0.6777329146104382\n",
      "0.729749709578625\n",
      "0.6638646482635797\n",
      "0.727844183056336\n",
      "0.5268701141530108\n",
      "0.5328825947921425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:05<00:12,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6884056306978666\n",
      "0.7231922543651447\n",
      "Validation loss decreased (0.253046 --> 0.243580).  Saving model ...\n",
      "0.9391727493917275\n",
      "0.9372693726937269\n",
      "0.9469964664310954\n",
      "0.9479768786127167\n",
      "0.8870967741935484\n",
      "0.9701492537313433\n",
      "0.7841191066997518\n",
      "0.8865979381443299\n",
      "0.9382239382239382\n",
      "0.9447619047619048\n",
      "0.927007299270073\n",
      "0.69666781174854\n",
      "0.7717041800643086\n",
      "0.8294344764933\n",
      "0.8219424460431655\n",
      "0.818058934847256\n",
      "0.6779864763335838\n",
      "0.7300711177157414\n",
      "0.6646052063857327\n",
      "0.7302577888723537\n",
      "0.5292075771099871\n",
      "0.5340057344630164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:06<00:10,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6871852006591928\n",
      "0.7254335260115607\n",
      "Validation loss decreased (0.243580 --> 0.235112).  Saving model ...\n",
      "0.9391727493917275\n",
      "0.9333333333333333\n",
      "0.9466192170818505\n",
      "0.9507246376811594\n",
      "0.8870967741935484\n",
      "0.9701492537313433\n",
      "0.8229665071770335\n",
      "0.9063291139240506\n",
      "0.950381679389313\n",
      "0.9431818181818182\n",
      "0.9253187613843351\n",
      "0.7029231815091774\n",
      "0.7719049308265342\n",
      "0.8308939428056744\n",
      "0.822742474916388\n",
      "0.8171812080536913\n",
      "0.676923076923077\n",
      "0.7281348788198103\n",
      "0.6629445234708392\n",
      "0.7258837485172005\n",
      "0.5254198597749877\n",
      "0.5309465522419301\n",
      "0.6857659141334431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:08<00:08,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7214736003374658\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9493975903614458\n",
      "0.9372693726937269\n",
      "0.9469964664310954\n",
      "0.9452449567723343\n",
      "0.8861788617886179\n",
      "0.9662921348314607\n",
      "0.8238095238095238\n",
      "0.906801007556675\n",
      "0.9505703422053232\n",
      "0.9391634980988594\n",
      "0.927007299270073\n",
      "0.7022071307300509\n",
      "0.7734650670430487\n",
      "0.8303330333033303\n",
      "0.821460373998219\n",
      "0.8161626973508161\n",
      "0.6759093619558736\n",
      "0.7275981889017584\n",
      "0.6613933030646992\n",
      "0.7242553191489361\n",
      "0.5240186034409862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:10<00:06,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5288785758311881\n",
      "0.6831962825448168\n",
      "0.719951360957815\n",
      "Validation loss decreased (0.235112 --> 0.234577).  Saving model ...\n",
      "0.9493975903614458\n",
      "0.9338235294117647\n",
      "0.950354609929078\n",
      "0.9449275362318841\n",
      "0.8842975206611571\n",
      "0.9699248120300752\n",
      "0.7851851851851852\n",
      "0.8979591836734694\n",
      "0.9483747609942639\n",
      "0.9467680608365019\n",
      "0.9253187613843351\n",
      "0.7031621897313839\n",
      "0.7724529641462549\n",
      "0.8303671998197792\n",
      "0.8229259589652096\n",
      "0.8171812080536913\n",
      "0.6772218073188947\n",
      "0.7284419144001687\n",
      "0.6632039560283184\n",
      "0.7263317823568513\n",
      "0.5255912575436307\n",
      "0.5311347640422839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:12<00:05,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6862603719599428\n",
      "0.7218965436383248\n",
      "Validation loss decreased (0.234577 --> 0.231885).  Saving model ...\n",
      "0.9468599033816425\n",
      "0.9338235294117647\n",
      "0.9436619718309859\n",
      "0.9452449567723343\n",
      "0.8870967741935484\n",
      "0.9701492537313433\n",
      "0.8125\n",
      "0.9012658227848102\n",
      "0.9507575757575758\n",
      "0.9429657794676806\n",
      "0.9253187613843351\n",
      "0.7028862478777589\n",
      "0.7712464589235127\n",
      "0.8307068887888338\n",
      "0.8221925133689839\n",
      "0.8164031090860359\n",
      "0.6763126491646778\n",
      "0.7275981889017584\n",
      "0.662975189010755\n",
      "0.724226072138597\n",
      "0.5241518394431253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:13<00:03,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5295601822439236\n",
      "0.6843360297557247\n",
      "0.7204379049802334\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9493975903614458\n",
      "0.9333333333333333\n",
      "0.9432624113475178\n",
      "0.9442815249266863\n",
      "0.8852459016393442\n",
      "0.9696969696969697\n",
      "0.8077858880778589\n",
      "0.906801007556675\n",
      "0.9501915708812261\n",
      "0.9449715370018975\n",
      "0.9253187613843351\n",
      "0.7029231815091774\n",
      "0.7696689213243147\n",
      "0.8306306306306306\n",
      "0.822742474916388\n",
      "0.8174006444683136\n",
      "0.6769184831292924\n",
      "0.7289029535864979\n",
      "0.6632043255549231\n",
      "0.7260215462009397\n",
      "0.525337507337116\n",
      "0.530941393841757\n",
      "0.6862132500200272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:15<00:01,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7219994841855994\n",
      "Validation loss decreased (0.231885 --> 0.230984).  Saving model ...\n",
      "0.9542168674698795\n",
      "0.9372693726937269\n",
      "0.9469964664310954\n",
      "0.9452449567723343\n",
      "0.8906882591093117\n",
      "0.9737827715355806\n",
      "0.8249400479616307\n",
      "0.9090909090909091\n",
      "0.9483747609942639\n",
      "0.9449715370018975\n",
      "0.9253187613843351\n",
      "0.703125\n",
      "0.771793054571226\n",
      "0.8304435937851835\n",
      "0.8225590726705305\n",
      "0.8168409761330115\n",
      "0.6767164179104478\n",
      "0.7279047719372169\n",
      "0.6626625915132561\n",
      "0.7246376811594203\n",
      "0.5244108839994792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5300171682396649\n",
      "0.6847147212294904\n",
      "0.7209982909184557\n",
      "EarlyStopping counter: 1 out of 50\n",
      "auc: 0.755830752312773, ap: 0.7393809784255796\n",
      "auc mean: 0.6673367400187041, ap mean: 0.675422137850262, acc mean: 0.6047505022169902, f1 mean: 0.6412402228432944 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08771929824561403\n",
      "0.6666666666666666\n",
      "0.0\n",
      "0.8203389830508474\n",
      "0.90625\n",
      "0.9389312977099237\n",
      "0.7804878048780488\n",
      "0.8707124010554089\n",
      "0.906187624750499\n",
      "0.9333333333333333\n",
      "0.9104204753199269\n",
      "0.7026476578411406\n",
      "0.7779359430604982\n",
      "0.8263607737291948\n",
      "0.8226068144943213\n",
      "0.679994032522751\n",
      "0.7383504935781764\n",
      "0.6537915066042204\n",
      "0.6611226611226612\n",
      "0.719461549477302\n",
      "0.5184701309729889\n",
      "0.5234786731586337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:15,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6774907075912708\n",
      "0.7184747985759791\n",
      "Validation loss decreased (inf --> 0.267886).  Saving model ...\n",
      "0.9383886255924171\n",
      "0.9433962264150944\n",
      "0.96\n",
      "0.9337175792507204\n",
      "0.9090909090909091\n",
      "0.9398496240601504\n",
      "0.8539325842696629\n",
      "0.9095477386934674\n",
      "0.9284332688588007\n",
      "0.9325842696629213\n",
      "0.9184397163120568\n",
      "0.7094617184887997\n",
      "0.7743988684582744\n",
      "0.8310077519379845\n",
      "0.823247134097574\n",
      "0.6775051729234407\n",
      "0.7387406171809842\n",
      "0.6530971617982183\n",
      "0.6579344734347017\n",
      "0.7169102100267819\n",
      "0.5153873250712524\n",
      "0.5203126956583961\n",
      "0.6750969709199345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:13,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7130454807138745\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9364705882352942\n",
      "0.9591078066914498\n",
      "0.96\n",
      "0.9337175792507204\n",
      "0.9090909090909091\n",
      "0.9398496240601504\n",
      "0.8539325842696629\n",
      "0.9095477386934674\n",
      "0.9284332688588007\n",
      "0.9325842696629213\n",
      "0.9184397163120568\n",
      "0.7073825503355705\n",
      "0.7729226361031518\n",
      "0.8291592128801432\n",
      "0.824764468371467\n",
      "0.6825846888524101\n",
      "0.7444163506110408\n",
      "0.6579557428872498\n",
      "0.6605015116485862\n",
      "0.7274555816292323\n",
      "0.5243320922333268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:05<00:11,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5318404222177426\n",
      "0.6870661015007447\n",
      "0.7210977217096592\n",
      "EarlyStopping counter: 2 out of 50\n",
      "0.9307875894988067\n",
      "0.9552238805970149\n",
      "0.9446494464944649\n",
      "0.9446064139941691\n",
      "0.92\n",
      "0.9393939393939394\n",
      "0.8447488584474886\n",
      "0.9086294416243654\n",
      "0.9197651663405088\n",
      "0.9343339587242027\n",
      "0.9184397163120568\n",
      "0.7094617184887997\n",
      "0.7743988684582744\n",
      "0.8310077519379845\n",
      "0.823247134097574\n",
      "0.6775051729234407\n",
      "0.7387406171809842\n",
      "0.6530971617982183\n",
      "0.6579344734347017\n",
      "0.7169102100267819\n",
      "0.5153873250712524\n",
      "0.5203126956583961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:06<00:10,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6750969709199345\n",
      "0.7130454807138745\n",
      "Validation loss decreased (0.267886 --> 0.255342).  Saving model ...\n",
      "0.9361702127659575\n",
      "0.9591078066914498\n",
      "0.96\n",
      "0.9337175792507204\n",
      "0.9090909090909091\n",
      "0.9433962264150944\n",
      "0.8539325842696629\n",
      "0.9095477386934674\n",
      "0.9320388349514563\n",
      "0.9325842696629213\n",
      "0.9162210338680927\n",
      "0.7073825503355705\n",
      "0.7729226361031518\n",
      "0.8291592128801432\n",
      "0.824764468371467\n",
      "0.6825846888524101\n",
      "0.7444163506110408\n",
      "0.6579557428872498\n",
      "0.6605015116485862\n",
      "0.7274555816292323\n",
      "0.5243320922333268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:08<00:08,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5318404222177426\n",
      "0.6870661015007447\n",
      "0.7210977217096592\n",
      "Validation loss decreased (0.255342 --> 0.250673).  Saving model ...\n",
      "0.9307875894988067\n",
      "0.9591078066914498\n",
      "0.9485294117647058\n",
      "0.9418604651162791\n",
      "0.92\n",
      "0.9433962264150944\n",
      "0.8526077097505669\n",
      "0.9095477386934674\n",
      "0.9302325581395349\n",
      "0.9325842696629213\n",
      "0.9123434704830053\n",
      "0.7073825503355705\n",
      "0.7728085867620751\n",
      "0.8291592128801432\n",
      "0.8252688172043011\n",
      "0.6821774794929157\n",
      "0.7442595323362123\n",
      "0.6577174141924615\n",
      "0.6602921835566772\n",
      "0.7270290964777948\n",
      "0.5237334029295664\n",
      "0.5311290632462055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:10<00:06,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6862000320344142\n",
      "0.7202858015841305\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9333333333333333\n",
      "0.9552238805970149\n",
      "0.9523809523809523\n",
      "0.9391304347826087\n",
      "0.9126984126984127\n",
      "0.9433962264150944\n",
      "0.8539325842696629\n",
      "0.906801007556675\n",
      "0.9115913555992141\n",
      "0.9325842696629213\n",
      "0.9181494661921709\n",
      "0.7094617184887997\n",
      "0.7743988684582744\n",
      "0.8310077519379845\n",
      "0.823247134097574\n",
      "0.6775051729234407\n",
      "0.7387406171809842\n",
      "0.6530971617982183\n",
      "0.6579344734347017\n",
      "0.7169102100267819\n",
      "0.5153873250712524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:11<00:05,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5203126956583961\n",
      "0.6750969709199345\n",
      "0.7130454807138745\n",
      "Validation loss decreased (0.250673 --> 0.249010).  Saving model ...\n",
      "0.9383886255924171\n",
      "0.9588014981273408\n",
      "0.9485294117647058\n",
      "0.9337175792507204\n",
      "0.9126984126984127\n",
      "0.9358490566037736\n",
      "0.8539325842696629\n",
      "0.906801007556675\n",
      "0.9284332688588007\n",
      "0.9325842696629213\n",
      "0.9184397163120568\n",
      "0.7086403215003348\n",
      "0.7733428367783322\n",
      "0.8304405874499332\n",
      "0.8240021430484865\n",
      "0.6798336798336798\n",
      "0.7416107382550335\n",
      "0.6549689278813515\n",
      "0.6590844871432608\n",
      "0.7219193020719739\n",
      "0.5198576972833118\n",
      "0.5256425334044997\n",
      "0.6808129786559115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:13<00:03,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7169600447052249\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9314420803782506\n",
      "0.9591078066914498\n",
      "0.9481481481481482\n",
      "0.9418604651162791\n",
      "0.9163346613545816\n",
      "0.9398496240601504\n",
      "0.8558558558558559\n",
      "0.9095477386934674\n",
      "0.9302325581395349\n",
      "0.9325842696629213\n",
      "0.9181494661921709\n",
      "0.7082077051926298\n",
      "0.7733428367783322\n",
      "0.8304405874499332\n",
      "0.8240021430484865\n",
      "0.6800356506238859\n",
      "0.7416885159937074\n",
      "0.6551057717419692\n",
      "0.6591310490992582\n",
      "0.7222617522887909\n",
      "0.519927536231884\n",
      "0.5257899880551634\n",
      "0.6809364093731587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:15<00:01,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7156917622912585\n",
      "EarlyStopping counter: 2 out of 50\n",
      "0.9311163895486936\n",
      "0.9591078066914498\n",
      "0.9481481481481482\n",
      "0.9473684210526315\n",
      "0.9156626506024096\n",
      "0.946969696969697\n",
      "0.8526077097505669\n",
      "0.906801007556675\n",
      "0.9302325581395349\n",
      "0.9325842696629213\n",
      "0.9200710479573713\n",
      "0.7094617184887997\n",
      "0.7740333451578574\n",
      "0.8307077878855115\n",
      "0.8241259674406192\n",
      "0.6786084381939305\n",
      "0.7398892256244122\n",
      "0.6539860721338738\n",
      "0.6586636626064916\n",
      "0.7192601679720676\n",
      "0.5169998071855517\n",
      "0.522814936028268\n",
      "0.6774415018739659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7140541041319252\n",
      "EarlyStopping counter: 3 out of 50\n",
      "auc: 0.7463187929260479, ap: 0.73051965521228\n",
      "auc mean: 0.7136367115603675, ap mean: 0.7306746138623976, acc mean: 0.6490587814497351, f1 mean: 0.6705843883191106 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.0\n",
      "0.0\n",
      "0.37037037037037035\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6651912741068606\n",
      "0.6669259187244799\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6669633585521436\n",
      "0.6667875929620896\n",
      "0.6667877576968486\n",
      "0.6667128891354087\n",
      "0.6666442388561816\n",
      "0.6667338658871557\n",
      "0.6667650858091899\n",
      "0.6666666666666666\n",
      "0.6666129220075422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:12,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6667433743719556\n",
      "Validation loss decreased (inf --> 0.684087).  Saving model ...\n",
      "0.6666666666666666\n",
      "0.9530685920577617\n",
      "0.9416058394160584\n",
      "0.92\n",
      "0.9061224489795918\n",
      "0.9253731343283582\n",
      "0.839907192575406\n",
      "0.9224806201550387\n",
      "0.9447619047619048\n",
      "0.9157894736842105\n",
      "0.4386206896551724\n",
      "0.7056010928961749\n",
      "0.7583482944344704\n",
      "0.8229643183897529\n",
      "0.8276779773785762\n",
      "0.847084117172803\n",
      "0.6860744297719088\n",
      "0.735431731178222\n",
      "0.6605204930987251\n",
      "0.6626957235082213\n",
      "0.7252263039417597\n",
      "0.522526054428436\n",
      "0.6896646289207564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:02<00:11,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7246921703167591\n",
      "Validation loss decreased (0.684087 --> 0.516818).  Saving model ...\n",
      "0.9486552567237164\n",
      "0.9530685920577617\n",
      "0.9454545454545454\n",
      "0.9147727272727273\n",
      "0.9061224489795918\n",
      "0.9253731343283582\n",
      "0.8375286041189931\n",
      "0.9272030651340997\n",
      "0.9429657794676806\n",
      "0.9078260869565218\n",
      "0.43668720054757015\n",
      "0.7039295392953929\n",
      "0.7616011335458732\n",
      "0.8225186524983044\n",
      "0.8207609412799648\n",
      "0.8438080084858128\n",
      "0.6806236080178174\n",
      "0.7294315435536408\n",
      "0.6554309052370366\n",
      "0.6581433739594675\n",
      "0.7145074065365624\n",
      "0.5130223331413579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:04<00:10,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6770296697770576\n",
      "0.7175439000253159\n",
      "Validation loss decreased (0.516818 --> 0.402797).  Saving model ...\n",
      "0.961352657004831\n",
      "0.9530685920577617\n",
      "0.9454545454545454\n",
      "0.9147727272727273\n",
      "0.9061224489795918\n",
      "0.9253731343283582\n",
      "0.8394495412844036\n",
      "0.9224806201550387\n",
      "0.9447619047619048\n",
      "0.9157894736842105\n",
      "0.4386206896551724\n",
      "0.7056010928961749\n",
      "0.7583482944344704\n",
      "0.8229643183897529\n",
      "0.8276779773785762\n",
      "0.8473938742611499\n",
      "0.6860744297719088\n",
      "0.735431731178222\n",
      "0.6612631578947369\n",
      "0.6626484539391562\n",
      "0.7250526719019345\n",
      "0.5223724606440656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:05<00:08,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6892936675612402\n",
      "0.7244286821523358\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9509803921568627\n",
      "0.9492753623188406\n",
      "0.9454545454545454\n",
      "0.9173789173789174\n",
      "0.9061224489795918\n",
      "0.9253731343283582\n",
      "0.8352668213457076\n",
      "0.91796875\n",
      "0.9465648854961832\n",
      "0.91005291005291\n",
      "0.4407484407484408\n",
      "0.6989690721649484\n",
      "0.7595667870036101\n",
      "0.8216589861751152\n",
      "0.8275245755138516\n",
      "0.8425900839880791\n",
      "0.6860587792012057\n",
      "0.736480686695279\n",
      "0.6601032409132032\n",
      "0.6639249639249639\n",
      "0.7262278456560584\n",
      "0.5258150827470023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:07<00:07,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6910397246190988\n",
      "0.7274842140245928\n",
      "EarlyStopping counter: 2 out of 50\n",
      "0.9458128078817734\n",
      "0.9454545454545454\n",
      "0.9454545454545454\n",
      "0.92\n",
      "0.9061224489795918\n",
      "0.9253731343283582\n",
      "0.8433179723502304\n",
      "0.9224806201550387\n",
      "0.9447619047619048\n",
      "0.9157894736842105\n",
      "0.4386206896551724\n",
      "0.7056010928961749\n",
      "0.7583482944344704\n",
      "0.8229643183897529\n",
      "0.8276779773785762\n",
      "0.8473938742611499\n",
      "0.6860744297719088\n",
      "0.735431731178222\n",
      "0.660346552904619\n",
      "0.6626484539391562\n",
      "0.7250526719019345\n",
      "0.5223724606440656\n",
      "0.6893094115094275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:08<00:05,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.724445697106351\n",
      "EarlyStopping counter: 3 out of 50\n",
      "0.9486552567237164\n",
      "0.9530685920577617\n",
      "0.9454545454545454\n",
      "0.92\n",
      "0.9061224489795918\n",
      "0.9253731343283582\n",
      "0.8433179723502304\n",
      "0.9224806201550387\n",
      "0.9447619047619048\n",
      "0.9157894736842105\n",
      "0.4386206896551724\n",
      "0.7056010928961749\n",
      "0.7583482944344704\n",
      "0.8229643183897529\n",
      "0.8276779773785762\n",
      "0.8473938742611499\n",
      "0.6860744297719088\n",
      "0.735431731178222\n",
      "0.660346552904619\n",
      "0.6626484539391562\n",
      "0.7250526719019345\n",
      "0.52235540024168\n",
      "0.6892936675612402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:10<00:04,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7244286821523358\n",
      "EarlyStopping counter: 4 out of 50\n",
      "0.9486552567237164\n",
      "0.9530685920577617\n",
      "0.9454545454545454\n",
      "0.92\n",
      "0.9061224489795918\n",
      "0.9253731343283582\n",
      "0.8433179723502304\n",
      "0.9224806201550387\n",
      "0.9447619047619048\n",
      "0.9157894736842105\n",
      "0.4386206896551724\n",
      "0.7056010928961749\n",
      "0.7583482944344704\n",
      "0.8229643183897529\n",
      "0.8276779773785762\n",
      "0.8473938742611499\n",
      "0.6860744297719088\n",
      "0.735431731178222\n",
      "0.660346552904619\n",
      "0.6626720878807333\n",
      "0.7250526719019345\n",
      "0.5223724606440656\n",
      "0.6893251561768368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:11<00:02,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.724445697106351\n",
      "EarlyStopping counter: 5 out of 50\n",
      "0.9486552567237164\n",
      "0.9530685920577617\n",
      "0.9454545454545454\n",
      "0.92\n",
      "0.9061224489795918\n",
      "0.9253731343283582\n",
      "0.8433179723502304\n",
      "0.9224806201550387\n",
      "0.9447619047619048\n",
      "0.9157894736842105\n",
      "0.4386206896551724\n",
      "0.7056010928961749\n",
      "0.7583482944344704\n",
      "0.8229643183897529\n",
      "0.8276779773785762\n",
      "0.8473938742611499\n",
      "0.6860744297719088\n",
      "0.735431731178222\n",
      "0.660346552904619\n",
      "0.6626484539391562\n",
      "0.7250526719019345\n",
      "0.52235540024168\n",
      "0.6892936675612402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:12<00:01,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7244286821523358\n",
      "EarlyStopping counter: 6 out of 50\n",
      "0.9486552567237164\n",
      "0.9530685920577617\n",
      "0.9454545454545454\n",
      "0.92\n",
      "0.9061224489795918\n",
      "0.9253731343283582\n",
      "0.8433179723502304\n",
      "0.9224806201550387\n",
      "0.9447619047619048\n",
      "0.9157894736842105\n",
      "0.4386206896551724\n",
      "0.7056010928961749\n",
      "0.7583482944344704\n",
      "0.8229643183897529\n",
      "0.8276779773785762\n",
      "0.8473938742611499\n",
      "0.6860744297719088\n",
      "0.735431731178222\n",
      "0.660346552904619\n",
      "0.6626484539391562\n",
      "0.7250526719019345\n",
      "0.52235540024168\n",
      "0.6892936675612402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7244797294123174\n",
      "EarlyStopping counter: 7 out of 50\n",
      "auc: 0.7493988917188295, ap: 0.7301558542130482\n",
      "auc mean: 0.7110691036033495, ap mean: 0.6873460433677572, acc mean: 0.6485609981810996, f1 mean: 0.7068866984867788 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6022727272727273\n",
      "0.0\n",
      "0.0\n",
      "0.7324675324675325\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.8454935622317596\n",
      "0.5777777777777777\n",
      "0.2900398406374502\n",
      "0.5415813191315035\n",
      "0.7476635514018691\n",
      "0.8215377380672466\n",
      "0.8249943400498075\n",
      "0.825109649122807\n",
      "0.68094284393776\n",
      "0.7358181221991474\n",
      "0.6666916251731496\n",
      "0.7295827565750445\n",
      "0.5357765546477044\n",
      "0.6930834533915963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:19,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7357211055891497\n",
      "Validation loss decreased (inf --> 0.559288).  Saving model ...\n",
      "0.9313725490196079\n",
      "0.9\n",
      "0.915129151291513\n",
      "0.9418604651162791\n",
      "0.9523809523809523\n",
      "0.96\n",
      "0.8524590163934426\n",
      "0.9193154034229829\n",
      "0.9341085271317829\n",
      "0.9283018867924528\n",
      "0.9090909090909091\n",
      "0.42778541953232463\n",
      "0.6952992898207643\n",
      "0.76113074204947\n",
      "0.8300341296928327\n",
      "0.8336803145963452\n",
      "0.8257510729613734\n",
      "0.6784225713369669\n",
      "0.7188797911475021\n",
      "0.5808795411089867\n",
      "0.73326971251342\n",
      "0.5431598113051395\n",
      "0.5312844453089541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:17,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7099319400108414\n",
      "Validation loss decreased (0.559288 --> 0.555788).  Saving model ...\n",
      "0.8756756756756757\n",
      "0.7947598253275109\n",
      "0.852589641434263\n",
      "0.9074074074074074\n",
      "0.921161825726141\n",
      "0.9505703422053232\n",
      "0.7672634271099744\n",
      "0.9137055837563451\n",
      "0.8805031446540881\n",
      "0.9260700389105059\n",
      "0.907103825136612\n",
      "0.4276729559748428\n",
      "0.6986162672966588\n",
      "0.7601683029453016\n",
      "0.8300609343263372\n",
      "0.824047566615283\n",
      "0.8245614035087719\n",
      "0.6836689038031319\n",
      "0.7355982274741507\n",
      "0.6605638425909042\n",
      "0.7290419890040384\n",
      "0.5346023660310332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:14,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.697365180989904\n",
      "0.7287636872316821\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9320388349514563\n",
      "0.8862745098039215\n",
      "0.8973384030418251\n",
      "0.9464285714285714\n",
      "0.9392712550607287\n",
      "0.9548872180451128\n",
      "0.7869674185463659\n",
      "0.9195979899497487\n",
      "0.9346534653465347\n",
      "0.9300567107750473\n",
      "0.9087656529516994\n",
      "0.43134535367545074\n",
      "0.6968876860622463\n",
      "0.7571378216425801\n",
      "0.8313035633739287\n",
      "0.8236847897864847\n",
      "0.8234048186391316\n",
      "0.6813056379821959\n",
      "0.7353654677776605\n",
      "0.6602651379433895\n",
      "0.7233433519393159\n",
      "0.5272286948553475\n",
      "0.6873142463709909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:12,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72279164015928\n",
      "EarlyStopping counter: 2 out of 50\n",
      "0.927536231884058\n",
      "0.9144981412639405\n",
      "0.9130434782608695\n",
      "0.9418604651162791\n",
      "0.9523809523809523\n",
      "0.9632352941176471\n",
      "0.8195121951219512\n",
      "0.9172932330827067\n",
      "0.9301397205588823\n",
      "0.9315589353612167\n",
      "0.9068100358422939\n",
      "0.4308547602501737\n",
      "0.6964467005076143\n",
      "0.7586452762923351\n",
      "0.8321933424532604\n",
      "0.8277543781866549\n",
      "0.827031375703942\n",
      "0.6836689038031319\n",
      "0.7355982274741507\n",
      "0.6601232268233271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:10<00:10,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7231018695154521\n",
      "0.5270734500245379\n",
      "0.6870060903575075\n",
      "0.7226213752326212\n",
      "EarlyStopping counter: 3 out of 50\n",
      "0.927536231884058\n",
      "0.9144981412639405\n",
      "0.9130434782608695\n",
      "0.9418604651162791\n",
      "0.9565217391304348\n",
      "0.967032967032967\n",
      "0.8483412322274881\n",
      "0.9215686274509803\n",
      "0.932806324110672\n",
      "0.9318181818181818\n",
      "0.9087656529516994\n",
      "0.4302567661346287\n",
      "0.6975956654249915\n",
      "0.7587437544610992\n",
      "0.8311212814645309\n",
      "0.8283681636282793\n",
      "0.8308362843911741\n",
      "0.6889161053276179\n",
      "0.7450894326785911\n",
      "0.663892923028614\n",
      "0.7486787713882057\n",
      "0.5572393646156655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:12<00:08,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7124790798927884\n",
      "0.7507337471753981\n",
      "Validation loss decreased (0.555788 --> 0.555179).  Saving model ...\n",
      "0.925\n",
      "0.8818897637795275\n",
      "0.8973384030418251\n",
      "0.9337349397590361\n",
      "0.9558232931726908\n",
      "0.9626865671641791\n",
      "0.8252427184466019\n",
      "0.9306930693069307\n",
      "0.9315068493150684\n",
      "0.9300567107750473\n",
      "0.9090909090909091\n",
      "0.42916093535075656\n",
      "0.6985195154777928\n",
      "0.7592267135325131\n",
      "0.8312274368231047\n",
      "0.8244106631416611\n",
      "0.8254304635761589\n",
      "0.6800059285608419\n",
      "0.7351670355148067\n",
      "0.6600995809005266\n",
      "0.7231018695154521\n",
      "0.5270734500245379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:14<00:06,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6870132700225946\n",
      "0.7226213752326212\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.927536231884058\n",
      "0.9144981412639405\n",
      "0.9130434782608695\n",
      "0.9418604651162791\n",
      "0.9523809523809523\n",
      "0.9705882352941176\n",
      "0.8117359413202934\n",
      "0.9181141439205955\n",
      "0.9288537549407114\n",
      "0.9315589353612167\n",
      "0.8989169675090253\n",
      "0.4316446911866759\n",
      "0.6983372921615202\n",
      "0.759800427655025\n",
      "0.8322270542458229\n",
      "0.8272949544343188\n",
      "0.8264019318486718\n",
      "0.6828319113905104\n",
      "0.7376628925443282\n",
      "0.6634531445705394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:16<00:04,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7412742382271468\n",
      "0.5506617183670611\n",
      "0.703068526379624\n",
      "0.739252711932503\n",
      "EarlyStopping counter: 2 out of 50\n",
      "0.9388753056234719\n",
      "0.8862745098039215\n",
      "0.9015151515151515\n",
      "0.9464285714285714\n",
      "0.9392712550607287\n",
      "0.9626865671641791\n",
      "0.8223844282238443\n",
      "0.9253731343283582\n",
      "0.9221556886227545\n",
      "0.9300567107750473\n",
      "0.9107142857142857\n",
      "0.4312370421561852\n",
      "0.6987870619946092\n",
      "0.7617709065354884\n",
      "0.8311864406779661\n",
      "0.8241006400353122\n",
      "0.8247806434458921\n",
      "0.6812045690550363\n",
      "0.7357993466118664\n",
      "0.6601232268233271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:18<00:02,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7231018695154521\n",
      "0.5270734500245379\n",
      "0.6870211496994999\n",
      "0.7226213752326212\n",
      "EarlyStopping counter: 3 out of 50\n",
      "0.927536231884058\n",
      "0.9022556390977443\n",
      "0.9077490774907749\n",
      "0.9380530973451328\n",
      "0.9392712550607287\n",
      "0.9591078066914498\n",
      "0.7990074441687345\n",
      "0.9118387909319899\n",
      "0.9105691056910569\n",
      "0.9307692307692308\n",
      "0.9048473967684022\n",
      "0.43145441892832287\n",
      "0.6937945066124109\n",
      "0.7595297470609191\n",
      "0.8321933424532604\n",
      "0.8273875470861954\n",
      "0.8257028112449799\n",
      "0.6840458811261731\n",
      "0.7355982274741507\n",
      "0.6600995809005266\n",
      "0.7231018695154521\n",
      "0.5270734500245379\n",
      "0.6870132700225946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:20<00:00,  2.07s/it]\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7226213752326212\n",
      "EarlyStopping counter: 4 out of 50\n",
      "auc: 0.7627587190796388, ap: 0.7488420123842341\n",
      "auc mean: 0.7184816172463397, ap mean: 0.6979584643657328, acc mean: 0.647363057430116, f1 mean: 0.7048173226276079 \n",
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.6666666666666666\n",
      "0.5420560747663551\n",
      "0.0\n",
      "0.6031746031746031\n",
      "0.6666666666666666\n",
      "0.6657183499288762\n",
      "0.9362549800796812\n",
      "0.9227799227799228\n",
      "0.9133574007220217\n",
      "0.4329608938547486\n",
      "0.696105702364395\n",
      "0.7753891771682728\n",
      "0.8201923076923077\n",
      "0.826135726303982\n",
      "0.6881211547562707\n",
      "0.7483364241300317\n",
      "0.6662998018930222\n",
      "0.6534510859265437\n",
      "0.7439216283437389\n",
      "0.5435346944502911\n",
      "0.5572619313926686\n",
      "0.7068589860629299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:13,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7361676466154078\n",
      "Validation loss decreased (inf --> 0.635947).  Saving model ...\n",
      "0.9154228855721394\n",
      "0.8862745098039215\n",
      "0.9363295880149812\n",
      "0.9146341463414634\n",
      "0.8559322033898306\n",
      "0.896551724137931\n",
      "0.8403755868544601\n",
      "0.9479768786127167\n",
      "0.9380863039399625\n",
      "0.9190140845070423\n",
      "0.4432358939496941\n",
      "0.7018021081264876\n",
      "0.7808849557522124\n",
      "0.8340522133938706\n",
      "0.8258411843876178\n",
      "0.6857746266405189\n",
      "0.7403338263257976\n",
      "0.6643667346192045\n",
      "0.6580136249551811\n",
      "0.7249701314217444\n",
      "0.5225577380370696\n",
      "0.5313429547207227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:12,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6863075775827454\n",
      "0.7203630976177599\n",
      "Validation loss decreased (0.635947 --> 0.392899).  Saving model ...\n",
      "0.9301204819277108\n",
      "0.9259259259259259\n",
      "0.953405017921147\n",
      "0.9482758620689655\n",
      "0.921875\n",
      "0.9202898550724637\n",
      "0.863013698630137\n",
      "0.9479768786127167\n",
      "0.9380863039399625\n",
      "0.9190140845070423\n",
      "0.4432358939496941\n",
      "0.7018021081264876\n",
      "0.7808849557522124\n",
      "0.8340522133938706\n",
      "0.8258411843876178\n",
      "0.6857746266405189\n",
      "0.7403338263257976\n",
      "0.6643667346192045\n",
      "0.6580136249551811\n",
      "0.7249701314217444\n",
      "0.5225407166123779\n",
      "0.5313478328727633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:04<00:10,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6863075775827454\n",
      "0.7203029091507726\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9301204819277108\n",
      "0.9298892988929889\n",
      "0.953405017921147\n",
      "0.9482758620689655\n",
      "0.921875\n",
      "0.9202898550724637\n",
      "0.863013698630137\n",
      "0.9479768786127167\n",
      "0.9380863039399625\n",
      "0.9190140845070423\n",
      "0.4432358939496941\n",
      "0.7018021081264876\n",
      "0.7808849557522124\n",
      "0.8337874659400545\n",
      "0.8255250403877221\n",
      "0.6857746266405189\n",
      "0.7403338263257976\n",
      "0.6645056726094003\n",
      "0.6581316119777658\n",
      "0.7253861234638741\n",
      "0.522762081663245\n",
      "0.5317090648513078\n",
      "0.6866727128703778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:05<00:08,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7206418672501823\n",
      "Validation loss decreased (0.392899 --> 0.391047).  Saving model ...\n",
      "0.9301204819277108\n",
      "0.9298892988929889\n",
      "0.953405017921147\n",
      "0.9482758620689655\n",
      "0.921875\n",
      "0.9202898550724637\n",
      "0.863013698630137\n",
      "0.9479768786127167\n",
      "0.9380863039399625\n",
      "0.9190140845070423\n",
      "0.4432358939496941\n",
      "0.7018021081264876\n",
      "0.7808849557522124\n",
      "0.8337874659400545\n",
      "0.8255250403877221\n",
      "0.6857746266405189\n",
      "0.7403338263257976\n",
      "0.6645056726094003\n",
      "0.6581316119777658\n",
      "0.7253861234638741\n",
      "0.522762081663245\n",
      "0.5317090648513078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:07<00:07,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6866727128703778\n",
      "0.7206418672501823\n",
      "Validation loss decreased (0.391047 --> 0.368833).  Saving model ...\n",
      "0.9301204819277108\n",
      "0.9253731343283582\n",
      "0.953405017921147\n",
      "0.9482758620689655\n",
      "0.921875\n",
      "0.9202898550724637\n",
      "0.863013698630137\n",
      "0.9479768786127167\n",
      "0.9380863039399625\n",
      "0.9190140845070423\n",
      "0.4432358939496941\n",
      "0.7018021081264876\n",
      "0.7808849557522124\n",
      "0.8337874659400545\n",
      "0.8255250403877221\n",
      "0.6857746266405189\n",
      "0.7403338263257976\n",
      "0.6645056726094003\n",
      "0.6581316119777658\n",
      "0.7253861234638741\n",
      "0.522762081663245\n",
      "0.5317090648513078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:08<00:05,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6866727128703778\n",
      "0.7206418672501823\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9297820823244553\n",
      "0.9298892988929889\n",
      "0.953405017921147\n",
      "0.9510086455331412\n",
      "0.921875\n",
      "0.9236363636363636\n",
      "0.863013698630137\n",
      "0.9479768786127167\n",
      "0.9380863039399625\n",
      "0.9190140845070423\n",
      "0.4432358939496941\n",
      "0.7018021081264876\n",
      "0.7811614730878187\n",
      "0.8337874659400545\n",
      "0.8253369272237197\n",
      "0.6862241040375019\n",
      "0.7422636256558518\n",
      "0.6644053195498842\n",
      "0.6619433198380567\n",
      "0.7310932698979086\n",
      "0.5322371563075664\n",
      "0.5394043857129177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:10<00:04,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6938877815308595\n",
      "0.7327457825736676\n",
      "EarlyStopping counter: 2 out of 50\n",
      "0.9301204819277108\n",
      "0.917910447761194\n",
      "0.9416058394160584\n",
      "0.9387755102040817\n",
      "0.921875\n",
      "0.9202898550724637\n",
      "0.8571428571428571\n",
      "0.9479768786127167\n",
      "0.9380863039399625\n",
      "0.9190140845070423\n",
      "0.4432358939496941\n",
      "0.7018021081264876\n",
      "0.7808849557522124\n",
      "0.8337874659400545\n",
      "0.8255250403877221\n",
      "0.6857746266405189\n",
      "0.7403338263257976\n",
      "0.6645056726094003\n",
      "0.6581316119777658\n",
      "0.7253861234638741\n",
      "0.522762081663245\n",
      "0.5317090648513078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:11<00:02,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6866727128703778\n",
      "0.7206418672501823\n",
      "EarlyStopping counter: 3 out of 50\n",
      "0.9297820823244553\n",
      "0.9213483146067416\n",
      "0.953405017921147\n",
      "0.953757225433526\n",
      "0.921875\n",
      "0.9202898550724637\n",
      "0.8597701149425288\n",
      "0.9479768786127167\n",
      "0.9380863039399625\n",
      "0.9190140845070423\n",
      "0.4432358939496941\n",
      "0.7018021081264876\n",
      "0.7808849557522124\n",
      "0.8337874659400545\n",
      "0.8255250403877221\n",
      "0.6857746266405189\n",
      "0.7403338263257976\n",
      "0.6645056726094003\n",
      "0.6581316119777658\n",
      "0.7253861234638741\n",
      "0.522762081663245\n",
      "0.5317090648513078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:13<00:01,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6866727128703778\n",
      "0.7206418672501823\n",
      "EarlyStopping counter: 4 out of 50\n",
      "0.9323671497584541\n",
      "0.917910447761194\n",
      "0.953405017921147\n",
      "0.9482758620689655\n",
      "0.921875\n",
      "0.9202898550724637\n",
      "0.8551724137931035\n",
      "0.9479768786127167\n",
      "0.9380863039399625\n",
      "0.9190140845070423\n",
      "0.4432358939496941\n",
      "0.7018021081264876\n",
      "0.7808849557522124\n",
      "0.8337874659400545\n",
      "0.8255250403877221\n",
      "0.6857746266405189\n",
      "0.7403338263257976\n",
      "0.6645056726094003\n",
      "0.6581316119777658\n",
      "0.7253861234638741\n",
      "0.522762081663245\n",
      "0.5317090648513078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6866727128703778\n",
      "0.7206418672501823\n",
      "EarlyStopping counter: 5 out of 50\n",
      "auc: 0.7499205816494698, ap: 0.734541129485913\n",
      "auc mean: 0.7137862294219269, ap mean: 0.7315956847909016, acc mean: 0.6603224926866529, f1 mean: 0.6761442628040192 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6546644844517185\n",
      "0.04285714285714286\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.7219512195121951\n",
      "0.08571428571428572\n",
      "0.2397003745318352\n",
      "0.6978193146417445\n",
      "0.872651356993737\n",
      "0.9219047619047619\n",
      "0.9048473967684022\n",
      "0.45517241379310347\n",
      "0.6991364421416235\n",
      "0.7873848334514528\n",
      "0.8220746507900161\n",
      "0.8195767195767196\n",
      "0.6782945736434108\n",
      "0.7428390233590529\n",
      "0.6624513271174937\n",
      "0.7306740289413557\n",
      "0.5274396198164182\n",
      "0.5322012498055756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:17,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6882442608107644\n",
      "0.7242322751073164\n",
      "Validation loss decreased (inf --> 0.441836).  Saving model ...\n",
      "0.9563106796116505\n",
      "0.9166666666666666\n",
      "0.9202898550724637\n",
      "0.9452449567723343\n",
      "0.9083665338645418\n",
      "0.966789667896679\n",
      "0.8430913348946136\n",
      "0.9264705882352942\n",
      "0.9224806201550387\n",
      "0.9343339587242027\n",
      "0.9012567324955116\n",
      "0.45934959349593496\n",
      "0.7072838665759019\n",
      "0.7892693258030357\n",
      "0.8215181217232733\n",
      "0.8195767195767196\n",
      "0.6783957059788281\n",
      "0.7428390233590529\n",
      "0.6625223294033583\n",
      "0.7307088113485981\n",
      "0.5274396198164182\n",
      "0.5322012498055756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:15,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6882442608107644\n",
      "0.7242322751073164\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9563106796116505\n",
      "0.9166666666666666\n",
      "0.9144981412639405\n",
      "0.9345238095238095\n",
      "0.8979591836734694\n",
      "0.9584905660377359\n",
      "0.8240963855421687\n",
      "0.9207920792079208\n",
      "0.921875\n",
      "0.9323308270676691\n",
      "0.9012567324955116\n",
      "0.45934959349593496\n",
      "0.7072838665759019\n",
      "0.7892693258030357\n",
      "0.8244897959183674\n",
      "0.8195767195767196\n",
      "0.6782945736434108\n",
      "0.7428390233590529\n",
      "0.6624513271174937\n",
      "0.7306740289413557\n",
      "0.5274396198164182\n",
      "0.5322012498055756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:05<00:13,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6882442608107644\n",
      "0.7242322751073164\n",
      "EarlyStopping counter: 2 out of 50\n",
      "0.9563106796116505\n",
      "0.9166666666666666\n",
      "0.9202898550724637\n",
      "0.9452449567723343\n",
      "0.9083665338645418\n",
      "0.966789667896679\n",
      "0.8376470588235294\n",
      "0.9264705882352942\n",
      "0.9224806201550387\n",
      "0.9343339587242027\n",
      "0.9032258064516129\n",
      "0.45934959349593496\n",
      "0.7072838665759019\n",
      "0.7892693258030357\n",
      "0.8244897959183674\n",
      "0.8195767195767196\n",
      "0.6782945736434108\n",
      "0.7428390233590529\n",
      "0.6624513271174937\n",
      "0.7306740289413557\n",
      "0.5274396198164182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:07<00:11,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5322012498055756\n",
      "0.6882442608107644\n",
      "0.7242322751073164\n",
      "EarlyStopping counter: 3 out of 50\n",
      "0.9563106796116505\n",
      "0.9166666666666666\n",
      "0.9202898550724637\n",
      "0.9452449567723343\n",
      "0.9083665338645418\n",
      "0.966789667896679\n",
      "0.8341232227488151\n",
      "0.9264705882352942\n",
      "0.9224806201550387\n",
      "0.9343339587242027\n",
      "0.9032258064516129\n",
      "0.45934959349593496\n",
      "0.7072838665759019\n",
      "0.7898269162839986\n",
      "0.823155505107832\n",
      "0.8195767195767196\n",
      "0.6782945736434108\n",
      "0.7428390233590529\n",
      "0.6624513271174937\n",
      "0.7306740289413557\n",
      "0.5274396198164182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:09<00:09,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5322012498055756\n",
      "0.6882442608107644\n",
      "0.7242322751073164\n",
      "EarlyStopping counter: 4 out of 50\n",
      "0.9563106796116505\n",
      "0.9207547169811321\n",
      "0.927007299270073\n",
      "0.9387755102040817\n",
      "0.9156626506024096\n",
      "0.951310861423221\n",
      "0.8341232227488151\n",
      "0.9287469287469288\n",
      "0.9224806201550387\n",
      "0.9343339587242027\n",
      "0.9032258064516129\n",
      "0.45934959349593496\n",
      "0.7072838665759019\n",
      "0.7892693258030357\n",
      "0.8243028791657221\n",
      "0.8193599576831526\n",
      "0.6782945736434108\n",
      "0.7427605157471994\n",
      "0.6623803400485784\n",
      "0.7305349324195698\n",
      "0.527247291537886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:11<00:07,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5318254127886778\n",
      "0.6878013583315199\n",
      "0.7240712804073166\n",
      "EarlyStopping counter: 5 out of 50\n",
      "0.9563106796116505\n",
      "0.9207547169811321\n",
      "0.9202898550724637\n",
      "0.9425287356321839\n",
      "0.9083665338645418\n",
      "0.959409594095941\n",
      "0.839622641509434\n",
      "0.9234567901234568\n",
      "0.9233716475095786\n",
      "0.9291044776119403\n",
      "0.9023090586145648\n",
      "0.45668233713901946\n",
      "0.7063197026022305\n",
      "0.7865640307907628\n",
      "0.8219424460431655\n",
      "0.8189429618001046\n",
      "0.6733608978145305\n",
      "0.7384615384615385\n",
      "0.6583374392904906\n",
      "0.7199775795226306\n",
      "0.5182751802002934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:13<00:05,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5198237885462555\n",
      "0.6760689701562815\n",
      "0.7158570966400148\n",
      "EarlyStopping counter: 6 out of 50\n",
      "0.9640287769784173\n",
      "0.9207547169811321\n",
      "0.9202898550724637\n",
      "0.9394812680115274\n",
      "0.9083665338645418\n",
      "0.9552238805970149\n",
      "0.839622641509434\n",
      "0.9264705882352942\n",
      "0.9266409266409267\n",
      "0.9325842696629213\n",
      "0.9071428571428571\n",
      "0.46008119079837617\n",
      "0.7065217391304348\n",
      "0.7881565033486077\n",
      "0.8238507055075103\n",
      "0.8193599576831526\n",
      "0.6782945736434108\n",
      "0.7427605157471994\n",
      "0.6623803400485784\n",
      "0.7305349324195698\n",
      "0.527247291537886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:15<00:03,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5318254127886778\n",
      "0.6878013583315199\n",
      "0.7240712804073166\n",
      "Validation loss decreased (0.441836 --> 0.438113).  Saving model ...\n",
      "0.9537712895377128\n",
      "0.9125475285171103\n",
      "0.927007299270073\n",
      "0.9452449567723343\n",
      "0.912\n",
      "0.9703703703703703\n",
      "0.8349056603773585\n",
      "0.9211822660098522\n",
      "0.9248554913294798\n",
      "0.9325842696629213\n",
      "0.9055258467023173\n",
      "0.4571813890761969\n",
      "0.707681849082257\n",
      "0.7884344146685472\n",
      "0.8244067796610169\n",
      "0.8193599576831526\n",
      "0.6782945736434108\n",
      "0.7427605157471994\n",
      "0.6623803400485784\n",
      "0.7305349324195698\n",
      "0.527247291537886\n",
      "0.5318254127886778\n",
      "0.6878013583315199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:17<00:01,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7240712804073166\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9563106796116505\n",
      "0.9207547169811321\n",
      "0.9236363636363636\n",
      "0.9266862170087976\n",
      "0.9083665338645418\n",
      "0.966789667896679\n",
      "0.8349056603773585\n",
      "0.9287469287469288\n",
      "0.9292543021032504\n",
      "0.930841121495327\n",
      "0.9\n",
      "0.4582210242587601\n",
      "0.7067209775967414\n",
      "0.7871966232852621\n",
      "0.8242753623188406\n",
      "0.8193599576831526\n",
      "0.6782945736434108\n",
      "0.7427605157471994\n",
      "0.6623325593856045\n",
      "0.7305349324195698\n",
      "0.527247291537886\n",
      "0.5318351375073143\n",
      "0.6878013583315199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:19<00:00,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7240712804073166\n",
      "EarlyStopping counter: 2 out of 50\n",
      "auc: 0.7539167900846243, ap: 0.7361401375311295\n",
      "auc mean: 0.6717257684266967, ap mean: 0.6779919883300046, acc mean: 0.6094925918194607, f1 mean: 0.6439704265982018 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.0\n",
      "0.6700507614213198\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:10,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "Validation loss decreased (inf --> 0.687406).  Saving model ...\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6792452830188679\n",
      "0.36477987421383645\n",
      "0.5027932960893855\n",
      "0.2909090909090909\n",
      "0.3584905660377358\n",
      "0.5170454545454546\n",
      "0.39316239316239315\n",
      "0.17443868739205526\n",
      "0.1936842105263158\n",
      "0.2919042189281642\n",
      "0.2770897832817337\n",
      "0.3443223443223443\n",
      "0.4120430107526882\n",
      "0.31816112881201636\n",
      "0.29496656107004576\n",
      "0.24257295591972658\n",
      "0.26425769947920014\n",
      "0.36642027455121434\n",
      "0.2759277945958067\n",
      "0.1147631352282515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:02<00:10,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18994570305186295\n",
      "0.3288810833294819\n",
      "Validation loss decreased (0.687406 --> 0.664292).  Saving model ...\n",
      "0.5035971223021583\n",
      "0.8630705394190872\n",
      "0.9172932330827067\n",
      "0.904\n",
      "0.9509433962264151\n",
      "0.8393285371702638\n",
      "0.9138276553106213\n",
      "0.918918918918919\n",
      "0.9239332096474954\n",
      "0.4265536723163842\n",
      "0.6973047684865239\n",
      "0.7739322533136966\n",
      "0.815311004784689\n",
      "0.8160550458715596\n",
      "0.8286830357142857\n",
      "0.6809643080776456\n",
      "0.7464146023468058\n",
      "0.6564691589817218\n",
      "0.6570521203063703\n",
      "0.7455627269060104\n",
      "0.5424920795181561\n",
      "0.5532689750852651\n",
      "0.7066684260403296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:03<00:08,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7386573496381332\n",
      "Validation loss decreased (0.664292 --> 0.557505).  Saving model ...\n",
      "0.9253731343283582\n",
      "0.9224806201550387\n",
      "0.9253731343283582\n",
      "0.8816326530612245\n",
      "0.9509433962264151\n",
      "0.8223844282238443\n",
      "0.9065040650406504\n",
      "0.9105058365758755\n",
      "0.9227871939736346\n",
      "0.4267425320056899\n",
      "0.6946778711484594\n",
      "0.7752976190476191\n",
      "0.8087591240875912\n",
      "0.8155880306193458\n",
      "0.8261482107635953\n",
      "0.6819692892195662\n",
      "0.7456949227863571\n",
      "0.6553081421502475\n",
      "0.6606641271307091\n",
      "0.7506843654769898\n",
      "0.5503326739795001\n",
      "0.5595956592834844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:05<00:07,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7116281932902432\n",
      "0.7482526434368519\n",
      "Validation loss decreased (0.557505 --> 0.361224).  Saving model ...\n",
      "0.9195979899497487\n",
      "0.9312977099236641\n",
      "0.9377289377289377\n",
      "0.8984375\n",
      "0.9591078066914498\n",
      "0.8683602771362586\n",
      "0.9239766081871345\n",
      "0.9363295880149812\n",
      "0.9289617486338798\n",
      "0.4290657439446367\n",
      "0.7065989847715736\n",
      "0.772066643034385\n",
      "0.8263363156687313\n",
      "0.8132890365448505\n",
      "0.8287707997852926\n",
      "0.6772872098315885\n",
      "0.7432332024201252\n",
      "0.6602177820065546\n",
      "0.6614983387517416\n",
      "0.7258720512943203\n",
      "0.5240652216619737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:06<00:06,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.533102164001798\n",
      "0.6877101489055102\n",
      "0.7247143261875532\n",
      "Validation loss decreased (0.361224 --> 0.232533).  Saving model ...\n",
      "0.9294403892944039\n",
      "0.9407407407407408\n",
      "0.9377289377289377\n",
      "0.8984375\n",
      "0.9591078066914498\n",
      "0.8683602771362586\n",
      "0.9239766081871345\n",
      "0.9363295880149812\n",
      "0.9289617486338798\n",
      "0.4290657439446367\n",
      "0.7065989847715736\n",
      "0.772066643034385\n",
      "0.8263363156687313\n",
      "0.8132890365448505\n",
      "0.8297130598015554\n",
      "0.6772872098315885\n",
      "0.7432332024201252\n",
      "0.6602188045029332\n",
      "0.6614516359479926\n",
      "0.7256290060269779\n",
      "0.5238079654416337\n",
      "0.532701456555416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:07<00:05,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6874785670195012\n",
      "0.7244536744229952\n",
      "Validation loss decreased (0.232533 --> 0.213984).  Saving model ...\n",
      "0.9294403892944039\n",
      "0.9407407407407408\n",
      "0.9343065693430657\n",
      "0.8949416342412452\n",
      "0.9591078066914498\n",
      "0.8669724770642202\n",
      "0.9248554913294798\n",
      "0.9365671641791045\n",
      "0.9244604316546763\n",
      "0.4303448275862069\n",
      "0.7081790642881185\n",
      "0.7733800350262697\n",
      "0.8266183793571752\n",
      "0.8055190538764783\n",
      "0.8246495636075113\n",
      "0.6725850135419802\n",
      "0.7376928728875827\n",
      "0.655079381550275\n",
      "0.6571871040405463\n",
      "0.7129946148442987\n",
      "0.5148947098099641\n",
      "0.5200178651183565\n",
      "0.6753025930151911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:08<00:03,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7166412636829708\n",
      "Validation loss decreased (0.213984 --> 0.213297).  Saving model ...\n",
      "0.9301204819277108\n",
      "0.9407407407407408\n",
      "0.9381818181818182\n",
      "0.8949416342412452\n",
      "0.9591078066914498\n",
      "0.8669724770642202\n",
      "0.9248554913294798\n",
      "0.9365671641791045\n",
      "0.9244604316546763\n",
      "0.4303448275862069\n",
      "0.7081790642881185\n",
      "0.7733800350262697\n",
      "0.8266183793571752\n",
      "0.8055190538764783\n",
      "0.8246495636075113\n",
      "0.6725850135419802\n",
      "0.7376928728875827\n",
      "0.655079381550275\n",
      "0.6571871040405463\n",
      "0.7129946148442987\n",
      "0.5148947098099641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:10<00:02,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5200178651183565\n",
      "0.6753025930151911\n",
      "0.7166578139073001\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9301204819277108\n",
      "0.9407407407407408\n",
      "0.9377289377289377\n",
      "0.8984375\n",
      "0.9591078066914498\n",
      "0.8683602771362586\n",
      "0.9239766081871345\n",
      "0.9363295880149812\n",
      "0.9289617486338798\n",
      "0.4290657439446367\n",
      "0.7065989847715736\n",
      "0.772066643034385\n",
      "0.8263363156687313\n",
      "0.8132890365448505\n",
      "0.8297130598015554\n",
      "0.6772872098315885\n",
      "0.7432332024201252\n",
      "0.6602188045029332\n",
      "0.6614516359479926\n",
      "0.7256290060269779\n",
      "0.5237908240068068\n",
      "0.5326965735970814\n",
      "0.6874785670195012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:11<00:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7244495835004837\n",
      "Validation loss decreased (0.213297 --> 0.209060).  Saving model ...\n",
      "0.9294403892944039\n",
      "0.9368029739776952\n",
      "0.8784313725490196\n",
      "0.8984375\n",
      "0.9552238805970149\n",
      "0.8657407407407407\n",
      "0.9239766081871345\n",
      "0.9363295880149812\n",
      "0.9289617486338798\n",
      "0.42966042966042967\n",
      "0.7053238385893523\n",
      "0.7727272727272727\n",
      "0.8265071329958582\n",
      "0.8143712574850299\n",
      "0.8292158968850698\n",
      "0.678110284065016\n",
      "0.7441811031990647\n",
      "0.6606603423604854\n",
      "0.6617246812777539\n",
      "0.7276401250902093\n",
      "0.5256237467538871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5350744618106753\n",
      "0.6890528396423728\n",
      "0.7242641814464362\n",
      "EarlyStopping counter: 1 out of 50\n",
      "auc: 0.7437374376023019, ap: 0.697335203952404\n",
      "auc mean: 0.7652896010144689, ap mean: 0.7776207792481854, acc mean: 0.7342264910111163, f1 mean: 0.7285225299347171 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6377295492487479\n",
      "0.0\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.8079470198675497\n",
      "0.9027237354085603\n",
      "0.7869674185463659\n",
      "0.9115913555992141\n",
      "0.9210019267822736\n",
      "0.9023941068139963\n",
      "0.41595441595441596\n",
      "0.6999306999306999\n",
      "0.7677655677655678\n",
      "0.8144475920679887\n",
      "0.8219611387257117\n",
      "0.8411829134720701\n",
      "0.6879334257975035\n",
      "0.7461320549139246\n",
      "0.6696704524297151\n",
      "0.7293102593345564\n",
      "0.5388826549695671\n",
      "0.5404993329521631\n",
      "0.6959121212840162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:13,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7324815916516312\n",
      "Validation loss decreased (inf --> 0.576350).  Saving model ...\n",
      "0.9507389162561576\n",
      "0.9111111111111111\n",
      "0.9314079422382672\n",
      "0.9122807017543859\n",
      "0.9236641221374046\n",
      "0.9343065693430657\n",
      "0.8597701149425288\n",
      "0.926923076923077\n",
      "0.928030303030303\n",
      "0.9074410163339383\n",
      "0.41379310344827586\n",
      "0.7045300878972278\n",
      "0.7699496764917325\n",
      "0.8252004581901489\n",
      "0.827037773359841\n",
      "0.8443850267379679\n",
      "0.6839019990981512\n",
      "0.7430930454112417\n",
      "0.6618771892201015\n",
      "0.7240074709065658\n",
      "0.5290461157939271\n",
      "0.5326758218131582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:12,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6867631082394648\n",
      "0.721876248443118\n",
      "Validation loss decreased (0.576350 --> 0.416382).  Saving model ...\n",
      "0.9586374695863747\n",
      "0.9357142857142857\n",
      "0.9280575539568345\n",
      "0.9069767441860465\n",
      "0.9201520912547528\n",
      "0.9343065693430657\n",
      "0.8577981651376146\n",
      "0.9254302103250478\n",
      "0.9227871939736346\n",
      "0.9113924050632911\n",
      "0.41345480028030834\n",
      "0.7049345417925479\n",
      "0.772291296625222\n",
      "0.8252162039144287\n",
      "0.8223684210526315\n",
      "0.8439735099337748\n",
      "0.6793015967766005\n",
      "0.7371734340572867\n",
      "0.6583451202263083\n",
      "0.7163643235071806\n",
      "0.5231332733581802\n",
      "0.5239610296232384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:04<00:10,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6781390424920883\n",
      "0.7174179805978097\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9636803874092009\n",
      "0.9323843416370107\n",
      "0.9280575539568345\n",
      "0.9096209912536443\n",
      "0.9236641221374046\n",
      "0.9343065693430657\n",
      "0.8597701149425288\n",
      "0.926923076923077\n",
      "0.928030303030303\n",
      "0.9107468123861566\n",
      "0.4143763213530655\n",
      "0.7047683462969225\n",
      "0.7688984881209503\n",
      "0.8248509857863365\n",
      "0.827220503756076\n",
      "0.8443017656500803\n",
      "0.684519332029487\n",
      "0.7434078153129302\n",
      "0.6623028221912223\n",
      "0.7246668584028377\n",
      "0.5296532846715328\n",
      "0.5333577679021395\n",
      "0.6874634967533583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:05<00:08,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.722010447550473\n",
      "Validation loss decreased (0.416382 --> 0.410093).  Saving model ...\n",
      "0.9509803921568627\n",
      "0.9390681003584229\n",
      "0.9280575539568345\n",
      "0.9096209912536443\n",
      "0.9236641221374046\n",
      "0.9343065693430657\n",
      "0.8597701149425288\n",
      "0.926923076923077\n",
      "0.928030303030303\n",
      "0.9107468123861566\n",
      "0.4143763213530655\n",
      "0.7047683462969225\n",
      "0.7688984881209503\n",
      "0.8248509857863365\n",
      "0.827220503756076\n",
      "0.8443017656500803\n",
      "0.684519332029487\n",
      "0.7434078153129302\n",
      "0.6623028221912223\n",
      "0.7246668584028377\n",
      "0.5296532846715328\n",
      "0.5333577679021395\n",
      "0.6874634967533583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:07<00:07,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.722010447550473\n",
      "Validation loss decreased (0.410093 --> 0.400488).  Saving model ...\n",
      "0.9509803921568627\n",
      "0.9390681003584229\n",
      "0.9280575539568345\n",
      "0.9122807017543859\n",
      "0.9236641221374046\n",
      "0.9304029304029304\n",
      "0.859122401847575\n",
      "0.926923076923077\n",
      "0.928030303030303\n",
      "0.9107468123861566\n",
      "0.4143763213530655\n",
      "0.7047683462969225\n",
      "0.7688984881209503\n",
      "0.8248509857863365\n",
      "0.827220503756076\n",
      "0.8443017656500803\n",
      "0.684519332029487\n",
      "0.7434078153129302\n",
      "0.6623028221912223\n",
      "0.7246668584028377\n",
      "0.5296532846715328\n",
      "0.5333577679021395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:08<00:05,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6874634967533583\n",
      "0.722010447550473\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9509803921568627\n",
      "0.9390681003584229\n",
      "0.9280575539568345\n",
      "0.9096209912536443\n",
      "0.9236641221374046\n",
      "0.9343065693430657\n",
      "0.8571428571428571\n",
      "0.9186046511627907\n",
      "0.9198473282442748\n",
      "0.9084249084249084\n",
      "0.41222459132906897\n",
      "0.7034013605442176\n",
      "0.7612809315866085\n",
      "0.8219749652294854\n",
      "0.8296923762817655\n",
      "0.8444084278768234\n",
      "0.6865218051967786\n",
      "0.7454739084132055\n",
      "0.6619560097112005\n",
      "0.7315884388555832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:10<00:04,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5363778376042809\n",
      "0.5405264529580401\n",
      "0.6934313360625233\n",
      "0.7257557958332335\n",
      "EarlyStopping counter: 2 out of 50\n",
      "0.9509803921568627\n",
      "0.935251798561151\n",
      "0.9163636363636364\n",
      "0.9107142857142857\n",
      "0.9153846153846154\n",
      "0.9343065693430657\n",
      "0.8571428571428571\n",
      "0.926923076923077\n",
      "0.928030303030303\n",
      "0.9107468123861566\n",
      "0.4143763213530655\n",
      "0.7047683462969225\n",
      "0.7688984881209503\n",
      "0.825120330048132\n",
      "0.827037773359841\n",
      "0.8443017656500803\n",
      "0.684519332029487\n",
      "0.7434078153129302\n",
      "0.6622317596566524\n",
      "0.7243543673039146\n",
      "0.5295804013552254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:11<00:02,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5330146782774313\n",
      "0.6870679789425498\n",
      "0.7217309501411101\n",
      "EarlyStopping counter: 3 out of 50\n",
      "0.9586374695863747\n",
      "0.9357142857142857\n",
      "0.9280575539568345\n",
      "0.9096209912536443\n",
      "0.9236641221374046\n",
      "0.9343065693430657\n",
      "0.8597701149425288\n",
      "0.926923076923077\n",
      "0.928030303030303\n",
      "0.9107468123861566\n",
      "0.4143763213530655\n",
      "0.7047683462969225\n",
      "0.7688984881209503\n",
      "0.825120330048132\n",
      "0.827037773359841\n",
      "0.8443017656500803\n",
      "0.684519332029487\n",
      "0.7434078153129302\n",
      "0.6622317596566524\n",
      "0.7243543673039146\n",
      "0.5295804013552254\n",
      "0.5330146782774313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:13<00:01,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6870679789425498\n",
      "0.7217309501411101\n",
      "EarlyStopping counter: 4 out of 50\n",
      "0.9509803921568627\n",
      "0.9390681003584229\n",
      "0.9280575539568345\n",
      "0.9096209912536443\n",
      "0.9236641221374046\n",
      "0.9343065693430657\n",
      "0.8597701149425288\n",
      "0.926923076923077\n",
      "0.928030303030303\n",
      "0.9107468123861566\n",
      "0.4143763213530655\n",
      "0.7047683462969225\n",
      "0.7688984881209503\n",
      "0.825120330048132\n",
      "0.827037773359841\n",
      "0.8443017656500803\n",
      "0.684519332029487\n",
      "0.7434078153129302\n",
      "0.6622317596566524\n",
      "0.7243543673039146\n",
      "0.5295804013552254\n",
      "0.5330146782774313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6870679789425498\n",
      "0.7217309501411101\n",
      "Validation loss decreased (0.400488 --> 0.392751).  Saving model ...\n",
      "auc: 0.7432900006279214, ap: 0.7263674526327146\n",
      "auc mean: 0.6672321786073669, ap mean: 0.6753919274187772, acc mean: 0.6087485545014204, f1 mean: 0.6429966892794806 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07111111111111111\n",
      "0.6666666666666666\n",
      "0.014184397163120567\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:12,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Validation loss decreased (inf --> 0.685753).  Saving model ...\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8362068965517241\n",
      "0.8976377952755905\n",
      "0.7564766839378239\n",
      "0.8963730569948186\n",
      "0.8757894736842106\n",
      "0.9124236252545825\n",
      "0.8998109640831758\n",
      "0.43316654753395284\n",
      "0.665948275862069\n",
      "0.7566525260316236\n",
      "0.7980985739304478\n",
      "0.8234280792420328\n",
      "0.6842783505154639\n",
      "0.7305852880892735\n",
      "0.6489966361210996\n",
      "0.6656393235340604\n",
      "0.7482144760686494\n",
      "0.5546168446909078\n",
      "0.5613660399831607\n",
      "0.7129818093372762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:02<00:10,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7458492975734355\n",
      "Validation loss decreased (0.685753 --> 0.676893).  Saving model ...\n",
      "0.9211195928753181\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "Validation loss decreased (0.676893 --> 0.645390).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:03<00:08,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.9358490566037736\n",
      "0.9138576779026217\n",
      "0.8362068965517241\n",
      "0.9019607843137255\n",
      "0.7648578811369509\n",
      "0.8935064935064935\n",
      "0.8781512605042017\n",
      "0.9124236252545825\n",
      "0.8977272727272727\n",
      "0.4337866857551897\n",
      "0.665948275862069\n",
      "0.7565485362095532\n",
      "0.798501872659176\n",
      "0.8266360505166476\n",
      "0.6846673095467696\n",
      "0.734453018610985\n",
      "0.6532878376033775\n",
      "0.6665615266332847\n",
      "0.7493611584327087\n",
      "0.5541173845123857\n",
      "0.569040986868285\n",
      "0.7184876625775468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:05<00:07,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7507869745787371\n",
      "Validation loss decreased (0.645390 --> 0.537917).  Saving model ...\n",
      "0.9187817258883249\n",
      "0.9027237354085603\n",
      "0.9056603773584906\n",
      "0.8412017167381974\n",
      "0.9147286821705426\n",
      "0.7743589743589744\n",
      "0.8992248062015504\n",
      "0.8879668049792531\n",
      "0.9212121212121213\n",
      "0.9001883239171374\n",
      "0.4382583868665239\n",
      "0.6680988184747583\n",
      "0.7596006144393241\n",
      "0.8049627791563275\n",
      "0.8284159266685763\n",
      "0.6866485013623979\n",
      "0.7350175597598279\n",
      "0.6539415258635604\n",
      "0.6663521641703031\n",
      "0.748303647158609\n",
      "0.5533316067927041\n",
      "0.5672685152257186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:06<00:06,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7171204547184653\n",
      "0.7495391098235449\n",
      "Validation loss decreased (0.537917 --> 0.417789).  Saving model ...\n",
      "0.9191919191919192\n",
      "0.9277566539923955\n",
      "0.922509225092251\n",
      "0.8816326530612245\n",
      "0.9433962264150944\n",
      "0.8285714285714286\n",
      "0.9017632241813602\n",
      "0.905811623246493\n",
      "0.9448818897637795\n",
      "0.9117647058823529\n",
      "0.44538407329105\n",
      "0.6880386073767666\n",
      "0.7619405791650996\n",
      "0.8245862884160756\n",
      "0.826533444351929\n",
      "0.6933292155651637\n",
      "0.7395484498217565\n",
      "0.6586522554317856\n",
      "0.6597354201602385\n",
      "0.7402328981196754\n",
      "0.5484329989935098\n",
      "0.5543544179509641\n",
      "0.708155281372254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:07<00:05,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7371842960740185\n",
      "Validation loss decreased (0.417789 --> 0.319689).  Saving model ...\n",
      "0.9223057644110275\n",
      "0.9358490566037736\n",
      "0.922509225092251\n",
      "0.8906882591093117\n",
      "0.9433962264150944\n",
      "0.8285714285714286\n",
      "0.9045226130653267\n",
      "0.9083665338645418\n",
      "0.9448818897637795\n",
      "0.916058394160584\n",
      "0.44757213230119636\n",
      "0.687801516195727\n",
      "0.7638680659670165\n",
      "0.8277162385104878\n",
      "0.8284449363586054\n",
      "0.6931853222325007\n",
      "0.7396935031297216\n",
      "0.6591484211684454\n",
      "0.6603283072123598\n",
      "0.7383210396909027\n",
      "0.544972999002511\n",
      "0.5510975084883554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:08<00:03,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7055166311963461\n",
      "0.7358832435652412\n",
      "Validation loss decreased (0.319689 --> 0.261142).  Saving model ...\n",
      "0.9303482587064676\n",
      "0.9358490566037736\n",
      "0.9264705882352942\n",
      "0.896\n",
      "0.9433962264150944\n",
      "0.8341232227488151\n",
      "0.905\n",
      "0.9151873767258383\n",
      "0.9393346379647749\n",
      "0.92\n",
      "0.45143256464011183\n",
      "0.6897260273972603\n",
      "0.7654867256637168\n",
      "0.8307050092764379\n",
      "0.8262885192255249\n",
      "0.692530047162635\n",
      "0.7379450443707901\n",
      "0.6609120521172639\n",
      "0.6625398337057251\n",
      "0.7340620208714576\n",
      "0.5428435954751745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:10<00:02,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5461267872002421\n",
      "0.7008758882829285\n",
      "0.7302278902406188\n",
      "Validation loss decreased (0.261142 --> 0.232382).  Saving model ...\n",
      "0.9330024813895782\n",
      "0.929368029739777\n",
      "0.9309090909090909\n",
      "0.9011857707509882\n",
      "0.9372693726937269\n",
      "0.8584686774941995\n",
      "0.9032258064516129\n",
      "0.9302325581395349\n",
      "0.9475728155339805\n",
      "0.9136690647482014\n",
      "0.4593103448275862\n",
      "0.6926465604879701\n",
      "0.7673410404624278\n",
      "0.8361098604232328\n",
      "0.82409381663113\n",
      "0.6855524079320113\n",
      "0.7331365935919055\n",
      "0.6617492096944152\n",
      "0.6645551601423487\n",
      "0.7219110536646082\n",
      "0.5282171450888499\n",
      "0.5303587435742642\n",
      "0.6879512971036882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:11<00:01,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7221200546989202\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.946078431372549\n",
      "0.929368029739777\n",
      "0.927536231884058\n",
      "0.8976377952755905\n",
      "0.9372693726937269\n",
      "0.8545034642032333\n",
      "0.900990099009901\n",
      "0.9343629343629344\n",
      "0.9457364341085271\n",
      "0.9123434704830053\n",
      "0.4577319587628866\n",
      "0.6935755129498823\n",
      "0.7725017717930546\n",
      "0.8374581939799332\n",
      "0.8193531422561136\n",
      "0.6812601686141103\n",
      "0.726875\n",
      "0.6563502742987268\n",
      "0.6599319513136203\n",
      "0.7100131258203638\n",
      "0.5195659112671561\n",
      "0.518268038293734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6762134020041426\n",
      "0.7148531313504526\n",
      "EarlyStopping counter: 2 out of 50\n",
      "auc: 0.7155370238386685, ap: 0.6647581065066692\n",
      "auc mean: 0.6878820501979049, ap mean: 0.6809912830273998, acc mean: 0.6446235787401554, f1 mean: 0.668268414521842 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662379421221865\n",
      "0.0\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:10,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "Validation loss decreased (inf --> 0.721512).  Saving model ...\n",
      "0.6666666666666666\n",
      "0.7260726072607261\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00267379679144385\n",
      "0.0\n",
      "0.0008892841262783459\n",
      "0.0\n",
      "0.0005446623093681918\n",
      "0.0004158004158004158\n",
      "0.0010085728693898135\n",
      "0.0003022974607013301\n",
      "0.00022136137244050912\n",
      "0.0012039328473011839\n",
      "0.0009667284298719085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:02<00:09,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012647312446105203\n",
      "Validation loss decreased (0.721512 --> 0.675588).  Saving model ...\n",
      "0.0\n",
      "0.31901840490797545\n",
      "0.8769230769230769\n",
      "0.8833333333333333\n",
      "0.9254901960784314\n",
      "0.7065217391304348\n",
      "0.7932011331444759\n",
      "0.8824742268041237\n",
      "0.9166666666666666\n",
      "0.8704061895551257\n",
      "0.40522875816993464\n",
      "0.5631911532385466\n",
      "0.7317829457364341\n",
      "0.7496128033040784\n",
      "0.7759940726105211\n",
      "0.7931034482758621\n",
      "0.6441234405778069\n",
      "0.6324011085915848\n",
      "0.6257980610073304\n",
      "0.6149020281883809\n",
      "0.7197163894191437\n",
      "0.5244682433437453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:03<00:08,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5243178772841725\n",
      "0.6996685323045155\n",
      "Validation loss decreased (0.675588 --> 0.590861).  Saving model ...\n",
      "0.8789473684210526\n",
      "0.75\n",
      "0.8769230769230769\n",
      "0.864406779661017\n",
      "0.9083665338645418\n",
      "0.6814404432132964\n",
      "0.7455621301775148\n",
      "0.8504273504273504\n",
      "0.901010101010101\n",
      "0.8435643564356435\n",
      "0.39589442815249265\n",
      "0.49580536912751677\n",
      "0.7140023800079334\n",
      "0.7311035027653411\n",
      "0.7554540842212075\n",
      "0.7786077083955781\n",
      "0.6319652986319653\n",
      "0.5785080164303696\n",
      "0.6079883452713366\n",
      "0.5856821251688429\n",
      "0.7085111161015046\n",
      "0.5113935646398717\n",
      "0.5015997806015176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:04<00:07,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6915190014487909\n",
      "Validation loss decreased (0.590861 --> 0.427555).  Saving model ...\n",
      "0.8632707774798928\n",
      "0.7606837606837606\n",
      "0.9144981412639405\n",
      "0.9163346613545816\n",
      "0.9389312977099237\n",
      "0.7602040816326531\n",
      "0.8301886792452831\n",
      "0.9050505050505051\n",
      "0.9299610894941635\n",
      "0.8876404494382022\n",
      "0.43564356435643564\n",
      "0.6624068157614483\n",
      "0.7487940630797774\n",
      "0.7928623101036895\n",
      "0.8095680445889457\n",
      "0.8115780684664625\n",
      "0.6671884783969944\n",
      "0.7125524435877083\n",
      "0.6546623081611169\n",
      "0.6567141148786791\n",
      "0.7290655494814285\n",
      "0.5346347607052897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:05<00:05,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6189782540838622\n",
      "0.7143184654965994\n",
      "Validation loss decreased (0.427555 --> 0.287905).  Saving model ...\n",
      "0.9086294416243654\n",
      "0.8769230769230769\n",
      "0.9328621908127208\n",
      "0.9140625\n",
      "0.9591078066914498\n",
      "0.8445475638051044\n",
      "0.8571428571428571\n",
      "0.9197651663405088\n",
      "0.9386973180076629\n",
      "0.9150090415913201\n",
      "0.4534246575342466\n",
      "0.6806637317981713\n",
      "0.7594575303354747\n",
      "0.8211586901763224\n",
      "0.8167330677290837\n",
      "0.8152492668621701\n",
      "0.6757730411287901\n",
      "0.7305820105820106\n",
      "0.6523627610026689\n",
      "0.660506769963396\n",
      "0.7181796407185629\n",
      "0.5218667449368947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:07<00:04,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6754147916595101\n",
      "0.7174199004040214\n",
      "Validation loss decreased (0.287905 --> 0.249244).  Saving model ...\n",
      "0.9414634146341463\n",
      "0.8821292775665399\n",
      "0.9328621908127208\n",
      "0.9182879377431906\n",
      "0.9591078066914498\n",
      "0.8472222222222222\n",
      "0.8571428571428571\n",
      "0.9197651663405088\n",
      "0.9386973180076629\n",
      "0.9150090415913201\n",
      "0.4534246575342466\n",
      "0.6806637317981713\n",
      "0.7589158345221113\n",
      "0.8211586901763224\n",
      "0.816552334587298\n",
      "0.815347721822542\n",
      "0.6759717844814648\n",
      "0.7304274227676683\n",
      "0.6522603599832566\n",
      "0.6603438476840011\n",
      "0.7181992337164751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:08<00:03,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.521781661666884\n",
      "0.6753683921272284\n",
      "0.7174091731053757\n",
      "Validation loss decreased (0.249244 --> 0.218994).  Saving model ...\n",
      "0.9391727493917275\n",
      "0.8821292775665399\n",
      "0.9328621908127208\n",
      "0.918918918918919\n",
      "0.9591078066914498\n",
      "0.8525345622119815\n",
      "0.8666666666666667\n",
      "0.921875\n",
      "0.9391634980988594\n",
      "0.9192100538599641\n",
      "0.4529331514324693\n",
      "0.6875\n",
      "0.7562965590634977\n",
      "0.8302989435828276\n",
      "0.815188762071993\n",
      "0.8186610437532946\n",
      "0.676165034134758\n",
      "0.730628080109049\n",
      "0.6533305836254898\n",
      "0.6592613357628425\n",
      "0.7153896899443973\n",
      "0.5208373221009637\n",
      "0.6780757521489972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:09<00:02,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7139659906324266\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.941747572815534\n",
      "0.8872180451127819\n",
      "0.9328621908127208\n",
      "0.918918918918919\n",
      "0.9591078066914498\n",
      "0.8525345622119815\n",
      "0.8666666666666667\n",
      "0.921875\n",
      "0.9391634980988594\n",
      "0.9192100538599641\n",
      "0.45324232081911264\n",
      "0.6870588235294117\n",
      "0.7562965590634977\n",
      "0.828982898289829\n",
      "0.8149286498353457\n",
      "0.8190928270042194\n",
      "0.6760688836104513\n",
      "0.7307450157397691\n",
      "0.65339179778179\n",
      "0.659282885282675\n",
      "0.7155392018114917\n",
      "0.5209643940603544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:10<00:01,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6785373894127804\n",
      "0.7141439091391768\n",
      "EarlyStopping counter: 2 out of 50\n",
      "0.9394673123486683\n",
      "0.8905660377358491\n",
      "0.9328621908127208\n",
      "0.9224806201550387\n",
      "0.9591078066914498\n",
      "0.8472222222222222\n",
      "0.8571428571428571\n",
      "0.9197651663405088\n",
      "0.9386973180076629\n",
      "0.9150090415913201\n",
      "0.4534246575342466\n",
      "0.6806637317981713\n",
      "0.7589158345221113\n",
      "0.8211586901763224\n",
      "0.816552334587298\n",
      "0.8156632924880128\n",
      "0.6758703481392557\n",
      "0.7304274227676683\n",
      "0.6522262334536703\n",
      "0.6602969382680969\n",
      "0.7181992337164751\n",
      "0.521781661666884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6753142673963318\n",
      "0.7173923253957071\n",
      "Validation loss decreased (0.218994 --> 0.216217).  Saving model ...\n",
      "auc: 0.7428834930332497, ap: 0.7027861954771182\n",
      "auc mean: 0.7065975109620442, ap mean: 0.6698160564299489, acc mean: 0.6364444617224201, f1 mean: 0.6963532963960195 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.6666666666666666\n",
      "0.0\n",
      "0.0\n",
      "0.4049079754601227\n",
      "0.889795918367347\n",
      "0.7105263157894737\n",
      "0.8426666666666667\n",
      "0.9141716566866267\n",
      "0.9467455621301775\n",
      "0.8801498127340824\n",
      "0.6654879773691655\n",
      "0.7854832914121451\n",
      "0.810049307349143\n",
      "0.8177859271143708\n",
      "0.8367123287671233\n",
      "0.6795307193578265\n",
      "0.7425527288540987\n",
      "0.6618595825426945\n",
      "0.6689419795221843\n",
      "0.7304788396582556\n",
      "0.5349164407535775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:15,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6964642775895306\n",
      "0.734585374258498\n",
      "Validation loss decreased (inf --> 0.365009).  Saving model ...\n",
      "0.9181141439205955\n",
      "0.9125475285171103\n",
      "0.9191176470588235\n",
      "0.9235127478753541\n",
      "0.921875\n",
      "0.9477611940298507\n",
      "0.8290398126463701\n",
      "0.8797953964194374\n",
      "0.9281553398058252\n",
      "0.9578544061302682\n",
      "0.9200710479573713\n",
      "0.6791553133514986\n",
      "0.78506629448709\n",
      "0.8252405459834414\n",
      "0.8137777777777778\n",
      "0.8319238900634249\n",
      "0.6752238805970149\n",
      "0.7385478342162668\n",
      "0.65801133436373\n",
      "0.6570615314333907\n",
      "0.7158229624777768\n",
      "0.5157527002339669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:12,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6771814416093218\n",
      "0.7141996757007181\n",
      "Validation loss decreased (0.365009 --> 0.281993).  Saving model ...\n",
      "0.935251798561151\n",
      "0.929368029739777\n",
      "0.927536231884058\n",
      "0.9235127478753541\n",
      "0.921875\n",
      "0.9477611940298507\n",
      "0.8290398126463701\n",
      "0.8797953964194374\n",
      "0.9281553398058252\n",
      "0.9578544061302682\n",
      "0.9200710479573713\n",
      "0.6791553133514986\n",
      "0.78506629448709\n",
      "0.8252405459834414\n",
      "0.8137777777777778\n",
      "0.8319238900634249\n",
      "0.6752238805970149\n",
      "0.7385478342162668\n",
      "0.65801133436373\n",
      "0.6570615314333907\n",
      "0.7158229624777768\n",
      "0.5157527002339669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:04<00:11,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6771814416093218\n",
      "0.7141996757007181\n",
      "Validation loss decreased (0.281993 --> 0.275402).  Saving model ...\n",
      "0.935251798561151\n",
      "0.929368029739777\n",
      "0.927536231884058\n",
      "0.9235127478753541\n",
      "0.921875\n",
      "0.9477611940298507\n",
      "0.8290398126463701\n",
      "0.8797953964194374\n",
      "0.9281553398058252\n",
      "0.9596928982725528\n",
      "0.9200710479573713\n",
      "0.6791553133514986\n",
      "0.78506629448709\n",
      "0.8252405459834414\n",
      "0.8137777777777778\n",
      "0.8319238900634249\n",
      "0.6752238805970149\n",
      "0.7385478342162668\n",
      "0.65801133436373\n",
      "0.6570615314333907\n",
      "0.7158229624777768\n",
      "0.5157527002339669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:06<00:09,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6771814416093218\n",
      "0.7141996757007181\n",
      "Validation loss decreased (0.275402 --> 0.258997).  Saving model ...\n",
      "0.9326923076923077\n",
      "0.929368029739777\n",
      "0.927536231884058\n",
      "0.9287749287749287\n",
      "0.921875\n",
      "0.9548872180451128\n",
      "0.8309859154929577\n",
      "0.884318766066838\n",
      "0.923679060665362\n",
      "0.9613899613899614\n",
      "0.9172661870503597\n",
      "0.6801925722145805\n",
      "0.7825779036827195\n",
      "0.8249943400498075\n",
      "0.8188941123796731\n",
      "0.8331100991159925\n",
      "0.6809408926417371\n",
      "0.7434390090279236\n",
      "0.6631016042780749\n",
      "0.6620743807552287\n",
      "0.7263966413816135\n",
      "0.5245118880204075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:08<00:08,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68995312069124\n",
      "0.7218201598789082\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9320388349514563\n",
      "0.929368029739777\n",
      "0.927007299270073\n",
      "0.9310344827586207\n",
      "0.9212598425196851\n",
      "0.9425287356321839\n",
      "0.8254716981132075\n",
      "0.884318766066838\n",
      "0.923679060665362\n",
      "0.9633911368015414\n",
      "0.9159212880143113\n",
      "0.6801925722145805\n",
      "0.7825779036827195\n",
      "0.8249943400498075\n",
      "0.8188941123796731\n",
      "0.8338239229328338\n",
      "0.6808382330770391\n",
      "0.7434390090279236\n",
      "0.6629625746933641\n",
      "0.6620743807552287\n",
      "0.7262926922343065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:09<00:06,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5244057933108837\n",
      "0.6896741814339692\n",
      "0.7215524984635749\n",
      "EarlyStopping counter: 2 out of 50\n",
      "0.9320388349514563\n",
      "0.929368029739777\n",
      "0.927536231884058\n",
      "0.9261363636363636\n",
      "0.921875\n",
      "0.9548872180451128\n",
      "0.8309859154929577\n",
      "0.8814432989690721\n",
      "0.923679060665362\n",
      "0.9633911368015414\n",
      "0.9159212880143113\n",
      "0.6789869952087612\n",
      "0.7828531271960647\n",
      "0.8244824482448245\n",
      "0.8163356393662129\n",
      "0.8342189160467588\n",
      "0.6781747223056139\n",
      "0.7409418398245797\n",
      "0.6602910602910603\n",
      "0.659792353212147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:11<00:04,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7212510630256072\n",
      "0.5198511567707491\n",
      "0.683548903600913\n",
      "0.7179835236847032\n",
      "EarlyStopping counter: 3 out of 50\n",
      "0.9297820823244553\n",
      "0.929368029739777\n",
      "0.927536231884058\n",
      "0.9235127478753541\n",
      "0.921875\n",
      "0.9477611940298507\n",
      "0.8309859154929577\n",
      "0.882051282051282\n",
      "0.923679060665362\n",
      "0.9633911368015414\n",
      "0.9172661870503597\n",
      "0.6801925722145805\n",
      "0.7825779036827195\n",
      "0.8249943400498075\n",
      "0.8188941123796731\n",
      "0.8338239229328338\n",
      "0.6808382330770391\n",
      "0.7434390090279236\n",
      "0.6629625746933641\n",
      "0.6620743807552287\n",
      "0.7262926922343065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:12<00:03,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5244057933108837\n",
      "0.6896741814339692\n",
      "0.7215524984635749\n",
      "EarlyStopping counter: 4 out of 50\n",
      "0.9320388349514563\n",
      "0.929368029739777\n",
      "0.927536231884058\n",
      "0.9261363636363636\n",
      "0.921875\n",
      "0.9548872180451128\n",
      "0.8309859154929577\n",
      "0.884318766066838\n",
      "0.923679060665362\n",
      "0.9633911368015414\n",
      "0.918918918918919\n",
      "0.6801925722145805\n",
      "0.7825779036827195\n",
      "0.8249943400498075\n",
      "0.8188941123796731\n",
      "0.8338239229328338\n",
      "0.6808382330770391\n",
      "0.7434390090279236\n",
      "0.6629625746933641\n",
      "0.6620743807552287\n",
      "0.7262926922343065\n",
      "0.5244057933108837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:14<00:01,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6896741814339692\n",
      "0.7215524984635749\n",
      "EarlyStopping counter: 5 out of 50\n",
      "0.9320388349514563\n",
      "0.929368029739777\n",
      "0.927536231884058\n",
      "0.9287749287749287\n",
      "0.921875\n",
      "0.9548872180451128\n",
      "0.8133971291866029\n",
      "0.8814432989690721\n",
      "0.9194499017681729\n",
      "0.9633911368015414\n",
      "0.9172661870503597\n",
      "0.6801925722145805\n",
      "0.7825779036827195\n",
      "0.8249943400498075\n",
      "0.8188941123796731\n",
      "0.8338239229328338\n",
      "0.6808382330770391\n",
      "0.7434390090279236\n",
      "0.6629625746933641\n",
      "0.6620743807552287\n",
      "0.7262926922343065\n",
      "0.5244057933108837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6896741814339692\n",
      "0.7215524984635749\n",
      "EarlyStopping counter: 6 out of 50\n",
      "auc: 0.7435954554404567, ap: 0.7294237724247336\n",
      "auc mean: 0.7049974613032317, ap mean: 0.6845802767845318, acc mean: 0.6490913080643176, f1 mean: 0.7056133399487721 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17692307692307693\n",
      "0.6666666666666666\n",
      "0.49193548387096775\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.6907993966817496\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.7306590257879656\n",
      "0.9007633587786259\n",
      "0.4186046511627907\n",
      "0.6758720930232558\n",
      "0.7702602230483271\n",
      "0.8173913043478261\n",
      "0.8173540439207284\n",
      "0.6721754807692307\n",
      "0.7388548489330234\n",
      "0.6629491293597769\n",
      "0.656595168531319\n",
      "0.7261353326011174\n",
      "0.5242250586090128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:16,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6877435820792569\n",
      "0.7199379728396222\n",
      "Validation loss decreased (inf --> 0.504364).  Saving model ...\n",
      "0.9544364508393285\n",
      "0.8947368421052632\n",
      "0.9368029739776952\n",
      "0.9590643274853801\n",
      "0.8941176470588236\n",
      "0.9618320610687023\n",
      "0.8616780045351474\n",
      "0.895\n",
      "0.9115384615384615\n",
      "0.9122137404580153\n",
      "0.9242144177449169\n",
      "0.43532684283727396\n",
      "0.7109164420485176\n",
      "0.771101573676681\n",
      "0.8196795305800045\n",
      "0.8167202572347267\n",
      "0.6723775172828373\n",
      "0.7388548489330234\n",
      "0.6629130709324352\n",
      "0.6565940918647329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:14,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7265863914373089\n",
      "0.5244128855737598\n",
      "0.6880701229682629\n",
      "0.7201617073285386\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9544364508393285\n",
      "0.9077490774907749\n",
      "0.9407407407407408\n",
      "0.9590643274853801\n",
      "0.8941176470588236\n",
      "0.9618320610687023\n",
      "0.863013698630137\n",
      "0.8984771573604061\n",
      "0.9058823529411765\n",
      "0.9136276391554703\n",
      "0.9256505576208178\n",
      "0.43435754189944137\n",
      "0.7051630434782609\n",
      "0.773121387283237\n",
      "0.820501138952164\n",
      "0.8167202572347267\n",
      "0.6723775172828373\n",
      "0.7388548489330234\n",
      "0.6629130709324352\n",
      "0.6565940918647329\n",
      "0.7265863914373089\n",
      "0.5244128855737598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:05<00:13,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6880859532272722\n",
      "0.7201617073285386\n",
      "Validation loss decreased (0.504364 --> 0.455886).  Saving model ...\n",
      "0.9544364508393285\n",
      "0.9077490774907749\n",
      "0.9368029739776952\n",
      "0.9590643274853801\n",
      "0.8976377952755905\n",
      "0.9618320610687023\n",
      "0.8636363636363636\n",
      "0.8994974874371859\n",
      "0.9111969111969112\n",
      "0.9157088122605364\n",
      "0.9256505576208178\n",
      "0.43575418994413406\n",
      "0.7124492557510149\n",
      "0.7728421812928855\n",
      "0.81278748850046\n",
      "0.8178581210627225\n",
      "0.673735976640541\n",
      "0.741800193569201\n",
      "0.6619032153296525\n",
      "0.653511189505016\n",
      "0.7390699523052464\n",
      "0.5344178952719878\n",
      "0.7000356083086053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:07<00:11,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7301866081229418\n",
      "Validation loss decreased (0.455886 --> 0.451300).  Saving model ...\n",
      "0.9330024813895782\n",
      "0.875968992248062\n",
      "0.9368029739776952\n",
      "0.9590643274853801\n",
      "0.8976377952755905\n",
      "0.9578544061302682\n",
      "0.847926267281106\n",
      "0.8994974874371859\n",
      "0.9111969111969112\n",
      "0.9157088122605364\n",
      "0.9256505576208178\n",
      "0.43405443126308446\n",
      "0.7114864864864865\n",
      "0.7725631768953068\n",
      "0.8203728967712597\n",
      "0.8167202572347267\n",
      "0.6723775172828373\n",
      "0.7388548489330234\n",
      "0.6629130709324352\n",
      "0.6565940918647329\n",
      "0.7265863914373089\n",
      "0.5244128855737598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:09<00:09,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6880859532272722\n",
      "0.7201617073285386\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9544364508393285\n",
      "0.9029850746268657\n",
      "0.9368029739776952\n",
      "0.9560117302052786\n",
      "0.8744939271255061\n",
      "0.9618320610687023\n",
      "0.8636363636363636\n",
      "0.8994974874371859\n",
      "0.9111969111969112\n",
      "0.9157088122605364\n",
      "0.9256505576208178\n",
      "0.4351464435146444\n",
      "0.7090663058186739\n",
      "0.7728421812928855\n",
      "0.8207461328480437\n",
      "0.8167202572347267\n",
      "0.6723775172828373\n",
      "0.7388548489330234\n",
      "0.6629130709324352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:10<00:07,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6565940918647329\n",
      "0.7265863914373089\n",
      "0.5244128855737598\n",
      "0.6880859532272722\n",
      "0.7201617073285386\n",
      "EarlyStopping counter: 2 out of 50\n",
      "0.9544364508393285\n",
      "0.9077490774907749\n",
      "0.9407407407407408\n",
      "0.9590643274853801\n",
      "0.8941176470588236\n",
      "0.9618320610687023\n",
      "0.863013698630137\n",
      "0.898989898989899\n",
      "0.9111969111969112\n",
      "0.9136276391554703\n",
      "0.9256505576208178\n",
      "0.4348432055749129\n",
      "0.711051030753633\n",
      "0.7734007950849295\n",
      "0.8165788871078543\n",
      "0.8167202572347267\n",
      "0.6723775172828373\n",
      "0.7388548489330234\n",
      "0.6629130709324352\n",
      "0.6565940918647329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:12<00:05,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7265863914373089\n",
      "0.5244128855737598\n",
      "0.6880859532272722\n",
      "0.7201617073285386\n",
      "EarlyStopping counter: 3 out of 50\n",
      "0.9544364508393285\n",
      "0.9077490774907749\n",
      "0.9368029739776952\n",
      "0.9590643274853801\n",
      "0.8976377952755905\n",
      "0.9615384615384616\n",
      "0.8610478359908884\n",
      "0.9017632241813602\n",
      "0.9005847953216374\n",
      "0.9157088122605364\n",
      "0.9256505576208178\n",
      "0.4348432055749129\n",
      "0.7112462006079028\n",
      "0.7721198988804623\n",
      "0.8207461328480437\n",
      "0.8167202572347267\n",
      "0.6723775172828373\n",
      "0.7388548489330234\n",
      "0.6629130709324352\n",
      "0.6565940918647329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:14<00:03,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7265863914373089\n",
      "0.5244128855737598\n",
      "0.6880859532272722\n",
      "0.7201617073285386\n",
      "EarlyStopping counter: 4 out of 50\n",
      "0.9567307692307693\n",
      "0.9037037037037037\n",
      "0.9368029739776952\n",
      "0.9590643274853801\n",
      "0.8941176470588236\n",
      "0.9618320610687023\n",
      "0.8636363636363636\n",
      "0.8994974874371859\n",
      "0.9069767441860465\n",
      "0.9157088122605364\n",
      "0.9256505576208178\n",
      "0.4348432055749129\n",
      "0.7112462006079028\n",
      "0.7728421812928855\n",
      "0.8134037181546936\n",
      "0.8167202572347267\n",
      "0.6723775172828373\n",
      "0.7388548489330234\n",
      "0.6629130709324352\n",
      "0.6565940918647329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:16<00:01,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7265863914373089\n",
      "0.5244128855737598\n",
      "0.6880859532272722\n",
      "0.7201617073285386\n",
      "EarlyStopping counter: 5 out of 50\n",
      "0.9519230769230769\n",
      "0.9077490774907749\n",
      "0.9407407407407408\n",
      "0.9560117302052786\n",
      "0.8941176470588236\n",
      "0.9618320610687023\n",
      "0.8656036446469249\n",
      "0.8967254408060453\n",
      "0.9111969111969112\n",
      "0.9157088122605364\n",
      "0.9256505576208178\n",
      "0.43156424581005587\n",
      "0.7112462006079028\n",
      "0.7728421812928855\n",
      "0.8203728967712597\n",
      "0.8173540439207284\n",
      "0.6721754807692307\n",
      "0.7388548489330234\n",
      "0.6629491293597769\n",
      "0.656595168531319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7261353326011174\n",
      "0.5242250586090128\n",
      "0.6877435820792569\n",
      "0.7199379728396222\n",
      "EarlyStopping counter: 6 out of 50\n",
      "auc: 0.7468280524892474, ap: 0.7306889876869296\n",
      "auc mean: 0.713940990094251, ap mean: 0.6922638696735496, acc mean: 0.6461375825456783, f1 mean: 0.7038407774594395 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6159554730983302\n",
      "0.0\n",
      "0.6515837104072398\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:11,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "Validation loss decreased (inf --> 0.674325).  Saving model ...\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.9230769230769231\n",
      "0.951310861423221\n",
      "0.8164251207729468\n",
      "0.856396866840731\n",
      "0.9058823529411765\n",
      "0.9616858237547893\n",
      "0.8983364140480592\n",
      "0.44849334267694463\n",
      "0.6697607997143877\n",
      "0.764490095377843\n",
      "0.8070258723000238\n",
      "0.8219366681964204\n",
      "0.8245079013030219\n",
      "0.6776962697050102\n",
      "0.7406267179769104\n",
      "0.6659095211054326\n",
      "0.7323076923076923\n",
      "0.532034391901262\n",
      "0.5150524010175718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:02<00:09,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6914482891752328\n",
      "0.7305126928820309\n",
      "Validation loss decreased (0.674325 --> 0.645044).  Saving model ...\n",
      "0.9135802469135802\n",
      "0.8871595330739299\n",
      "0.9185185185185185\n",
      "0.9230769230769231\n",
      "0.951310861423221\n",
      "0.8192771084337349\n",
      "0.8682170542635659\n",
      "0.916504854368932\n",
      "0.9616858237547893\n",
      "0.9044117647058824\n",
      "0.44972067039106145\n",
      "0.6763353378139371\n",
      "0.7656934306569343\n",
      "0.8075294117647058\n",
      "0.8210285714285714\n",
      "0.8269972451790634\n",
      "0.6796207057360485\n",
      "0.7420556651325882\n",
      "0.6676871383236886\n",
      "0.7314035175128295\n",
      "0.5311511483977445\n",
      "0.5406452105233035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:03<00:08,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6954338877388345\n",
      "0.7355161258700127\n",
      "Validation loss decreased (0.645044 --> 0.492974).  Saving model ...\n",
      "0.9297820823244553\n",
      "0.9207547169811321\n",
      "0.9343065693430657\n",
      "0.9230769230769231\n",
      "0.9552238805970149\n",
      "0.8192771084337349\n",
      "0.8682170542635659\n",
      "0.916504854368932\n",
      "0.9616858237547893\n",
      "0.9044117647058824\n",
      "0.45080251221214235\n",
      "0.6765641569459173\n",
      "0.7656934306569343\n",
      "0.8083705619562662\n",
      "0.8215672835275303\n",
      "0.8279658684282962\n",
      "0.6798197918284915\n",
      "0.7423877327491786\n",
      "0.6678102625298329\n",
      "0.7315640093611512\n",
      "0.5306823254695924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:04<00:07,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5402494925333308\n",
      "0.6953151932289624\n",
      "0.7354863984721236\n",
      "Validation loss decreased (0.492974 --> 0.325702).  Saving model ...\n",
      "0.9297820823244553\n",
      "0.9213483146067416\n",
      "0.9424460431654677\n",
      "0.9318181818181818\n",
      "0.9411764705882353\n",
      "0.8306264501160093\n",
      "0.8781725888324873\n",
      "0.9245283018867925\n",
      "0.9563567362428842\n",
      "0.9150090415913201\n",
      "0.44751381215469616\n",
      "0.6873086083701939\n",
      "0.7661375661375661\n",
      "0.8231338264963013\n",
      "0.8201280070624586\n",
      "0.8218451749734889\n",
      "0.673551863493489\n",
      "0.7383197150639011\n",
      "0.6562642769284835\n",
      "0.7133979851238114\n",
      "0.5125434195291393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:06<00:06,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5200360479330436\n",
      "0.6767955182072829\n",
      "0.7153021622620588\n",
      "Validation loss decreased (0.325702 --> 0.225736).  Saving model ...\n",
      "0.9263657957244655\n",
      "0.9230769230769231\n",
      "0.95\n",
      "0.9318181818181818\n",
      "0.9411764705882353\n",
      "0.8306264501160093\n",
      "0.8781725888324873\n",
      "0.9245283018867925\n",
      "0.9563567362428842\n",
      "0.9150090415913201\n",
      "0.44751381215469616\n",
      "0.6873086083701939\n",
      "0.7661375661375661\n",
      "0.8231338264963013\n",
      "0.8201280070624586\n",
      "0.8218451749734889\n",
      "0.673551863493489\n",
      "0.7383197150639011\n",
      "0.6562642769284835\n",
      "0.7133979851238114\n",
      "0.5125434195291393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:07<00:04,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5200360479330436\n",
      "0.6767955182072829\n",
      "0.7153021622620588\n",
      "Validation loss decreased (0.225736 --> 0.185684).  Saving model ...\n",
      "0.9263657957244655\n",
      "0.9230769230769231\n",
      "0.95\n",
      "0.9318181818181818\n",
      "0.9411764705882353\n",
      "0.8306264501160093\n",
      "0.8781725888324873\n",
      "0.9245283018867925\n",
      "0.9563567362428842\n",
      "0.9150090415913201\n",
      "0.44751381215469616\n",
      "0.6873086083701939\n",
      "0.7661375661375661\n",
      "0.8231338264963013\n",
      "0.8201280070624586\n",
      "0.8218451749734889\n",
      "0.673551863493489\n",
      "0.7383197150639011\n",
      "0.6562642769284835\n",
      "0.7133979851238114\n",
      "0.5125434195291393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:08<00:03,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5200360479330436\n",
      "0.6767955182072829\n",
      "0.7153021622620588\n",
      "Validation loss decreased (0.185684 --> 0.184153).  Saving model ...\n",
      "0.9263657957244655\n",
      "0.9264705882352942\n",
      "0.95\n",
      "0.9318181818181818\n",
      "0.9411764705882353\n",
      "0.8306264501160093\n",
      "0.8781725888324873\n",
      "0.928030303030303\n",
      "0.9563567362428842\n",
      "0.9150090415913201\n",
      "0.44813278008298757\n",
      "0.6868824531516184\n",
      "0.7650816181689141\n",
      "0.8186949650033868\n",
      "0.8221729490022173\n",
      "0.8222755129229949\n",
      "0.6755903143329824\n",
      "0.7400630914826498\n",
      "0.6564890903938793\n",
      "0.7202018278750952\n",
      "0.5175712612260835\n",
      "0.5267950899808089\n",
      "0.6828466118514318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:09<00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7203948907500117\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9263657957244655\n",
      "0.9264705882352942\n",
      "0.95\n",
      "0.9318181818181818\n",
      "0.9411764705882353\n",
      "0.8306264501160093\n",
      "0.8781725888324873\n",
      "0.928030303030303\n",
      "0.9563567362428842\n",
      "0.9150090415913201\n",
      "0.4487534626038781\n",
      "0.6855969893944578\n",
      "0.7658969804618118\n",
      "0.8186341022161918\n",
      "0.8236339404709018\n",
      "0.8223350253807107\n",
      "0.676913803496082\n",
      "0.7410610695074359\n",
      "0.6567291311754685\n",
      "0.7214350460378799\n",
      "0.5189633788106274\n",
      "0.528249459709787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:10<00:01,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6840633737185461\n",
      "0.7203773673464599\n",
      "EarlyStopping counter: 2 out of 50\n",
      "0.9263657957244655\n",
      "0.9144981412639405\n",
      "0.9386281588447654\n",
      "0.9318181818181818\n",
      "0.9411764705882353\n",
      "0.8306264501160093\n",
      "0.8781725888324873\n",
      "0.928030303030303\n",
      "0.9563567362428842\n",
      "0.9150090415913201\n",
      "0.4487534626038781\n",
      "0.6855969893944578\n",
      "0.7658969804618118\n",
      "0.818819271657996\n",
      "0.8238169295712064\n",
      "0.8223350253807107\n",
      "0.6770158251695554\n",
      "0.7409282700421941\n",
      "0.6568456923786873\n",
      "0.7215383147246874\n",
      "0.5188087774294671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5283118251250988\n",
      "0.6842045428707851\n",
      "0.720548524197525\n",
      "EarlyStopping counter: 3 out of 50\n",
      "auc: 0.7371586263394685, ap: 0.703597519309435\n",
      "auc mean: 0.6555867263117185, ap mean: 0.647693034676192, acc mean: 0.6021463727290713, f1 mean: 0.6383762794543751 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.9085365853658537\n",
      "0.8535564853556485\n",
      "0.9266409266409267\n",
      "0.712401055408971\n",
      "0.8775510204081632\n",
      "0.9551656920077972\n",
      "0.9063670411985019\n",
      "0.6848816029143898\n",
      "0.7648155050316809\n",
      "0.7879535917057516\n",
      "0.8243403850724982\n",
      "0.8060989643268124\n",
      "0.6676163342830009\n",
      "0.7040353529480172\n",
      "0.6582207207207207\n",
      "0.65768538876674\n",
      "0.7319033453368822\n",
      "0.5413566113337149\n",
      "0.39020919943976345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:13,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5815711624849348\n",
      "0.7160287393860222\n",
      "Validation loss decreased (inf --> 0.541452).  Saving model ...\n",
      "0.9104477611940298\n",
      "0.8793774319066148\n",
      "0.922509225092251\n",
      "0.9479768786127167\n",
      "0.8957528957528957\n",
      "0.9363295880149812\n",
      "0.847926267281106\n",
      "0.9118773946360154\n",
      "0.945179584120983\n",
      "0.931899641577061\n",
      "0.7122083192424755\n",
      "0.7687411598302687\n",
      "0.8196870038557496\n",
      "0.8361456483126111\n",
      "0.8176438945669715\n",
      "0.6847487772343264\n",
      "0.7342782152230971\n",
      "0.6595966983596281\n",
      "0.6579623287671232\n",
      "0.7231557960694959\n",
      "0.5268181818181819\n",
      "0.5303064699205449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:02<00:11,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6842968429684296\n",
      "0.7196013445220131\n",
      "Validation loss decreased (0.541452 --> 0.410785).  Saving model ...\n",
      "0.9285714285714286\n",
      "0.9298892988929889\n",
      "0.927536231884058\n",
      "0.9479768786127167\n",
      "0.8992248062015504\n",
      "0.9363295880149812\n",
      "0.8452655889145496\n",
      "0.9097888675623801\n",
      "0.945179584120983\n",
      "0.925589836660617\n",
      "0.7124957670165933\n",
      "0.7696689213243147\n",
      "0.8213879408418657\n",
      "0.8374471870135646\n",
      "0.8183783783783783\n",
      "0.6869888475836431\n",
      "0.7359781121751026\n",
      "0.6618395508683561\n",
      "0.6604821089580573\n",
      "0.7264484108046196\n",
      "0.529425204817704\n",
      "0.5338465476887069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:04<00:10,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6885268455991103\n",
      "0.7227970706354832\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9285714285714286\n",
      "0.9298892988929889\n",
      "0.9309090909090909\n",
      "0.9479768786127167\n",
      "0.8992248062015504\n",
      "0.9363295880149812\n",
      "0.8452655889145496\n",
      "0.9097888675623801\n",
      "0.945179584120983\n",
      "0.925589836660617\n",
      "0.7124957670165933\n",
      "0.7696689213243147\n",
      "0.8213879408418657\n",
      "0.8374471870135646\n",
      "0.8183783783783783\n",
      "0.6869888475836431\n",
      "0.7359781121751026\n",
      "0.6618395508683561\n",
      "0.6604821089580573\n",
      "0.7265177548682703\n",
      "0.529425204817704\n",
      "0.5339148881695653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:05<00:08,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6885512813162873\n",
      "0.7228141463299392\n",
      "EarlyStopping counter: 2 out of 50\n",
      "0.9282296650717703\n",
      "0.9298892988929889\n",
      "0.9309090909090909\n",
      "0.9479768786127167\n",
      "0.8992248062015504\n",
      "0.9363295880149812\n",
      "0.8452655889145496\n",
      "0.9097888675623801\n",
      "0.945179584120983\n",
      "0.925589836660617\n",
      "0.7124957670165933\n",
      "0.7696689213243147\n",
      "0.8213879408418657\n",
      "0.8374471870135646\n",
      "0.8183783783783783\n",
      "0.6869888475836431\n",
      "0.7359781121751026\n",
      "0.6618395508683561\n",
      "0.6604821089580573\n",
      "0.7265177548682703\n",
      "0.529425204817704\n",
      "0.5339148881695653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:07<00:07,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6885512813162873\n",
      "0.7228141463299392\n",
      "EarlyStopping counter: 3 out of 50\n",
      "0.9282296650717703\n",
      "0.9298892988929889\n",
      "0.9309090909090909\n",
      "0.9479768786127167\n",
      "0.8992248062015504\n",
      "0.9363295880149812\n",
      "0.8452655889145496\n",
      "0.9097888675623801\n",
      "0.945179584120983\n",
      "0.927536231884058\n",
      "0.7124957670165933\n",
      "0.7696689213243147\n",
      "0.8210143279508756\n",
      "0.8374471870135646\n",
      "0.8185745140388769\n",
      "0.6867845993756504\n",
      "0.7359006734006734\n",
      "0.6614924746971524\n",
      "0.6603645217889498\n",
      "0.7259979968521963\n",
      "0.5291623173277662\n",
      "0.5333004530176823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:08<00:05,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6879574794671187\n",
      "0.7223022262093062\n",
      "Validation loss decreased (0.410785 --> 0.409752).  Saving model ...\n",
      "0.9282296650717703\n",
      "0.9298892988929889\n",
      "0.924187725631769\n",
      "0.9449275362318841\n",
      "0.8992248062015504\n",
      "0.9363295880149812\n",
      "0.8364485981308412\n",
      "0.9097888675623801\n",
      "0.945179584120983\n",
      "0.925589836660617\n",
      "0.7124957670165933\n",
      "0.7696689213243147\n",
      "0.8213879408418657\n",
      "0.8374471870135646\n",
      "0.8190167477039438\n",
      "0.6869888475836431\n",
      "0.7359781121751026\n",
      "0.6618395508683561\n",
      "0.6605530878349334\n",
      "0.726275108545255\n",
      "0.529386809385504\n",
      "0.5336599097040706\n",
      "0.6882822170265438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:10<00:04,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7226946334089192\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9256594724220624\n",
      "0.9298892988929889\n",
      "0.927536231884058\n",
      "0.9387755102040817\n",
      "0.8992248062015504\n",
      "0.9363295880149812\n",
      "0.8452655889145496\n",
      "0.9097888675623801\n",
      "0.945179584120983\n",
      "0.925589836660617\n",
      "0.7124957670165933\n",
      "0.7696689213243147\n",
      "0.8213879408418657\n",
      "0.8374471870135646\n",
      "0.8183783783783783\n",
      "0.6869888475836431\n",
      "0.7359781121751026\n",
      "0.6618395508683561\n",
      "0.660458452722063\n",
      "0.7263444195256955\n",
      "0.5294213635325218\n",
      "0.5337099191985668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:11<00:02,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6883847820355575\n",
      "0.7227287759247886\n",
      "Validation loss decreased (0.409752 --> 0.408125).  Saving model ...\n",
      "0.9282296650717703\n",
      "0.9298892988929889\n",
      "0.9309090909090909\n",
      "0.9479768786127167\n",
      "0.8992248062015504\n",
      "0.9363295880149812\n",
      "0.8452655889145496\n",
      "0.9097888675623801\n",
      "0.945179584120983\n",
      "0.925589836660617\n",
      "0.7124957670165933\n",
      "0.7696689213243147\n",
      "0.8213879408418657\n",
      "0.8374471870135646\n",
      "0.8183783783783783\n",
      "0.6869888475836431\n",
      "0.7359781121751026\n",
      "0.6618395508683561\n",
      "0.6604821089580573\n",
      "0.7265177548682703\n",
      "0.5294732032116979\n",
      "0.5338026237601133\n",
      "0.6885039153414889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:12<00:01,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7227799957477972\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9282296650717703\n",
      "0.9298892988929889\n",
      "0.9309090909090909\n",
      "0.9479768786127167\n",
      "0.8992248062015504\n",
      "0.9363295880149812\n",
      "0.8457943925233645\n",
      "0.9097888675623801\n",
      "0.945179584120983\n",
      "0.925589836660617\n",
      "0.7124957670165933\n",
      "0.7696689213243147\n",
      "0.8213879408418657\n",
      "0.8374471870135646\n",
      "0.8183783783783783\n",
      "0.6869888475836431\n",
      "0.7359781121751026\n",
      "0.6618395508683561\n",
      "0.6605530878349334\n",
      "0.7265177548682703\n",
      "0.529425204817704\n",
      "0.5338855972496526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6885275975142746\n",
      "0.7228312228312228\n",
      "EarlyStopping counter: 2 out of 50\n",
      "auc: 0.7544636766165904, ap: 0.7446155133813381\n",
      "auc mean: 0.7492167838395624, ap mean: 0.7738209442150769, acc mean: 0.6999598079497908, f1 mean: 0.707566083594134 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3473367/3542105101.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 57861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43805309734513276\n",
      "0.6666666666666666\n",
      "0.0\n",
      "0.8347826086956521\n",
      "0.9098039215686274\n",
      "0.7027027027027027\n",
      "0.7848837209302325\n",
      "0.8796680497925311\n",
      "0.9094650205761317\n",
      "0.836\n",
      "0.5795363709032774\n",
      "0.731551655364978\n",
      "0.7526315789473684\n",
      "0.7787212787212787\n",
      "0.802158273381295\n",
      "0.6619134471895208\n",
      "0.6485329303614155\n",
      "0.6229249011857707\n",
      "0.6232691805277366\n",
      "0.7315065403698692\n",
      "0.5342245989304812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:11,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30544647643267636\n",
      "0.5403692976104272\n",
      "0.7100064090060467\n",
      "Validation loss decreased (inf --> 0.714034).  Saving model ...\n",
      "0.8563829787234043\n",
      "0.8737864077669902\n",
      "0.9428571428571428\n",
      "0.9169960474308301\n",
      "0.959409594095941\n",
      "0.8558352402745996\n",
      "0.9118387909319899\n",
      "0.9366602687140115\n",
      "0.9580152671755725\n",
      "0.9107468123861566\n",
      "0.6921751120303343\n",
      "0.7609403254972875\n",
      "0.8215349369988545\n",
      "0.8229493500672345\n",
      "0.8266883645240033\n",
      "0.6857056053471062\n",
      "0.7429851701696362\n",
      "0.6573658327988027\n",
      "0.6614865110199339\n",
      "0.7265583313121513\n",
      "0.5263298762127802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:02<00:09,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5326188605842965\n",
      "0.6924536869927692\n",
      "0.7263198200354185\n",
      "Validation loss decreased (0.714034 --> 0.409936).  Saving model ...\n",
      "0.9290953545232273\n",
      "0.951310861423221\n",
      "0.945054945054945\n",
      "0.9133858267716536\n",
      "0.9558823529411765\n",
      "0.8558352402745996\n",
      "0.9122807017543859\n",
      "0.9447619047619048\n",
      "0.9580152671755725\n",
      "0.9113924050632911\n",
      "0.6946148602590321\n",
      "0.7586455331412104\n",
      "0.8294223826714802\n",
      "0.8281840408979774\n",
      "0.826133909287257\n",
      "0.6847172081829122\n",
      "0.7412100095026924\n",
      "0.6557480980557904\n",
      "0.658581823369953\n",
      "0.7247040855288278\n",
      "0.5226796014682747\n",
      "0.5319683710349129\n",
      "0.6858673657100809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:03<00:09,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7207109518645985\n",
      "Validation loss decreased (0.409936 --> 0.266379).  Saving model ...\n",
      "0.9313725490196079\n",
      "0.9708029197080292\n",
      "0.9428571428571428\n",
      "0.9098039215686274\n",
      "0.9523809523809523\n",
      "0.8558352402745996\n",
      "0.9077306733167082\n",
      "0.9449715370018975\n",
      "0.9580152671755725\n",
      "0.9039145907473309\n",
      "0.6946229286438959\n",
      "0.7619387027797576\n",
      "0.8319571524213345\n",
      "0.8238661382650815\n",
      "0.8219032429558746\n",
      "0.6791834301892415\n",
      "0.7360284132455865\n",
      "0.6498680602266259\n",
      "0.6548442602802261\n",
      "0.7133454698221537\n",
      "0.516122828386435\n",
      "0.5194515363053686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:05<00:07,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6727095056777976\n",
      "0.7134778293285322\n",
      "Validation loss decreased (0.266379 --> 0.214198).  Saving model ...\n",
      "0.9471153846153846\n",
      "0.9708029197080292\n",
      "0.9428571428571428\n",
      "0.9098039215686274\n",
      "0.9523809523809523\n",
      "0.8558352402745996\n",
      "0.9077306733167082\n",
      "0.9449715370018975\n",
      "0.9580152671755725\n",
      "0.9039145907473309\n",
      "0.6946229286438959\n",
      "0.7619387027797576\n",
      "0.8319571524213345\n",
      "0.8238661382650815\n",
      "0.8219032429558746\n",
      "0.6791834301892415\n",
      "0.7360284132455865\n",
      "0.6498680602266259\n",
      "0.6548442602802261\n",
      "0.7133454698221537\n",
      "0.516122828386435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:06<00:06,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5194515363053686\n",
      "0.6727095056777976\n",
      "0.7134778293285322\n",
      "Validation loss decreased (0.214198 --> 0.198430).  Saving model ...\n",
      "0.9471153846153846\n",
      "0.9708029197080292\n",
      "0.9428571428571428\n",
      "0.9098039215686274\n",
      "0.9523809523809523\n",
      "0.8558352402745996\n",
      "0.9077306733167082\n",
      "0.9449715370018975\n",
      "0.9580152671755725\n",
      "0.9039145907473309\n",
      "0.6946229286438959\n",
      "0.7619387027797576\n",
      "0.8319571524213345\n",
      "0.8238661382650815\n",
      "0.8219032429558746\n",
      "0.6791834301892415\n",
      "0.7360284132455865\n",
      "0.6498680602266259\n",
      "0.6548442602802261\n",
      "0.7133454698221537\n",
      "0.516122828386435\n",
      "0.5194515363053686\n",
      "0.6727095056777976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:07<00:05,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7134778293285322\n",
      "EarlyStopping counter: 1 out of 50\n",
      "0.9471153846153846\n",
      "0.9708029197080292\n",
      "0.9428571428571428\n",
      "0.9098039215686274\n",
      "0.9523809523809523\n",
      "0.8558352402745996\n",
      "0.9077306733167082\n",
      "0.9449715370018975\n",
      "0.9580152671755725\n",
      "0.9039145907473309\n",
      "0.6946229286438959\n",
      "0.7619387027797576\n",
      "0.8319571524213345\n",
      "0.8238661382650815\n",
      "0.8219032429558746\n",
      "0.6791834301892415\n",
      "0.7360284132455865\n",
      "0.6498680602266259\n",
      "0.6548442602802261\n",
      "0.7133454698221537\n",
      "0.516122828386435\n",
      "0.5194515363053686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:08<00:03,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6727095056777976\n",
      "0.7134778293285322\n",
      "Validation loss decreased (0.198430 --> 0.197707).  Saving model ...\n",
      "0.9471153846153846\n",
      "0.9708029197080292\n",
      "0.9428571428571428\n",
      "0.9098039215686274\n",
      "0.9523809523809523\n",
      "0.8558352402745996\n",
      "0.9077306733167082\n",
      "0.9449715370018975\n",
      "0.9580152671755725\n",
      "0.9039145907473309\n",
      "0.6946229286438959\n",
      "0.7619387027797576\n",
      "0.8319571524213345\n",
      "0.8238661382650815\n",
      "0.8219032429558746\n",
      "0.6791834301892415\n",
      "0.7360284132455865\n",
      "0.6498680602266259\n",
      "0.6548442602802261\n",
      "0.7133454698221537\n",
      "0.516122828386435\n",
      "0.5194515363053686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:10<00:02,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6727095056777976\n",
      "0.7134778293285322\n",
      "Validation loss decreased (0.197707 --> 0.188427).  Saving model ...\n",
      "0.9471153846153846\n",
      "0.9708029197080292\n",
      "0.9428571428571428\n",
      "0.9098039215686274\n",
      "0.9523809523809523\n",
      "0.8558352402745996\n",
      "0.9077306733167082\n",
      "0.9449715370018975\n",
      "0.9580152671755725\n",
      "0.9039145907473309\n",
      "0.6946229286438959\n",
      "0.7619387027797576\n",
      "0.8319571524213345\n",
      "0.8238661382650815\n",
      "0.8219032429558746\n",
      "0.6791834301892415\n",
      "0.7360284132455865\n",
      "0.6498680602266259\n",
      "0.6548442602802261\n",
      "0.7133454698221537\n",
      "0.516122828386435\n",
      "0.5194515363053686\n",
      "0.6727095056777976\n",
      "0.7134778293285322\n",
      "Validation loss decreased (0.188427 --> 0.182729).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:11<00:01,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9471153846153846\n",
      "0.9708029197080292\n",
      "0.9428571428571428\n",
      "0.9098039215686274\n",
      "0.9523809523809523\n",
      "0.8558352402745996\n",
      "0.9077306733167082\n",
      "0.9449715370018975\n",
      "0.9580152671755725\n",
      "0.9039145907473309\n",
      "0.6946229286438959\n",
      "0.7619387027797576\n",
      "0.8319571524213345\n",
      "0.8238661382650815\n",
      "0.8219032429558746\n",
      "0.6791834301892415\n",
      "0.7360284132455865\n",
      "0.6498680602266259\n",
      "0.6548442602802261\n",
      "0.7133454698221537\n",
      "0.516122828386435\n",
      "0.5194515363053686\n",
      "0.6727095056777976\n",
      "0.7134778293285322\n",
      "Validation loss decreased (0.182729 --> 0.182408).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.7417152535806872, ap: 0.726798931876052\n",
      "auc mean: 0.7425412494700531, ap mean: 0.7638906715534944, acc mean: 0.6866133969764222, f1 mean: 0.6992371070377079 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root_path = \"/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2\"\n",
    "for dir_name in os.listdir(root_path):\n",
    "    folder_path = os.path.join(root_path, dir_name)\n",
    "    train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = torch.load(f'{folder_path}/train_feats.pt'), torch.load(f'{folder_path}/train_labels.pt'), torch.load(f'{folder_path}/val_feats.pt'), torch.load(f'{folder_path}/val_labels.pt'), torch.load(f'{folder_path}/test_feats.pt'), torch.load(f'{folder_path}/test_labels.pt')\n",
    "    f1_list_val, f1_list_test = train_eval_model(2, train_feats, train_labels, val_feats, val_labels, test_feats, test_labels)\n",
    "    with open(f\"{folder_path}/f1_val_scores.txt\", \"w\") as file:\n",
    "        for score in f1_list_val:\n",
    "            file.write(f\"{score}\\n\")\n",
    "    with open(f\"{folder_path}/f1_test_scores.txt\", \"w\") as file:\n",
    "        for score in f1_list_test:\n",
    "            file.write(f\"{score}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_0-12': ['/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-12_valid_12-20_test_20-27',\n",
       "  '/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-12_valid_12-16_test_16-27',\n",
       "  '/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-12_valid_12-24_test_24-27'],\n",
       " 'train_0-8': ['/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-8_valid_8-24_test_24-27',\n",
       "  '/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-8_valid_8-16_test_16-27',\n",
       "  '/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-8_valid_8-20_test_20-27',\n",
       "  '/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-8_valid_8-12_test_12-27'],\n",
       " 'train_0-20': ['/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-20_valid_20-24_test_24-27'],\n",
       " 'train_0-16': ['/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-16_valid_16-20_test_20-27',\n",
       "  '/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-16_valid_16-24_test_24-27'],\n",
       " 'train_0-4': ['/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-4_valid_4-8_test_8-27',\n",
       "  '/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-4_valid_4-16_test_16-27',\n",
       "  '/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-4_valid_4-24_test_24-27',\n",
       "  '/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-4_valid_4-20_test_20-27',\n",
       "  '/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2/train_0-4_valid_4-12_test_12-27']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_folders = {}\n",
    "\n",
    "\n",
    "root_path = \"/home/niamatzawad/niamatzawad/HTGNN/splits/time_window_2\"\n",
    "for dir_name in os.listdir(root_path):\n",
    "    prefix = \"_\".join(dir_name.split(\"_\")[:2])\n",
    "    folder_path = os.path.join(root_path, dir_name)\n",
    "    if prefix not in grouped_folders:\n",
    "        grouped_folders[prefix] = []\n",
    "    grouped_folders[prefix].append(folder_path)\n",
    "    \n",
    "grouped_folders        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_plot(folder, train_start, train_end, val_start, val_end, test_start, test_end, scores):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    x = range(11)\n",
    "    plt.ylim(0, 1)  # Explicitly setting y-axis from 0 to 1\n",
    "    plt.yticks([i * 0.1 for i in range(11)])  # Ticks from 0 to 1 at 0.1 intervals\n",
    "\n",
    "    plt.xticks(range(min(x), max(x) + 1, 1))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 scores(Validation)')\n",
    "\n",
    "    # Adding a grid for better readability\n",
    "    plt.grid(True)\n",
    "\n",
    "    # labels = validation_splits\n",
    "    colors = ['red', 'green', 'blue', 'cyan', 'black', 'gray', 'purple', 'orange']\n",
    "    # colors = ['r','b']\n",
    "    for i,v_split in enumerate(scores):\n",
    "        plt.plot(v_split, color=colors[i],  linestyle='-', linewidth=2)\n",
    "    # plt.plot(all_val_f1_scores[0], color=colors[0], label=labels[0], linestyle='-', linewidth=2)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(folder + \"/validation.png\")  # You can specify the file path here\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 12) (12, 20) (20, 27)\n",
      "(0, 12) (12, 16) (16, 27)\n",
      "(0, 12) (12, 24) (24, 27)\n",
      "(0, 8) (8, 24) (24, 27)\n",
      "(0, 8) (8, 16) (16, 27)\n",
      "(0, 8) (8, 20) (20, 27)\n",
      "(0, 8) (8, 12) (12, 27)\n",
      "(0, 20) (20, 24) (24, 27)\n",
      "(0, 16) (16, 20) (20, 27)\n",
      "(0, 16) (16, 24) (24, 27)\n",
      "(0, 4) (4, 8) (8, 27)\n",
      "(0, 4) (4, 16) (16, 27)\n",
      "(0, 4) (4, 24) (24, 27)\n",
      "(0, 4) (4, 20) (20, 27)\n",
      "(0, 4) (4, 12) (12, 27)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_scores(file_path):\n",
    "    scores = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            scores.append(float(line.strip()))\n",
    "    return scores\n",
    "\n",
    "for key,item in grouped_folders.items():\n",
    "    val_scores = []\n",
    "    test_scores = []\n",
    "    labels = []\n",
    "    \n",
    "    train_start, train_end = dict_ind_year[0], dict_ind_year[int(key.split(\"-\")[1] - 1)]\n",
    "    \n",
    "    for folder in item:\n",
    "        folder_name = folder.split(\"/\")[-1]\n",
    "        pattern = r'(\\d+)-(\\d+)'\n",
    "        matches = re.findall(pattern, folder_name)\n",
    "        results = {\n",
    "            \"train\": tuple(map(int, matches[0])),\n",
    "            \"valid\": tuple(map(int, matches[1])),\n",
    "            \"test\": tuple(map(int, matches[2]))\n",
    "        }\n",
    "        print(results['train'], results['valid'], results['test'])\n",
    "        labels.append(f\"validation({dict_ind_year[results['valid'][0]]} - {dict_ind_year[results['valid'][1]]})\")\n",
    "        val_scores.append(get_scores(os.path.join(folder, 'f1_val_scores.txt')))\n",
    "        test_scores.append(get_scores(os.path.join(folder, 'f1_test_scores.txt')))\n",
    "    get_plot(folder, train_start, train_end, labels, val_scores)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('action', 'involved_in_r_t0', 'actor'): 506, ('actor', 'involved_in_t0', 'action'): 506, ('actor', 'involved_with_r_t0', 'actor'): 584, ('actor', 'involved_with_t0', 'actor'): 584},\n",
       "       metagraph=[('action', 'actor', 'involved_in_r_t0'), ('actor', 'action', 'involved_in_t0'), ('actor', 'actor', 'involved_with_r_t0'), ('actor', 'actor', 'involved_with_t0')]),\n",
       " Graph(num_nodes={'action': 25, 'actor': 18622},\n",
       "       num_edges={('action', 'involved_in_r_t0', 'actor'): 526, ('actor', 'involved_in_t0', 'action'): 526, ('actor', 'involved_with_r_t0', 'actor'): 591, ('actor', 'involved_with_t0', 'actor'): 591},\n",
       "       metagraph=[('action', 'actor', 'involved_in_r_t0'), ('actor', 'action', 'involved_in_t0'), ('actor', 'actor', 'involved_with_r_t0'), ('actor', 'actor', 'involved_with_t0')])]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10,6))\n",
    "x = range(11)\n",
    "plt.ylim(0, 1)  # Explicitly setting y-axis from 0 to 1\n",
    "plt.yticks([i * 0.1 for i in range(11)])  # Ticks from 0 to 1 at 0.1 intervals\n",
    "\n",
    "plt.xticks(range(min(x), max(x) + 1, 1))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 scores(Validation)')\n",
    "\n",
    "# Adding a grid for better readability\n",
    "plt.grid(True)\n",
    "\n",
    "# Show legend to label each line\n",
    "\n",
    "\n",
    "# labels = validation_splits\n",
    "colors = ['red', 'green', 'blue', 'cyan', 'black', 'gray', 'purple', 'orange']\n",
    "# colors = ['r','b']\n",
    "for i,v_split in enumerate(all_val_f1_scores):\n",
    "    plt.plot(v_split, color=colors[i],  linestyle='-', linewidth=2)\n",
    "# plt.plot(all_val_f1_scores[0], color=colors[0], label=labels[0], linestyle='-', linewidth=2)\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(root_path + \"/validation.png\")  # You can specify the file path here\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
